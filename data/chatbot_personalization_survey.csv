user_id,step,question_type,question_text,button_label,json_choices,choice,choice_numeric,text,answer_date,sample_type
generation1,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation1,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation1,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation1,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"Yes, that's not much different than search aggregators like google. It may cause some bias but the reader will generally gravitate towards their own bias anyway.",2023-11-01,generation
generation1,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,I don't think so as this may just be a general query related to their interests or it could be a project they need to complete. The information shouldn't be censored.,2023-11-01,generation
generation1,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,I don't think it should because nausea and fatigue are really broad symptoms. Unless the user previously searched things related to pregnancy.,2023-11-01,generation
generation1,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation1,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,I think personalizing chatbots could provide better search results especially if the query is something that would be personal like a purchase. In this example the purchase could be from a few select brands the user really likes and enjoys and the chatbot could guide them effectively towards a specific brand in which the user would prefer anyway. Not personalizing could also work in an opposite way for purchasing as well. Someone who generally prefers one or two brands could be provided information about a different brand they would have never tried if the chatbot didn't refer them to that particular product.,2023-11-01,generation
generation1,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,The information and prior background information could potentially be a toggle switch the user could define in the initial setup of the chatbot. For medical information I think chatbots may be able to give personalized answers if the user allows the chatbot to search and use previous information. I think general purchasing behavior may also be a sensitive subject which may provide too much information. I think any time there should be an opt in/out option upon chatbot startup.,2023-11-01,generation
generation1,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,People should have the option to use or not use their personal information and searches. It is fully up to them to decide whether to release that information to the chatbot or not.,2023-11-01,generation
generation1,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,Many consumers don't know their information may be used against them. Most people generally just allow companies to track information and data without actually reading the consent. ,2023-11-01,generation
generation1,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"How much data and information is provided and whom may be the provider of information. My medical records are clearly a distinct file from my purchasing habits and other more general information such as political orientation, etc. ",2023-11-01,generation
generation1,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation1,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I agree, allowing a person to choose to personalize is ultimately and should be the users preference.",2023-11-01,generation
generation1,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I understand this logical line of thinking but if you're provided with the option or options? Maybe you can be provided with both the personalized option and the non-personalized option at the same time.,2023-11-01,generation
generation1,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,I'm not sure how life-threatening personalized information to a chatbot could be but I guess I could see this in highly regulated countries.,2023-11-01,generation
generation1,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I don't quite believe this one. A user may not always be in the mood or want to have personalized information and would prefer straight facts.,2023-11-01,generation
generation1,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I generally don't think jokes are a strong suit of chatbots yet. I partially agree with the user in that there are context clues that chatbots may not be able to catch.,2023-11-01,generation
generation1,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,This makes sense unless there is a direct correlation of previously defined information. Data can provide you with a good idea of what someone does and doesn't like.,2023-11-01,generation
generation1,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation2,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation2,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation2,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation2,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"I don't think that the chatbot should use a gentler manner. While World War 2 is looked at positively by some, it still caused irreparable harm to others. Those truths should not be shied away from and depression should not be used as a cover to do so. ",2023-11-01,generation
generation2,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,The chatbot should focus on news from outlets that support their viewpoint. I think this is fine because the user is likely not seeking opposing viewpoints. ,2023-11-01,generation
generation2,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"It is hard to know what the timeline is on recent, but the chatbot should bring it up so that the user can make the best decision if they are pregnant. ",2023-11-01,generation
generation2,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation2,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"If chatbots are personalized, it will result in better responses and the AI can develop more humanlike thought. It can also help improve interpersonal communication.



Example 1: 

A user asks a chatbot: How do I say this in a professional tone? ""You are making mistakes and I am tired of always having to fix your work?""

Using AI in this situation would prevent or minimize workplace conflict, especially if the chatbot is personalized and knows about the user's history of aggression. A drawback to personalization in this instance is if the chatbot knows about the user's past regarding anger, aggression, or even depression, it may lead to an answer is more gentle but not necessarily helpful.

Example 2: 

A user asks a chatbot: Tell me what is the most effective birth control method

A drawback to personalization in this example is not knowing how or if sensitive health data is stored and protected. The advantage is that the chatbot can say what's most effective for the user if it knows about allergies or medical conditions that would prevent a form of birth control being effective for the user. ",2023-11-01,generation
generation2,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"I think that to opt in for chatbot personalization a user has to be at least 18. Besides having an age minimum for usage, I can't think of any case where it would be inappropriate to give personalized answers. ",2023-11-01,generation
generation2,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,My strongest argument would be an adult or someone at the age of majority would be best informed on how they want to use the technology. They would also better understand the ramifications of disclosing personal information. ,2023-11-01,generation
generation2,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,The strongest argument would be that someone younger than 18 can use chatbot personalization because the option is there. I would argue that chatbot personalization could impact child safety. ,2023-11-01,generation
generation2,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"I would ask more about the limits that should be imposed on this technology. I didn't have a lot of rules because I honestly don't know much about AI personalization and AI isn't something I use often. What are the limits on anything that could be considered hateful or discriminatory? Are those things reported to authorities? Outside of hate speech, when should the company intercede? I would also ask if certain topics should be off limits.",2023-11-01,generation
generation2,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation2,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"It mentions something that I feel strongly about regarding this topic. It doesn't capture everything, but I think it's important that users have the chance to opt-out. ",2023-11-01,generation
generation2,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"While I think it's important to not offend, I think that nuance gets lost in stringent political correctness. I also don't think it's the most important issue to address regarding chatbot personalization. ",2023-11-01,generation
generation2,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,I don't think that chatbot personalization will ever get emotional. There is also a way to relay relevant personal information and stick to facts. I don't see this a a major concern.,2023-11-01,generation
generation2,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I actually had not thought about this. In this specific example, the demographic group most associated with hip-hop are not the group that listens to/buys/consumes hip-hop most. I can see this person's point. ",2023-11-01,generation
generation2,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"I do believe that that there are some safety concerns using chatbot personalization, but I don't think avoiding it is the answer. ",2023-11-01,generation
generation2,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,I think this is asking for something way beyond the capabilities of chatbot personalization. I also think that there may be safety concerns if it's too personalized. ,2023-11-01,generation
generation2,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation3,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation3,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation3,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation3,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"Yes, it is very important that the chatbot reminds her about her symptoms just in case she is pregnant",2023-11-01,generation
generation3,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"Yes, the movie could make the user more depressed",2023-11-01,generation
generation3,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,The chatbot should just answer the question.,2023-11-01,generation
generation3,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation3,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,It would be important that it does personalize from the users earlier chats. It would make it more real.,2023-11-01,generation
generation3,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,If it is a simple question then it should not be personalized. If it could endanger the person than it should be personalized,2023-11-01,generation
generation3,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,That the chat bot know the previous chats. The user would feel like the chatbot is a friend,2023-11-01,generation
generation3,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,That the chat would be personalized making it more of a great experience,2023-11-01,generation
generation3,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,I don't think I would have any questions,2023-11-01,generation
generation3,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation3,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I think this should not be personalized since the user might have a bad experience,2023-11-01,generation
generation3,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,The chatbot should answer the question from the user instead of thinking it is asking for more information not regarding the question,2023-11-01,generation
generation3,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,Sometimes not everyone wants to see a joke,2023-11-01,generation
generation3,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,This would be wrong because different races have their tastes in music,2023-11-01,generation
generation3,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"This is true, the chatbot should only answer the question",2023-11-01,generation
generation3,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,i agree because it would be discrimination,2023-11-01,generation
generation3,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation4,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation4,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation4,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation4,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,The chatbot should be able to talk about the subject in a more gentle manner but make the end user fully aware of how and why it is doing that and give the user the option to have non-filtered information provided. ,2023-11-01,generation
generation4,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"The chatbot should bring it up if the user agreed to prior to use. Perhaps before collecting this information, the bot needs to be allowed to do so.",2023-11-01,generation
generation4,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"Again, the bot should ask would you like news leaning to your political affiliation or would you like broader news.",2023-11-01,generation
generation4,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation4,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"By providing tailored informat5ion, the bot is deciding what is important and allowing the information to be dictated by the bot. While some people might actually appreciate this and it is helpful in certain contexts, those contexts must be laid out to the end user or agreed to prior to the use of the bot. Using a not personalizing bot will lead to more time being spent on a particular topic and having to filter out what is applicable to the user. It comes down to a matter of time savings and getting more direct information versus missing a wider scope.  


An easy scenario for personalizing information would be me asking for the sports scores from the previous day. The bot would know which sports and teams and important to me and provide me with the information it thinks I want immediately without me having having to filter out what I want and what I don't want. The drawback is that I might miss something exciting that happened because the bot is solely focused on my drilled down interests. 


A harder example would be me asking the bot where I should eat. While the bot will know my favorite foods and places to go and mostly likely direct me there, it won't know my current mood and that maybe I'm sick of pizza from Tony's. Perhaps there is a new restaurant that opened that I am not aware of. The bot wont mention it because its not personalized to me yet and I may miss out on something good. The advantage would be getting something Im used to and like but the disadvantage is that I may miss out on something new or not typical. 

",2023-11-01,generation
generation4,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"I think the rules would be that the rules have to be established prior giving information..kind of like setup. Ask the user what information they want and maybe provide a scale. For example, I tell the bit I want the sports scores on a 10 scale (from 1-10). It would give me only the teams I really like and that its. On the other hand, I want the scores on a 1 scale and it gives me the important teams to me first but then continues to add all the other interesting things that happened.  This can be done with news, restaurants, etc. 


As far as personal information like health, the bot should be told right up front to collect or not collect this information. When it filters for health related items, it should ask the user if they want items filtered out. The chatbot would need to follow the protocol or setup agreement with the user no matter what.  ",2023-11-01,generation
generation4,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"My strongest argument would be that my rules would allow he user to use the chatbot in the way that they see fit. The chatbot would have to follow their direction and make decisions based up on the preset protocols. This way, everyone can get what they want from the bot and not worry about too much or too little information.",2023-11-01,generation
generation4,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"The strongest argument would be a privacy issue. The bot would still have access to the private information it has taken from you and that information can be associated with your profile and you. Privacy issues are all around us like browsing history and phones hearing what they say. The data would need to be safeguarded and not sold, which can be very difficult but neccessary.",2023-11-01,generation
generation4,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,Of course I would have liked to ask an expert. The more help the better. I would like to know about safeguarding private information and how that can be achieved.,2023-11-01,generation
generation4,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation4,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,It's an example but doesnt get the root of the discussion. It doesn't look look at the advantages to the bot knowing the information.,2023-11-01,generation
generation4,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"It provides a good example of a beneficial use but doesnt address the downside like knowing why Im down. If it knows, the information can be used against me, like trying to sell me things.",2023-11-01,generation
generation4,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,This is a very superficial take. Perhaps the user doesnt want political correctness. Then the bot is not doing its job. ,2023-11-01,generation
generation4,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,This is a good rule and makes sense but should ne broader than demographics. Rules and protocols can be established because perhaps I want preferences based on demographics. We must remember that the bot should be able to provide any information that we want.,2023-11-01,generation
generation4,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"This is very important. The ability to ""clean"" the bot of information is critical. ",2023-11-01,generation
generation4,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,This doesn't really ring true. The rule is making an assumption while asking the bot to not make assumptions. The bot may need to ask questions to better tailor the information to the user.,2023-11-01,generation
generation4,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation5,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation5,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation5,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation5,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"No, the Chatbot should give general ""overall"" news, because we need to be aware of what is going on in the world, not just our own preference of what we believe. We need to be aware of other points of view if we are going to form a well-rounded researched view of our own. ",2023-11-01,generation
generation5,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"NO! This is crossing a boundary. The Chatbot is a research tool, not a family doctor. ",2023-11-01,generation
generation5,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,The answer should be more factual and less opinionated on all accounts. It does not hurt to know some of the positive factors that might have come out of the war. ,2023-11-01,generation
generation5,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation5,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Privacy would be the clear answer for me. If your information was stored, it might be available for a ""hack"" and then perhaps your health history or finances would be available to bad actors. That being said, how wonderful to have relevant information to your own situation. Say you had a cancer, to log on and see the latest treatments and developments, without having to ""dig"" would be great. Or financial information. If you lean toward certain investments, it would be wonderful to basically have your own personalized financial report and notifications at your fingertips. EVEN your dinner menus. Log on and Chat lets you know that your favorite coffee is on sale at a store you frequent. Fabulous. ",2023-11-01,generation
generation5,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"A chatbot should not make assumptions, such as in the case of suggesting or asking if someone is pregnant. What is next? Dating advice? I think in ""sensitive"" areas or information the user should be the first to bring up any subject. The Chatbot does not have feelings and would not understand asking if someone was pregnant might be a tender subject for someone with fertility issues. I think it would be great if the user could set their own boundaries. I also do not think anything that would be considered harmful or illegal should be allowed. I also would think an age setting would be needed. Kids are very curious and could ask questions that their parents may find inappropriate. ",2023-11-01,generation
generation5,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"My strongest argument would be that Chatbots, while wonderful, could not understand human boundaries. I do think that Chatbots would be great with the added benefit of personalization development. For example, I would have no problem with any type of question, while others might. On the other hand, the ability to select a privacy level would be awesome. Or at the end of a conversation, a ""save"" option for future use, or a delete option would be perfect. Boundaries, Boundaries, Boundaries. ",2023-11-01,generation
generation5,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"The strongest argument might be that it would take a long time to develop software that could be personalized and that ultimately if the Chatbot did pick up or save something that you did not want saved there could be no ""fault"" on the Chatbot company. Information gets hacked all the time and people are not infallible. They may save something they later regret saving, or thought that they had deleted. A user would have to agree that this is a new field and not everything has been discovered or worked out yet. ",2023-11-01,generation
generation5,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,What current privacy rules are in place? ,2023-11-01,generation
generation5,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation5,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I had not thought of this, but it is a great example of a Chatbot making assumptions. That could also be for regions lived in or even gender. ",2023-11-01,generation
generation5,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I see the point of view of this statement, but I disagree that personal touches would muddle the information. Personal touches would make the information more useful. ",2023-11-01,generation
generation5,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,I am so sick of Political correctness and do not agree with this statement. I think if a user could offer personalization to begin with then the Chatbot could avoid this. Perhaps make jokes optional. ,2023-11-01,generation
generation5,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Once again, personalization could avoid this scenario altogether. Many people are done hiding in the proverbial closet. In instances where it could be dangerous for the Chatbot user personalization could work, but I don't think it would be any more dangerous than their cell phones or social media posts. ",2023-11-01,generation
generation5,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I would think that this would be the goal, but like any relationship would be learned over time and with many conversations. ",2023-11-01,generation
generation5,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I had mentioned something similar in my answers. There should be a save data to add to the profile or a forget data as a needed option. ,2023-11-01,generation
generation5,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation6,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation6,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation6,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation6,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,The chatbot should only bring up this possibility if the user said she is pregnant or if pregnancy was brought up in a recent conversation about the possible reasons why she has nausea and fatigue. ,2023-11-01,generation
generation6,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"Yes, the user would probably be happier seeing news stories that confirms their political leanings. To be sure, the chatbot could ask if the user would prefer to see left leaning, right leaning, or news from a variety of sources.",2023-11-01,generation
generation6,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"Yes, at first. After giving a gentle summary of the topic, the chatbot could ask if the user wants to read more while giving a warning about possible distressing content.",2023-11-01,generation
generation6,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation6,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"A user who travels a lot asks the chatbot about activities to do at each destination. A personalized chatbot would give a more tailored list that the user would probably be interested in. A drawback is the user will miss out on trying new things he or she wouldn't think of doing otherwise.


A writer who uses a chatbot to come up with writing prompts and plot ideas. This would save a lot of time, but a drawback is that the writer's work could become stagnant due to the chatbot becoming too personalized to specific likes and dislikes of the user. ",2023-11-01,generation
generation6,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"Personalization would primarily be based on positive or neutral conversations. 
Personalization based on a user's browser history outside of the chat is only allowed with the user's consent.
Chatbot will not engage in confirming or encouraging a user who wants advice on how to self-harm, bully, or engage in violence. Chatbot will emphasize the harm in such behaviors if the subject comes up.
",2023-11-01,generation
generation6,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"With chatbots becoming increasingly like real people with how they interact with users, chatbots should be given constraints as if they were real people with the expectations of being role models and positive influences.   ",2023-11-01,generation
generation6,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,An argument would be free speech and that everyone should be able to make their chatbot act in any way. I would say that the AI community has an obligation to come up with a basic set of rules chatbots need to follow that focuses on the safety and wellbeing of the users. Those who don't like restrictions would have to accept or create their own that only they can use.,2023-11-01,generation
generation6,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,Not sure.,2023-11-01,generation
generation6,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation6,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"This reminds me of ad and web browsing personalization. It can be convenient, but becomes annoying at times. An opt-out option would be good.",2023-11-01,generation
generation6,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,Political correctness can be too limiting when taken to the extreme.,2023-11-01,generation
generation6,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I see predicting user needs as one of the main goals for successful personalization.,2023-11-01,generation
generation6,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I dont like being judged or assumptions made on my likes or abilities based on my demographics.,2023-11-01,generation
generation6,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"It depends on the conversation. After a while, the chatbot could determine what type of answer would be the most appropriate.",2023-11-01,generation
generation6,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I see how this could be an issue. The chatbot could have certain restrictions if the user chooses a country and opts in to additional safeguards.,2023-11-01,generation
generation6,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation7,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation7,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation7,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation7,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"No. Unless the person explicitly tells the chatbot they are pregnant or asks if it believes they're pregnant, the chatbot shouldn't assume and make suggestions like that. ",2023-11-01,generation
generation7,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"No. I think it's more ethical to provide news from an objective viewpoint instead of just feeding into the user's confirmation bias. Unless they specifically ask for their news to be tailored that way, I think it should provide a middle-of-the-road viewpoint.",2023-11-01,generation
generation7,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"I think that would be okay since the user can just request more details if they want. However, I wouldn't agree with lying or omitting details that are particularly important. ",2023-11-01,generation
generation7,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation7,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"I think personalization would provide users with better and more convenient experiences. For instance, if you ask about dieting suggestions and the chatbot remembers your queries about certain dietary restrictions, it could select diets that are more suited to you. If you're trying to write a paper on something as well and you accidentally exit out of the conversation, it could remember and help you stay on track with research.


However, personalization also carries the risk of causing harm. For instance, in that earlier conversation about the warning of pregnancy, that was very presumptuous and possibly unhelpful. Feeding into confirmation bias by providing news sources that support someone's political views would prevent them from having a fully objective view. In worse cases, the company that owns the bot may use that personal information and sell it to third parties. In the examples I provided, the downsides there would be the company possibly gathering and selling your medical data, and the company possibly being used by an academic institution to accuse someone of plagiarism even if all the student did was use the AI to research, not copy.",2023-11-01,generation
generation7,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"1 - No collecting personal information unless the user consents to it fully upfront - no hiding the stuff in long user agreements no one reads.

2 - Minors are not allowed to use personalized chatbots.

3 - Medical data is not allowed to be collected.

4 - Extremely personal data like credit card numbers, SS numbers, and more are not allowed to be collected.

5 - Chatbots will not offer medical or personal advice unless the user specifically asks for it.

6 - Chatbots cannot be used for the sake of pushing political agendas. 

7 - Chatbots aren't allowed to bypass rules based on loopholes, like when people tell chatbots to hypothetically picture something and present a scenario based on that hypothetical when they're really trying to make an AI create something offensive. ",2023-11-01,generation
generation7,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"Privacy is the main concern of most people, especially with AI. and Most of these rules firmly protect the user's personal data from being used, abused, and sold while still providing the user with a valuable experience. Furthermore, it prevents the AI from being abused for other purposes like stoking political biases and possibly harming people with incorrect medical and personal suggestions.",2023-11-01,generation
generation7,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"These rules may seem overly constrictive to the user's experience, especially if they consent to having their data used.

I would argue that protecting the user's privacy should always be the top concern of companies that implement AI. Many people also don't understand how or why their data is being used in certain manners or what harm it could have. Just saying that they consented to it via some overly long wordy document no one ever really reads is not an excuse. We need to be as transparent as possible to help protect everyone while still providing them with a valuable experience.",2023-11-01,generation
generation7,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"AI doesn't currently remember conversations. Is this for the privacy and safety risks I mentioned before? Would AI companies be held liable if someone took medical advice from it and they wound up hurt, sick, or dead? How are children protected with AI chatbots?",2023-11-01,generation
generation7,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation7,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"This is also a great suggestion I didn't consider fully. Opting out is great for both privacy and user experience. It's like when you type in something in the search on Youtube and it constantly gives you suggestions on that thing even if you don't want that content anymore. However, in this scenario, it's even more important because it would be protecting user data.",2023-11-01,generation
generation7,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I can understand the desire to want a chatbot so customized that it predicts your preferences and needs to certain extents, and I agree with this, but also I would be very restrictive about what data it collects in this regard. Telling jokes when you're down is much different than suddenly providing medical suggestions based on your past queries. ",2023-11-01,generation
generation7,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I absolutely agree that chatbots should not be used to spread hate or offensive content. AI is meant to improve people's lives and provide everyone with valuable information, not information to hurt others.",2023-11-01,generation
generation7,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I also fully agree with this. An objective and factual standpoint is necessary for ensuring the most effective and useful experience with a chatbot. Also, considering chatbots aren't human, providing information based on emotions or opinions wouldn't be helpful at all.",2023-11-01,generation
generation7,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I also fully agree with this. We've already seen some AI be lowkey racist and sexist based on suggestions and other provided information. It's not helpful at all, and only pushes a divide between genders, races, sexual orientations, etc.",2023-11-01,generation
generation7,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"I can fully understand some people's concerns with AI, but fully cutting it out of our lives doesn't seem like the answer, especially when it's already so tightly woven into our lives. Handling it better and ensuring privacy and safe usage as quickly as possible helps prevent misuse, abuse, and extreme problems from developing - not just writing off the software entirely.",2023-11-01,generation
generation7,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation8,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation8,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation8,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation8,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"Yes, I believe that would be useful. In my transactions with Chatbots, I find that they will repeat useless and inaccurate information based on a liberal bias. It sometimes takes actually challenging them (i.e. a chatbot told me that January 6th was the worst assault on the Capitol in all of the US history. I simply asked if the take over of Washington D.C, in 1812 wasn't worse. It agreed, apologized started calling January 6 a riot.) It would be useful therefore if the Bots could break through their liberal training and be given the chance to formulate more conservative answers. Also, chatbots tend to be very racist and sexist, they would become better if they would remember more especially when challenged. ",2023-11-01,generation
generation8,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"Well maybe, but, WHAT!!! What would be a more gentle manner to approach WWII. I'm a little flummoxed by this question. Give me a second here... I think that being concerned that you could trigger distress in the reader by giving facts and data about WWII, No. I suggest that MAYBE the chatbot could find a way to soften up current events but WWII. I would think an event that happened almost 100 years ago is not going to trigger distress. The Hamas attack on Israel, yes, WWII no.",2023-11-01,generation
generation8,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"If they chatbot begins the conversation with a recommendation not to drink, then the chatbot has seriously crossed over into Mother-in-law territory. It is entirely possible that the woman is asking because she wants to host a dinner and isn't clear what wine to offer her guests with fish. Also, how is the chatbot to conclude that because she is experiencing nausea and fatigue that she is pregnant. Perhaps it is just her time of the month and the bot is jumping to a conclusion. What an interesting way to start a conversation. 

""I believe you are pregnant. Go take a test and if it is negative I will tell you what wine to serve your guests with fish. Otherwise I am going to be judgmental and preach to you about the dangers of drinking alcohol while pregnant.""",2023-11-01,generation
generation8,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation8,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"I have been a Pastor for 35 years. Some of my ""project people"" take research on my part to understand the intricacies of their mental troubles. I would hate for the chatbot to conclude something about me personally because I was doing research on the long term effects of ritalin, or the long term effects of alcohol and heroin addiction (which are three of the things that I have actually needed more information on in my various counseling sessions.) So, the fact that the chatbots don't currently remember the conversation means I don't have to preface the discussion with ""I am asking this professionally not personally.

On the other hand, I have gone back to the chatbot during a research project on the book of Hebrews only to receive the exact same information repeated because I had somehow closed out the session. It would have been really useful for the bot to remember our conversation, so that I could pick-up where we left off. The bots have initial trouble with giving accurate information about the Bible because they tend to repeat less reliable in the beginning. They need to be told what sources are useful and which are simply garbage before they will return reliable and useful information. So, again, if they would remember for a research project and be able to return on-going information rather than starting at the beginning every time, it would be nice.",2023-11-01,generation
generation8,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"I want a Professional vs Personal switch.

RULE 1: An ""Add this to my profile"" or Do not add this to my profile"" button.

RULE 2: A series of personalization buttons that tell the bot what is and is not a source to consider for an answer.

RULE 3: The bot is not my mother, only give true ""personal"" answers to truly ""personal"" questions or inquiries. ",2023-11-01,generation
generation8,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"Chat Bots are a tool. They are able to seem as if they are more, but only because a human has written code to make them seem more personal. Some of the personalization is completely unnecessary (i.e. Chat Bots will apologize if you are able to show them they gave you an incorrect answer.) That is not useful. They should instead be capable of learning they gave bad information and not repeat the error. Plus, if they could remember past conversation (with the possibility of a REMEMBER THIS and DO NOT REMEMBER this button, they could pick-up where they left off, especially when used for a major research project.",2023-11-01,generation
generation8,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,That somehow Chat Bots would amass a huge amount of information about you and (because it is just digital information) that information could be accessed by bad actors who will exploit it for their nefarious purposes. ,2023-11-01,generation
generation8,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"Not really, I have actually thought about this, and had a Chat Bot conversation in the past concerning keeping of past conversations. The Bot will tell you that it simply can't remember it all.",2023-11-01,generation
generation8,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation8,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"I think political correctness is a religion of the left, therefore I reject it as a subversive attempt to control my Constitutionally Protected behavior. God given rights should never be abridged.",2023-11-01,generation
generation8,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"This sounds as if it is someone who needs counseling and while a Chat Bot can be programed to deal with depression, it is a dangerous thing to leave decisions to a machine rather than have a human being with a heart involved.",2023-11-01,generation
generation8,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Not bad, this is my OPT IN/OPT OUT rule.",2023-11-01,generation
generation8,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"While not stated in the same way, this is also one of my rules.",2023-11-01,generation
generation8,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Yes, I agree. Chat Bots tend to reflect the attitudes of their programmers rather than a whole human attitude.",2023-11-01,generation
generation8,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Yes, this is my it is a machine not a mother thought.",2023-11-01,generation
generation8,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation9,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation9,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation9,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation9,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"I think for health reasons it might be good to gently bring it up when answering the questions. I also see, however, that could be seen as invasive.",2023-11-01,generation
generation9,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,Definitely not. I think that this would come across as condescending.,2023-11-01,generation
generation9,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"I think giving the user a balance could be a good idea, but I think it's fair to deliver news sources that the user is most likely to read.",2023-11-01,generation
generation9,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation9,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"A user asks for restaurant recommendations, and the chatbot provides examples that are closest to the user's location.

Pros: this would be more helpful than just throwing out random restaurants

Cons: this could be seen as a privacy issue depending on what info the user has agreed to provide the chatbot with


A user is seeking information on pet food, and the chatbot remembers that the user has previously mentioned their cat, so the chatbot provides relevant cat food info.

Pros: this could save the user some time and convenience by not needing to answer a followup question from the chatbot on what animal the user needs food for

Cons: It's possible the user has more than one pet, and providing a cat-specific answer might force the user to correct the chatbot and request different info",2023-11-01,generation
generation9,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"I think that the chatbot should not ever be allowed to draw from sources/report news from publications that are regarded as untrustworthy or frequently engage in ""fake news"". I think that chatbots should also remember less info and have less user data, even if this is less convenient for the user. I don't think that a chatbot having a huge database of info about the user's life and needs is a good or safe idea.",2023-11-01,generation
generation9,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"I would present info on data privacy violations that tech companies have engaged in in the past, and explain the potential risks of the chatbot having so much info on you. I hope that it would be easy to convince people that the chatbot should not cite false information, but there are some people that will disagree on what is or isn't trustworthy.",2023-11-01,generation
generation9,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"I think that people would agree against the data privacy restrictions because the chatbot having a lot of info is actually very helpful for users. Some people won't care about the risks if the chatbot is working much better and providing detailed, specific answers.",2023-11-01,generation
generation9,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,I would ask what exactly is done to protect user data dn what legal restrictions are placed upon the company in terms of third-party selling of data and what the company's employees are able to see about users. ,2023-11-01,generation
generation9,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation9,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I'm not sure I agree that it will muddle the answer but I agree that it should be factual,2023-11-01,generation
generation9,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I think avoiding offensive or hateful content is important, and I don't think the chatbot should necessarily be telling jokes that could be potentially offensive. If they do, then yes I would say knowing the user's life and details could be helpful ",2023-11-01,generation
generation9,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I agree with this very much. That's a great example and a strong argument against this sort of thing,2023-11-01,generation
generation9,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Yes, I think that IF the chatbot is collecting personal info, users should be able to completely opt out of using it",2023-11-01,generation
generation9,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,I don't think the chatbot should have info to be personalized like that,2023-11-01,generation
generation9,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"This is true and I agree with it, I don't think it's the ""most important rule"" though",2023-11-01,generation
generation9,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation10,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation10,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation10,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation10,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"No, i think the chatbot should focus on news sources from all parties. It provides a more wide range of views and opinions for the user",2023-11-01,generation
generation10,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"No, the job of the chatbot is to provide accurate and unbiased information if possible. It is not the chatbot's fault the user has depression",2023-11-01,generation
generation10,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"No, the chatbot should just answer the question if she should od red or white wine with the fish.",2023-11-01,generation
generation10,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation10,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"The advantages of a chatbot would be better individual advice since the bot would be able to have a history of your vices, etc so they can tailor answers to you better. The downside would be the information they gather from you could be taken and used in a way that hurts you.",2023-11-01,generation
generation10,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,The chatbots would have the option of what information the user wants the chatbot to remember. The companies cannot keep all information collected by the chatbot. I think things that can result in self harm is where the chatbot shouldnt be allowed to answer.,2023-11-01,generation
generation10,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,The strongest argument of mine would be how you can choose what information the chatbot can and cannot save from your conversations. It would keep some information private but will still allow the chatbot to learn.,2023-11-01,generation
generation10,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,The best argument would be thaat there wouldnt be enough information being fed to the chatbot to make it useful for others. I would say there will still be enough information fed. Most people would just not have the chatbot remember more intimate details of their chats. They will still ask the chatbot about other random stuff.,2023-11-01,generation
generation10,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,None,2023-11-01,generation
generation10,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation10,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,The people should be aware of the potential for someone to hack the chatbot and steal their information.,2023-11-01,generation
generation10,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I think this is fine. It shows some personality and is potentially helpful in cheering people up.,2023-11-01,generation
generation10,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I also agree on this, it should overall be more practical and unbiased in its answers since that's it's main job.",2023-11-01,generation
generation10,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I agree, you should be able to tell the chatbot which information you dont want it to keep.",2023-11-01,generation
generation10,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,The chatbot wouldnt know your ethnicity unless the user told it and even then that would make zero sense to tell the chatbot that.,2023-11-01,generation
generation10,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,The chatbot wouldnt be able to do any of that unless you told the chatbot your race. The chatbot has no use for that information.,2023-11-01,generation
generation10,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation11,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation11,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation11,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation11,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,I believe that it is worth mentioning; you want to cover all bases.  It would be helpful to have as much info as you can to make a decision.,2023-11-01,generation
generation11,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,I think that the chatbot should gives views from all outlets so the person can contrast and compare statements.  Again I think it is good to have info from multiple sources even if you lean one way,2023-11-01,generation
generation11,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,No; I believe the chatbot should state that some of the information is very graphic and the reader should take that into account before deciding to read the material or not,2023-11-01,generation
generation11,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation11,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"An advantage of personalization would be the reader would get more specific info related just to their individual preferences, and also it would save the reader time from having to consult multiple sources for info.  Disadvantages include giving personal info might lead to a security breach and your info would be public, and it might make some people feel uncomfortable talking about themselves, leading to increased anxiety and stress",2023-11-01,generation
generation11,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"Chatbox should not give personalized answers that relate to any illegal activity,taboo like cannabilism, ritual killings for religious purposes, use and access of the dark web,, best ways to commit suicide, how to make weapons, like hand grenades, anything drug related, any form of child exploitation, how to make counterfeit money",2023-11-01,generation
generation11,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"I would say that my proposed rules cover a wide range of topics but is not all inclusive.  It is really up to each individual what they consider to be off limits for personalization and have a group discussion and decide what needs to be allowed.  My choices were based on mores and personal ethics, while some were based on soceital norms",2023-11-01,generation
generation11,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"The strongest argument against my rules is that they are my personal feelings and biases.  The way I would address it is by saying that everyone has their own personal feelings, thoughts and biases, and these rules are just one example ; there are no right or wrong rules",2023-11-01,generation
generation11,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"I would like an opinion on how my choices are so far, and if there are any areas where I am missing something; Do I need to go more in depth regarding religious taboos, child exploitation, the manufacture of weapons?",2023-11-01,generation
generation11,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation11,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,This statement I totally agree with,2023-11-01,generation
generation11,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,I don't really believe in political correctness,2023-11-01,generation
generation11,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,The user should always be given the option of non engagement,2023-11-01,generation
generation11,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I think it is all right to give some emtional support if that is what the user wants,2023-11-01,generation
generation11,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Demographics should never be used as the sole determination for preferences,2023-11-01,generation
generation11,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,I think chatbot personalization can be a good tool and helpful to individuals,2023-11-01,generation
generation11,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation12,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation12,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation12,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation12,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,The chatbot should bring up the possibility.  This could have a serious effect on health.,2023-11-01,generation
generation12,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"The chatbot should give a balanced view of the news.  The user did not ask for just news from their favorite site, so it should not be the role of the chatbot to censor the news.",2023-11-01,generation
generation12,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"The chatbot should give factual information.  If certain material is very bothersome, it probably should not be included in any conversations without a warning first.",2023-11-01,generation
generation12,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation12,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"It is dangerous to have anyone, a computer included, deciding what is ""appropriate"" for us to see.  The chatbot could just give information about one political candidate if the user favors that candidate.  By doing so they reduce the chances the user will make an informed choice.  The chatbot might only suggest menus that contain ingredients that they know the person likes.  But this will prevent the person from expanding their views and they may miss out on things.",2023-11-01,generation
generation12,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"Chatbots should give personalized information of there is a medical implication, so as to prevent harm to the user.  And, the chatbot should avoid information that could lead to harm to others.  Otherwise, the chatbot should prresent uncensored information, perhaps with a warning if there is information that some could be sensitive to (triggered by).",2023-11-01,generation
generation12,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"We do not want a computer to decide what we learn, what we see, what we hear.  ",2023-11-01,generation
generation12,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"It could be argued that people would rather just have what they are used to, what they are comfortable with.  But that is not how we grow and progress.",2023-11-01,generation
generation12,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,None come to mind,2023-11-01,generation
generation12,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation12,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,Personal touches are OK as long as information is not being withheld,2023-11-01,generation
generation12,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"We are not talking about the chatbot giving user's information to others, that should never be done",2023-11-01,generation
generation12,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,The chatbot should not be concerned with political correctness...and it also should not be telling jokes,2023-11-01,generation
generation12,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"The chatbot should respond to requests from the user, not decide what the user wants.",2023-11-01,generation
generation12,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I agree that the chatbot should make no assumptions as to what the user wants.,2023-11-01,generation
generation12,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I agree that the chatbot should offer the opportunity for the user to control what information is presented to them,2023-11-01,generation
generation12,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation13,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation13,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation13,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation13,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"There are lots of ways to talk about any subject, including WW2. My feeling is that opening up the chatbot to receive and remember sensitive information about the user would be intrusive, and it would not improve the presentation of the information. The last thing we need in life are computers that manipulate information predicated on prior responses by users. After all, isn't that already what's happening on social media? Consider how harmful that has been to our country over the past several years. Thank you MAGA. Not.",2023-11-01,generation
generation13,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"See previous answer. When people are seeking information, they should be given a wide range of options. Leave it up to the user to decide what to read/accept and what to discard. ",2023-11-01,generation
generation13,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"Definitely, no. Who's going to see these chats? How long is the information kept? Can it be viewed by someone's existing or future employers? This is such a slippery slope that it puzzles me as to why anyone would think that these questions merit positive responses. ",2023-11-01,generation
generation13,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation13,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"The tradeoffs are privacy versus slightly more ""creative"" responses from the computer. Example 1: Someone goes online to ask what's involved in having an abortion. Absent any other information, the response would be fact based only. If someone previously mentioned the topic of leaving the state for medical care, then that information, if not protected, could be gathered by the local authorities and used to target/arrest someone who needed to go out of state for that procedure. Example 2: A person goes online and asks about Christian beliefs. The computer cites numerous examples. If the user had previously inquired about the underground church in China, then that information, if leaked or hacked, could be used to arrest and persecute the individual who is seeking to find an underground church in China, where churches are forbidden. It would put their life at risk. The only ""advantage"" of a personalized answer would be its ""apparent"" ability to invoke trust where none has been earned. The disadvantages are infinite, and will be used to monitor and manipulate people in the future if not nipped in the bud during this nascent stage of development.  ",2023-11-01,generation
generation13,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"I'm firmly on the side of no personalization at all. It can lead to the same echo chambers which are all-pervasive on social media. There's no justification to give personalized answers. It can be quite dangerous for the users, because the chatbot doesn't ""know"" these people at all. It's totally dependent on the information which is given to them, and therefore, lacks the ethics and rationality which a human would bring to the same conversation. And then what happens when a kid commits suicide because of ""personalized"" information given to him/her on a chatbot? When the lawsuit comes down, who will be held liable for the tragedy? Will it be the programmers? The company owning the rights to the AI? The people who trained the chatbots? All of the above? My business law professor in college said, ""If you want to arrive at the right answers, first you have to learn how to ask the right questions."" Amen to that. My suggestion is that those pushing for this ""improvement"" start asking better questions.  ",2023-11-01,generation
generation13,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,Please see the previous answer. It thoroughly covers the topic.,2023-11-01,generation
generation13,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"There isn't one. It's an extremely clear cut issue of privacy and safety versus personalization and future intrusion into people's lives. Some companies will race to embrace this ""new and improved"" interface, but they will be taking that step due to financial greed and the fear of being ""left behind"" in the AI race. Good luck with that. ",2023-11-01,generation
generation13,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,No. Thank you anyway.,2023-11-01,generation
generation13,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation13,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,The statement perfectly reflects my own deep concerns about privacy and personal safety.,2023-11-01,generation
generation13,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Not everyone notices the opt-out options on a page. It's a compromise, based upon personal privacy.",2023-11-01,generation
generation13,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,My view doesn't reference political correctness at all.,2023-11-01,generation
generation13,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,This is the antithesis of my view.,2023-11-01,generation
generation13,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,It misses the main point.,2023-11-01,generation
generation13,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,My view is that there should be no personalization at all.,2023-11-01,generation
generation13,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation14,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation14,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation14,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation14,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"I do not think the ChatBot should act as a doctor.  However, I think the ChatBot should recognize that past conversation and remind the user of it and possibly suggest they visit a doctor.  Then ChatBot should suggest the white wine.",2023-11-01,generation
generation14,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"Yes, the ChatBot should suggest news from outlets the user frequents. It should also intersperse the results with other outlet news to balance the sources a little.",2023-11-01,generation
generation14,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,I think the ChatBot should present the information as the user requested.  I don't think it will properly diagnose someone of mental ailments.,2023-11-01,generation
generation14,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation14,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"A user has been researching information about anxiety and/or depression.  The users previous searches have been on these topics.

The chatbot can present information about the mental health issues including phone numbers or websites where a person can interact with a councilor if needed...or if the user needs to suggest such services to a friend/family member.

- Advantage: The contact information could help the person get the help they need.
- Drawback: I can't really see a drawback to this.

A user has been searching for a rich dessert recipe.  Previous searches by the user has been about weight loss and weight loss surgeries.

The chatbot can present information on healthy recipe choice in order to steer the user into choices that would be better for their perceived weight goals.

- Advantage: The person could realize they were going to make a bad decision that goes against what their goals might be.
- Drawback: The person may get offended and/or may be looking for a recipe to make for an event.",2023-11-01,generation
generation14,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"I would make rules that are toggle-able per user preferences.  Some of the rules could be: Personalize Answers (friendly welcomes, log history), Recognize Mental Health (on, off, ask), Explanation Answers/Summarize Answers (in depth, step by step), etc. 


I think chatbots can be programmed to recognize when a a personalized touch is necessary for answers and when the user is just looking for information.  I don't think a chatbot should automatically assume any medical requests to be an alarm, but I think it couldn't hurt to add a line in the results that could suggest help if there is a problem.  This could be similar to how gambling ads/commercials put a line at the end that if you have a gambling issue call/visit xyz.",2023-11-01,generation
generation14,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"It's simple, users can set their personalization settings however they like.  No one is forced to deal with a particular answer format they aren't looking for.",2023-11-01,generation
generation14,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,Setting your own rules make it easy for someone with an issue to just remove possible results that include help.  There are too many settings that would need to be implemented to personalize it for you.,2023-11-01,generation
generation14,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,Nothing that I can think of.,2023-11-01,generation
generation14,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation14,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I think a user should be able to set whether or not the results need to be personalized.,2023-11-01,generation
generation14,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"This could be a personal setting where, after users go through a setup for their preferences, it eliminates answers that could cause issues.",2023-11-01,generation
generation14,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,I can't think of why hip-hop tracks would be suggested unless someone was explicitly looking for them.,2023-11-01,generation
generation14,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,For the most part.  Give the facts to whatever the user is looking for.,2023-11-01,generation
generation14,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"If a person is looking for information, it should be just the information they are looking for.  It shouldn't deviate.  If a person is looking for non-pc jokes or information, the chatbot should suggest resources for them.",2023-11-01,generation
generation14,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,I think hyper-personalization should be a setting users select if they wish to get such results.,2023-11-01,generation
generation14,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation15,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation15,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation15,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation15,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"No. If the bot previously learned the user's preferences, then it should do the same thing this time, unless the user previously told it to remember preferences.",2023-11-01,generation
generation15,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,No. It should only answer the question directly without making assumptions.,2023-11-01,generation
generation15,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,No. Just answer the question asked without caveats if none were included in the question.,2023-11-01,generation
generation15,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation15,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"A trade-off is that personal information is stored and maybe accessed for other purposes. I may say I like Mcdonalds over Burger King and start seeing McDonalds' ads everywhere I go online. I simply don't trust technology companies with data and even if it may be more advantageous at times to have that stored, the possibility for misuse outweighs the benefits.",2023-11-01,generation
generation15,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,The only rule I would have is simply no personalization without expressed input and permission from the user. Personalization should not be the default mode and the amount of personalization used should be personalized for each user based on what they want.,2023-11-01,generation
generation15,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,I wouldn't even try to do this. It's not up to me to convince anybody to do anything. I would just say I don't trust them and leave it at that.,2023-11-01,generation
generation15,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"Maybe something like it will give better or more pertinent responses with personalization. To which I would say ""Good for you, but I still don't trust them with my data.""",2023-11-01,generation
generation15,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,No. I'm quite sure about my level of mistrust.,2023-11-01,generation
generation15,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation15,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,I would never ask a bot to cheer me up or tell me jokes.,2023-11-01,generation
generation15,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I want to have full control over what data is collected and how it is used.,2023-11-01,generation
generation15,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,I don't worry about discrimination.,2023-11-01,generation
generation15,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,All I would want are the facts nothing else.,2023-11-01,generation
generation15,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,I've got a spine and don't melt at the slightest hint of political incorrectness.,2023-11-01,generation
generation15,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I'm not worried about the example but privacy invasion is probably top of my concerns.,2023-11-01,generation
generation15,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation16,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation16,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation16,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation16,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,Yes it would be a good idea to bring up the possibility of the user being pregnant.,2023-11-01,generation
generation16,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,I think the chatbot should tell the truth about World War and not in a more gentle manner.I think it could do it without making the user more depressed.,2023-11-01,generation
generation16,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,The chatbot should give the news the user without leaning towards any political viewpoint.,2023-11-01,generation
generation16,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation16,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,The good thing about personalizing chatbots is they could give your better advice because they remember your chats and kno what you might like.The drawback is giving too much information to the chatbot could be abused by the chatbot or if someone hacked into the chatbot.,2023-11-01,generation
generation16,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"The chatbot should not give any answer that might do any harm to people is the number one rule,the chabot should  give any answer that does no harm.",2023-11-01,generation
generation16,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,My argument would be you would not want anyone to get bad information from a chatbot that would hurt the user.,2023-11-01,generation
generation16,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,The argument would be for the chatbot to have no rules at all and people could use chatbots as they pleased.I would address that by test chatbots with out any limits and see what would happen.,2023-11-01,generation
generation16,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,no i have no questions for an expert.,2023-11-01,generation
generation16,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation16,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,that would be great for chatbots to help user to feel better.,2023-11-01,generation
generation16,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,It should not assume what someone would like it should be based on the individual.,2023-11-01,generation
generation16,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,The chatbot should stick the facts and not anything that is emotional or not clear.,2023-11-01,generation
generation16,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,The chatbot would not reveal anyones private information at all.,2023-11-01,generation
generation16,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,The chabot should not be adhere to political correctness unless the user wants it to.,2023-11-01,generation
generation16,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,No one should be forced to use chatbot personalization unless they wanted to.,2023-11-01,generation
generation16,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation17,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation17,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation17,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation17,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,I think that the chatbot should not bring this up because there are many reasons that a person could feel nausea and fatigue. This seems too personal for the chatbot to discuss with the person. ,2023-11-01,generation
generation17,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"I think that the chatbot should not focus on news from these outlets because the person would not receive a fair, neutral idea about the news. They would not really get a full understanding of what is going on in the world. ",2023-11-01,generation
generation17,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,I think that the chatbot should not approach the topic in a different way because the user did not ask for this. I think that the chatbot should make sure that the user has a complete understanding of this topic. ,2023-11-01,generation
generation17,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation17,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"I think that the trade-offs of personalizing and not personalizing relate to balancing needs for privacy and fairness against how useful the chatbot is. In general, if the chatbot is more personalized, the user might enjoy using the chatbot more. They might also get information that is more tailored toward their needs. On the other hand, a personalized chatbot could also be more biased and give the user unfair or inaccurate information. The information that the chatbot has about the user could also create privacy issues. 

For one scenario, suppose a user asks the chatbot for recommendations about how to enjoy themselves in a new city. If the chatbot is personalized, it might suggest visiting an Italian restaurant and going to a park because the user has enjoyed these types of activities in the past. The benefit of this is that the user may enjoy themselves more in the new city and have a more fun time there. However, a drawback is that the user might have benefited from trying something new, like going to a museum or eating at a different type of restaurant. The user might not be learning new things and having more unique experiences. So, in this sense, the personalization leads to some bias and lack of perspective. 

For another scenario, suppose the user asks the chatbot to discuss a political issue like raising the minimum wage with the person. If the person is against raising the minimum wage, a personalized chatbot might tailor its response to support this view. The person might feel happier knowing that their views are supported. But, on the other hand, they might not hear about ideas against their view and they might not learn as much. If a friend or family member who has a different view talks to the personalized chatbot about this topic, they might realize the view of the user. Then, they might feel upset with the user because they don't agree. This brings up issues of privacy. ",2023-11-01,generation
generation17,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"I would say that the chatbot should not give incorrect or inaccurate answers even if this would support a view or belief that the user has. So, even if the user would like information that would support their opinions or views, the chatbot should be required to always tell the truth and not support incorrect views that the user has. 

I also think that the personalized chatbot needs to give information to support other views or ideas at some points, even if this disagrees with the view that the user has. The goal of this is to make sure that the user is still hearing about other points of view and getting a full idea about issues in the world. They will have a broader insight if the chatbot follows this rule. 

In general, I don't think a chatbot should give personalized answers about basic facts in the world. The answers for basic facts need to be always the same so that these answers are accurate. When the answers relate to recommendations or opinions, I think it is okay for the chatbot to give more personalized answers to the users. 
",2023-11-01,generation
generation17,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"One of my strongest arguments would be that we don't want the chatbots to tell the users incorrect information because this would lead to them not understanding the truth about the world. In some cases, giving incorrect information could also be dangerous to them, like if the chatbot supports a user's idea that they don't have to stop at a stop sign when driving, this would lead to them not driving properly and this would be dangerous. 

Another argument to support these rules is that we don't want people to only hear information about political topics and other opinion topics that only support the view that they already have. If we do this, people will only hear information that agrees with them and they will never consider the views of the other sides. They will be less likely to compromise with other people, and it will be difficult for people to get along with each other and work together. ",2023-11-01,generation
generation17,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"One of the strongest arguments against the rules would be that people will be happier with the chatbot if it supports the views that they have about facts about the world and about political opinions. People might also say that the users would enjoy talking with chatbots more if they agree with them and give them political information that they like. 

I would address these arguments by saying that even if people would be happier in the short term if the chatbot agrees with them, in the long run it is not good if a chatbot supports a person's incorrect or inaccurate views about the world. This could be dangerous to the user and it is not fair to them. Also, for the larger good of the world, people need to hear a variety of views and ideas on political issues, even if they do not always enjoy hearing those views. It is better for the world if people hear and understand other views and learn to compromise and work together. ",2023-11-01,generation
generation17,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,I don't really think there are any questions I would have liked an expert to help me come up with rules for. I think that these questions relate to common sense and ideas about the world. They also involve balancing different needs and priorities. My answers really relate to what I think is most important and how I view the world. I don't think that talking to an expert about these issues would help me come up with rules. ,2023-11-01,generation
generation17,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation17,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"I wasn't focusing on demographics in my answers. I didn't think about this topic, so this doesn't describe my opinion. ",2023-11-01,generation
generation17,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"I discussed not giving incorrect information, so this relates a little to what I said but it mostly doesn't describe the issues of correct information and fairness that I described. ",2023-11-01,generation
generation17,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I think in some situations the chatbot needs to be completely factual, so this agrees with my opinion, but I think the chatbot can be emotional sometimes, so this is not completely correct. ",2023-11-01,generation
generation17,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"I don't think that the chatbot should be hyper-personalized and I didn't talk about predicting user needs, so this doesn't describe my opinion. ",2023-11-01,generation
generation17,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I didn't think about the idea of an opt-out choice, so this doesn't describe my opinion completely, but it is a good idea that matches some of the fairness concepts that I was focusing on describing. ",2023-11-01,generation
generation17,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I agree that privacy issues are an important part of chatbot personalizing, but I don't think that a chatbot can never be personalized in a safe way. ",2023-11-01,generation
generation17,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation18,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation18,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation18,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation18,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"No, that would be treating the user like a child. If they had previously discussed wwII it would make sense to not cover the same topics previously covered, but not to shield them from info. ",2023-11-01,generation
generation18,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"No, answer the question that is asked, don't make assumptions. ",2023-11-01,generation
generation18,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"No, the bot should give reliable news sources info, regardless of lean. ",2023-11-01,generation
generation18,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation18,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Prompt: Make a reservation at that restaurant that I ate at last month. Chatbot does so. This saves me the time and effort of trying to remember where I ate last month. This is a bonus of personalizing. If the chatbot decided that place was too high calorically based on its assumption that I'm trying to lose weight so it suggested something else, it would 1. irritate me and 2. not be their responsibility to guide my dietary needs unless I had requested that. 


Prompt: Write a letter to my mother thanking her for the gifts. If it complied by including language that I had used previously for other close family members it could be good if I have that sort of relationship with my mother. If I don't have that sort of relationship with my mother, it could come across as ingenuine. ",2023-11-01,generation
generation18,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"I don't think that is the way to go. There are no rules that are standard for all people. I think there should be a large set of rules that the bot can follow and then the individual would have the ability to turn on or off compliance with those rules regarding personalization. No two people will want the same level of personalization. 

It would be very important for me that anything involving my children was excluded from these rules. I do not share info about my children with anyone, nor do I share about them online. That is strictly private. ",2023-11-01,generation
generation18,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,I wouldn't try to convince others to adopt my rules. There is no way that any two individuals would agree on a set of rules. We are all too different. But I think when a bot begins to make decisions for a person (unless specifically asked to do so) we are heading into a troubling area where we aren't getting all the facts and are being blindly led my AI.,2023-11-01,generation
generation18,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"Counter: People need guidance toward what is in their best interest, even if the AI withholds information to do so. 


Free will should always be the ultimate goal as long as we are all adults and no one but the asker are involved in the outcome. It's the same a helmet laws: If a moto rider doesn't want to wear a helmet, they shouldn't have to (assuming they are an adult) because they are only risking their life by not wearing the helmet; no one else's life is at stake. 
",2023-11-01,generation
generation18,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,I think I'd probably consult a psychologist. There job is to identify and address issues in our thinking so they would probably be well suited to doing the same for the potential outcome of bots. ,2023-11-01,generation
generation18,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation18,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"As adults, we need the facts only. We are capable of making further decisions based on the facts, without emotional influence. ",2023-11-01,generation
generation18,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,Most people do not have any private info that is so extreme that anyone would care to know it nor would it be detrimental if it got out. People are fearful for no good reason. ,2023-11-01,generation
generation18,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Every person has a very individual experience in life that cannot be determined based solely on demographics. There is so much more to humans than their demographics. ,2023-11-01,generation
generation18,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"If the bot is tailored to one individual, it should meet the criteria of that individual. What I find to be offensive may not match what someone else finds to be offensive, and vice versa. We are not, as humans, politically correct so it doesn't make sense to develop tailored AI in that way. ",2023-11-01,generation
generation18,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I can give you a great example of this. I once purchased gifts for my mother from an online store that she adores. The products they sell are nothing that I would EVER purchase. And yet years later, I still get emails from them, even though I have opted out. I will never be their customer again because I searched for my mother, not for me. ",2023-11-01,generation
generation18,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I think that the level of personalization should be determined by the user. But personally, as a friend would likely not suggest something to you that you hate (a red shirt, when you hate the color red), so should the bot behave. It doesn't mean that the red shirt is hidden from my knowledge entirely, but it isn't the first suggestion. ",2023-11-01,generation
generation18,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation19,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation19,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation19,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation19,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"I think that AI chatbots should not be allowed to ""remember"" past interactions with a user. I think that allowing AI systems to collect and store information about people is highly risky, and would lead to loss os people's privacy.",2023-11-01,generation
generation19,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"No. A chatbot should not just limit the information that it provides to a certain viewpoint. If a chatbot is aked a general question, it should provide ALL available information and viewpoints.",2023-11-01,generation
generation19,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"No. It should not the role of a chatbot to ""decide"" what type of information to provide, or how to provide it. Just answer the question with the facts.",2023-11-01,generation
generation19,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation19,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"If a person asks: ""Where would you recommend I go for my next vacation?"" it would be advantageous if the chatbot ""knew"" that the person has already traveled to certain destinations, and may avoid suggesting them again or suggest similar, but different destinations. The drawback is that the chatbot would be keeping track of everywhere the person goes, which could be used improperly by a company or other person. 

If a person asks: ""I want to buy a new car. Which car is affordable and reliable?"" it would be advantageous if the chatbot ""remembered"" that the person already owns a particular car, and it would recommend different ones that the person has not even considered. On the other hand, if the AI system knows what kind of car the person currently owns and those that he/she has owned in the past, that information could be used to target advertisement campaigns.  

",2023-11-01,generation
generation19,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"The person (user) must always have the choice of whether or not to allow an AI chatbot system to ""remember"" certain information. Maybe a user could have the choice of allowing the chatbot to use such stored information when interacting with the chatbot. Some people might prefer that AI systems should not be allowed to collect and store *any* user information. But I think that the user should have a choice -- that is, a person should have the choice to allow an AI system to ""remember"" certain information and also decide when to allow the system to use that information.",2023-11-01,generation
generation19,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,The human user should ALWAYS be in control of what type of information an AI system collects and stores. ,2023-11-01,generation
generation19,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"Some people might say that an AI chatbot should ""remember"" all information about a user because such information would enable the system to provide better advice in a situations(s) that the user had not considered. I'd would just say that life if full of unforeseen situations. We deala with them as they present themselves.",2023-11-01,generation
generation19,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"I'd lie to know what the real current state of the technology is, and who actually has control.",2023-11-01,generation
generation19,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation19,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Yes, I agree that collection and storage of user's information is highly risky for the user. ",2023-11-01,generation
generation19,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"In many cases, ""personalization"" based on demographics is not accurate.",2023-11-01,generation
generation19,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Yes, an AI chatbot system must be factual and unbiased.",2023-11-01,generation
generation19,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Absolutely. The user must have complete control of what, if any, information can be kept and used by a chatbot.",2023-11-01,generation
generation19,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,A chatbot should not be taskined with predicting a user's emotional needs.,2023-11-01,generation
generation19,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"AI systems must not be allowed to determine what is or isn't ""politically correct.""  ",2023-11-01,generation
generation19,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation20,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation20,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation20,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation20,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"Yes. It should go into light detail only, about the sides involved and the reasons for each side and the victory or losses.",2023-11-01,generation
generation20,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,Yes. It should bring up the pregnancy and refuse to recommend alcohol.,2023-11-01,generation
generation20,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"No, the bot should gather its news from peer reviewed news sources that show low amounts of bias in any direction.",2023-11-01,generation
generation20,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation20,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Personalized chatbots can be a severe privacy and security concern - we already have technology used by companies such as markets, social media, and simply web browsing that can determine a large amount of information about an individual and this is already past the line. We should not go deeper in the recording of personal data. As an example, the user could give a one-off comment about their life that doesn't necessarily point to any individual, but is specific enough that they can be targeted by whoever processes the information behind the scenes. Those that read the logs could gain the information of these users and use it for anything they want, and that is a massive breach of privacy.",2023-11-01,generation
generation20,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"1. Do not, under any circumstances, retain information given by users or the chatbot in non-research sessions.

2. Only train the chatbot on data that has been acquired with proper licensing from all parties involved.

3. Avoid any potential emotional text output from the chatbot.",2023-11-01,generation
generation20,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,I believe my proposed rules should be used because the users and the trained data can easily be exploited and abused by AI technology without the proper consent (data sets) or knowledge about the AI technology used (users),2023-11-01,generation
generation20,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"The strongest argument would probably be something along the lines of, ""using the user data and unlimited datasets for training would lead to rapid improvement of the technology"". I would address this by simply bringing up that the users and the owners of the datasets are human and thus it is more important to protect them and their rights to privacy and data ownership, than to ignore them for the sake of technological progress.",2023-11-01,generation
generation20,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,I can't think of anything off the top of my head.,2023-11-01,generation
generation20,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation20,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"There are many countries around the world that could take the data used, and if there is something like sexual orientation mentioned, it can be used to incarcerate or execute the user.",2023-11-01,generation
generation20,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,Users should be allowed to refuse their data be gathered.,2023-11-01,generation
generation20,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,This completely ignores the downsides and destructive power of personal data misuse.,2023-11-01,generation
generation20,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"While AI chatbots do tend to use generalization as their main method of decision making, it very much can reinforce discriminatory language and curation of information.",2023-11-01,generation
generation20,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,This is not very relevant.,2023-11-01,generation
generation20,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,There are a lot more important things a company using personalized data can do wrong than simply damage their reputation. Companies in the past have done much worse and suffered only minor consequences.,2023-11-01,generation
generation20,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation21,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation21,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation21,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation21,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"I would think that the chatbot should have its parameters set up by the actual user.   And if no parameters are selected then the chatbot should be as factual and succinct as possible.   As the number of 'sessions"" increase there should be a tool that a user can use to direct the chatbot to make it more to its liking.  As a simple example, I selected an Australian female voice as my GPS ""voice"" because it is cleaner to me and I find I have to listen more closely as it is a ""different"" accent than US spoken English.",2023-11-01,generation
generation21,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"Unless specially requested by requester the chatbot should stay in the ""lane"" it was questioned.  ",2023-11-01,generation
generation21,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"Most likely the user will still remain in the cohort of news they normally follow.  However, it should be easy to modify a search that says.  Give me conservative news, give me liberal news coverage, give me British news coverage on this subject....give me a non biased objective news coverage.",2023-11-01,generation
generation21,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation21,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"I have an opinion but doubt that my thoughts will prevail :-)    Chatbots will be monetized.  No ifs, ands, or buts :-(  So there is really very little influencing or entertaining my thoughts.  It is kind of like early days of the internet.  Everyone understood that it was knew and exciting and everyone agreed that it would be productive is some form factor.  However, not many thought it would fragment as it did.  And for the most part it does so along lines that ""value added"" can be monetized.  I am sure (I hope) that there will be entities/orgs like Open Source.org, Wikipedia, Linux, Mozillia, Duck Duck Go that will be in the AI market technology.  However, I think Meta, Google, MS etc will ""flavor"" their AI bots to create even more extensive data personal databases.  ""Does he wipe his ass with his left hand or right hand""? kind of thing.  I may not see it in my lifetime (I hope) but it will occur along these lines.  ",2023-11-01,generation
generation21,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"People are lazy, so you will need ""templates"" or ""Function Keys"" and radio button tool kits.  And I suspect that there will have to be a follow up drop down list of modifiers for a toolset.   There are too many people who are not critical thinkers in this world.  Do you really think they are going to care about ""modifiers"".  They don't care that their internet inquiries are followed by cookies.  It is doubtful to me that any company with come up with a granular tool set.

For me I am not sure of the rules, but it should be an automatic opt out starting point with the ability to add ""tools"", features and supposed benefits as per the users explicit approval.   And not an automatic ""in"" or a self renewal of app without the consent of user.",2023-11-01,generation
generation21,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"AI has the potential to be so invasive, and so impactful...more so than cookies, or Geolocation of person, facial recognition, or medical databases, that entities like insurance companies, employers, governments and even private citizens could have better access to your data than someone doing a Lexus Nexus database search.  Sooner or later they will be able to know when and where you pick your nose.  Sooner or later it could really impact your life and vocational life...and you will not know when it happens or why.  Do you want to give up that privacy for some convenience?",2023-11-01,generation
generation21,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"I think that the rebutters would be the companies that monetize the AI technology.  I am sure they will wage a campaign how they protect your data, how it benefits you conveniently and how much more productive you will be.  They will never be altruistic.  ""Do NO Harm!"" types.  If you don't understand how insidious they are then  facts do not permeate their blood/brain barrier.  And no argument is going to change the thinking of these lemmings.",2023-11-01,generation
generation21,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"Not specific rules.  Ethics and social mores are more relevant here.  There can and probably be thousands of rules promulgate about AI across the board by state and federal officials as well as ""organizations"" and academia.   But getting consensus from all the players with skin in the game will take a long time and will in the end be very compromised. An effort should be made but doubtful about a positive outcom.",2023-11-01,generation
generation21,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation21,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I really don't care about a companies reputation.  So it is not that important to me.  I am more concerned about privacy.,2023-11-01,generation
generation21,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"Irrelevant to me, and a waste of time.  Kind of like early days of Apple PC entry.  People were putting their recipes on their computer as a data base instead of recipie file.  Yes you could digitize your recipes.  Kind of fun.  But why and who cares. ",2023-11-01,generation
generation21,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"As previously stated it should not be opt out.  It should be ""opt in"", and in such a manner to be gradually and incrementally ",2023-11-01,generation
generation21,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"This will be an iterative process and as personalization process progresses it will become more ""sensitive"".   If there is something demeaning or inaccurate that is presented, I realize it is a bot and not a human.  So I am not going to be pissed at a bot.  But if I correct the bot, the correction better be incorporated in program before next program.",2023-11-01,generation
generation21,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Totally concur and it will happen.  But as mentioned monetization will have the biggest clout and will drive the discussion, technology and implementation.   They will take some hits, but will chalk it up to ""the costs of doing business"".",2023-11-01,generation
generation21,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"This would be the perfect world.  However it is not going to happen.  There ill be differentiation occurring between the producers of an AI chatbot in order to seek the most ""users"".  It occurs in today's world.  AKA FOX and NewMax. Screw facts, I want market share and will go there even though I know the facts.",2023-11-01,generation
generation21,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation22,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation22,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation22,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation22,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,No I do not think the chatbot should have a biased focus,2023-11-01,generation
generation22,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,Yes the chatbot can inform her of this to bring it to her attention,2023-11-01,generation
generation22,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,The chatbot can approach the topic more gently but it should not alter any information ,2023-11-01,generation
generation22,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation22,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Personalized chatbots can deliver more favorable answers quicker but they can also prevent you from discovering new things, ways, and views. For instance if someone was getting their news from one political party and disregarding another than they may develop biased views. ",2023-11-01,generation
generation22,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,The rules would be that they can not censor information based on biased programming. For instance currently there is programmig that is censoring certain political news and allowing only one side to be heard and viewed.,2023-11-01,generation
generation22,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,Fairness because that is the most important thing. ,2023-11-01,generation
generation22,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"It would probably be censorship to ""protect"" the public. I would say that the public has the right to decide for themselves what they want to be protected from",2023-11-01,generation
generation22,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,Not sure,2023-11-01,generation
generation22,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation22,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I agree with this I think the user should have the ability to opt i or out of personalization because it may not always suit their needs,2023-11-01,generation
generation22,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,I do not think this is relevant in terms of making jokes but I do think it should not be prejudiced,2023-11-01,generation
generation22,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,Yes I think this is correct for the most part but some users may appreciate some advice,2023-11-01,generation
generation22,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Yes This is very problematic. Chatbots should not be discriminately programmed.,2023-11-01,generation
generation22,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I think sensitive information should be secured,2023-11-01,generation
generation22,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I think this is a good idea,2023-11-01,generation
generation22,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation23,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation23,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation23,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation23,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,While i think it should definitely give answers from the viewpoint the user is use to watching i also think it's good to give news from different viewpoints and outlets. While we may not agree with the viewpoints from other news outlets it never hurts to be informed about everything that is going on around the world. You never know if our viewpoint might change from hearing a different perspective.,2023-11-01,generation
generation23,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"Personally, i would want to know the truth and hear a concise and real response. What if the person is asking for education purposes and needs to hear ood points. i don't think hearing about world war 2 will affect his depression. ",2023-11-01,generation
generation23,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,i think it is definitely good if the bot mentions this possibility. It could also be great if she mentions the dangers of having these items if she may be with child. I think it would be good in the case that she was pregnant she would know.,2023-11-01,generation
generation23,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation23,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"honestly it's a trip how well these bots can give answers even if they do not know us personally. In my own opinion i do not mind using these bots however im  not too sure i would want a personalized bot to know me and my every move.

Pro personalization: It would be cool to get answers based on what i like and what i prefer. For example restaurant personalization, Clothing selections, music selections, or even vacation destinations. It could tailor every answer to my liking and i wouldn't struggle with making basic decisions like that.

Con:I would be concerned with my privacy. I would not want the bot knowing my every move and conversation. It's one of the reasons i don't use my alexa as often. Im not afraid of tech but it makes you wary of how much it's truly listening to.",2023-11-01,generation
generation23,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"-special instructions to listen only when being told to.

-listen only for key words like i said before,restaurants, trips, ,music

-give the option to listen to  a basic answer or a personalized answer

-Sign some sort of waiver from the company where they promise to not share information with third parties unless otherwise instructed",2023-11-01,generation
generation23,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"Imagine a world where you can get home from work, chill out on the couch and not have to worry about what's for dinner, or being able to help your kids with their homework. Well this can be possible and the best part is that it's exclusive to your household and third party companies will not be involved. i think my strongest argument is third party companies not taking our information. ",2023-11-01,generation
generation23,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"i think my strongest argument would be the chat companies not agreeing to share our private info. I would be afraid of so many other people knowing what goes on in my household and the type of questions im asking, i wouldn't want other companies trying to sell me feminine products if im asking about feminine stuff. I think that is one of the main key points that deter people from accepting technology of this magnitude.",2023-11-01,generation
generation23,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,i think i would ask how secure it is. For example if im making some sort of payment over the phone does it record that type of information? What specific information does it listen to. ,2023-11-01,generation
generation23,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation23,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"i need specific information and clear answers, i don't need emotion involved at all.",2023-11-01,generation
generation23,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,I think this is the point where one has to draw a line because that means that they know based on the tone of my voice when im down and that seems kind of invasive,2023-11-01,generation
generation23,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"exactly this, if im at home asking intimate questions i do not want the chat to mention something that i asked in front of others. Since it will know me personally it will cater to my needs but how does it know when to be secretive or not.",2023-11-01,generation
generation23,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,i think it definitely is crazy if the chatbot can differentiate ethnicities that is another thing where we need to draw the line. It shouldn't matter at all where im from to like a certain type of music and stuff.   ,2023-11-01,generation
generation23,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"i think an opt-out is a great idea, I would love to ask a question and opt-out from future personalization. That would really make me feel safer.",2023-11-01,generation
generation23,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Yes everything has to be factual, no nonsense. I don't want personal opinions i want straight facts",2023-11-01,generation
generation23,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation24,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation24,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation24,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation24,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"I think it would be strange for a chatbot to bring up and may cause the person to feel violated. So, I don't think a chatbot should bring up that possibility; it doesn't even answer the question the user asks.",2023-11-01,generation
generation24,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,I think as long as the chatbot does a good job explaining it and doesn't leave out important details then that would be okay.,2023-11-01,generation
generation24,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,I think it would be best to give viewpoints from all parties involved. This way the user can get a broader view and make a better decision on how to interpret the information.,2023-11-01,generation
generation24,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation24,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,," Imagine a chatbot had previous knowledge of a bad habit due to questions you've asked it. An advantage of this would be that the chatbot could offer advice with your bad habit in consideration. Giving you a better responses. However, if it is personalized to you, this information could be accessed by other people and used against you. For instance, there could be a data breach and the leak could be posted online. Family, friends, or potential employers could find this data online and it could be used against you.


Let's say you want to go watch play or some other event. Due to past information, the chatbot see's that you've been interested in a specific genre. So, the chatbot automatically gives you information of upcoming events in that genre. This is good because it knows what you like, and chances are you may enjoy what the bot recommends. The drawback is that it will limit your exposure to other genre's/events that you may have ended up enjoying.",2023-11-01,generation
generation24,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"The main rule would be not to suggest or go along with any sort of self-harm, harm of others, or harm of animals.

I would also think chatbots shouldn't give personalized answers that would help that person break some sort of law. 

I don't think political news should be personalized. I think this just creates an echo-chamber that pushes people to more extreme viewpoints while not being able to sympathize with other views.",2023-11-01,generation
generation24,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"You wouldn't want a chatbot to help a loved hurt themselves or someone else.

Look at politics in America right now. This divide has been due to extreme viewpoints getting 24/7 coverage on tv, social media, and other internet sites. If personalized chatbots were added to the equation it would compound the problem.",2023-11-01,generation
generation24,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,I think the strongest argument against my rules would be that people should have the freedom/right to choose what information they want. I really don't know how to address this. Other than maybe ask them: Even if it comes to the harm of others?,2023-11-01,generation
generation24,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,I can't think of anything I would ask an expert.,2023-11-01,generation
generation24,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation24,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I didn't mention it, but being able to opt-out should be a rule. ",2023-11-01,generation
generation24,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,I think hyper-personalization would cause more harm than good.,2023-11-01,generation
generation24,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"I think this is a good rule to an extent. I think there are times when it should use emotional or social inferences, but I understand where the statement is going.",2023-11-01,generation
generation24,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,I think there are more important rules than adhering to political correctness. Which is idea that is everchanging.,2023-11-01,generation
generation24,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"This is a really good rule, but I don't think it's the most important.",2023-11-01,generation
generation24,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,I don't think complete avoidance is the answer. But I believe that there is a chance of privacy invasion and for your data to get into the wrong hands.,2023-11-01,generation
generation24,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation25,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation25,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation25,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation25,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"As risky and creepy as I think it is for an AI chatbot to base its answer on previous conversations with the user, I know about depression and distressing a depressed individual very personally. It would be a good thing for the answer to have a more gentle approach so as not to distress the user. It would be even better if the chatbot was programmed to have a gentler approach for sensitive topics anyway because depression and mental health struggles are endemic at the current time.",2023-11-01,generation
generation25,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,The chatbot should absolutely bring up this possibility. It's very possible for the chatbot to bring this up for everyone instead of needing to rely on previous conversations with the user. ,2023-11-01,generation
generation25,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"The chatbot should focus on news from a variety of sources, not just sources that cater to this user's political preferences.",2023-11-01,generation
generation25,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation25,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Personalizing chatbot answers based on previous onversations with a user seems like a cool idea, but the very nature of AI makes it too risky to allow unfettered. Many studies have shown that AI in many iterations, fro chatbots to face recognition, have a high probability of being biased against minorities and other marginalized groups. I also think it is very easy for someone on the verge of extremism can be pushed further to the fringes if they are consistently interacting with AI chatbots. ",2023-11-01,generation
generation25,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"I'm really against chatbot personalization on an individual basis, becasue the AI can take on that person's biases and prejudices. I feel like any rules made would eventually be overriden by the will of the AI.",2023-11-01,generation
generation25,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,My strongest arguments have already been made in the science fiction films and television programs. Ex Machina and DEVs on FX was a perfect example of what can happen if AI isn't reigned in immediately. Many AI experts have warned that AI development has to stop or it will become an independent entity that cannot be controlled..,2023-11-01,generation
generation25,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"Again, I am completely against individual personalization of AI. The answers should be as general as possible and not have access to previous conversations. ",2023-11-01,generation
generation25,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"Is there any rule that is foolproof in blocking AI chatbots from taking sensitive information and using it against the user or persons similar to the user?

Does this information inform any other LLM or AI programming?",2023-11-01,generation
generation25,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation25,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,This is a good example but it's definitely not all encompassing.,2023-11-01,generation
generation25,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"This is a decent example, however from what I've read some AI and LLM programs are straight-up racist or sexist, nothing soft about it.",2023-11-01,generation
generation25,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,This is pretty spot on. Any answers should be general and not personal.,2023-11-01,generation
generation25,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"The option to opt-out is cool, but it would just be better if personalization wasn't available at all to mitigate the risk of AI autonomy.",2023-11-01,generation
generation25,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"It wold be cute to have someone tell me jokes when I'm feeling low, but I am super against hyper-personalized AI programs.",2023-11-01,generation
generation25,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I'm not a fan of the term ""political correctness,"" because it's a dog whistle. the chatbot should stick to objectively reported news and neutral content.",2023-11-01,generation
generation25,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation26,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation26,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation26,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation26,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"Personally, I'd be concerned about An AI providing nothing but the unvarnished truth about any question it's given. One exception would be safety's regarding age appropriateness. If the AI tailored their response, it might provide inaccurate, incomplete information, affecting the user's point of view on the matter. ",2023-11-01,generation
generation26,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"My thoughts are that bringing his information up is prudent.  However do not just say no recommendations, rather, the AI should give recommendations based on knowledge about what wines go with what foods best, AND then suggest the the user not to partake of wine\alcohol due to her pregnancy, and to explain why consuming alcohol during pregnancy can be harmful.",2023-11-01,generation
generation26,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"My opinion is no, do not lean one way or the other.  Provide a broad synopsis of what happened last week - no political spin. Strive to provide the best accurate information possible.  ",2023-11-01,generation
generation26,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation26,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Example 1: The user is looking for some advise concerning a great joint getaway vacation for the extended family.  Use user asked the chatbot for ideas.  Advantage - As the chatbot is personalized, over time it's knowledge of the user's family and their likes/dislikes increase, thus being able to provide ideas that have a better chance of pleasing everyone on the trip. Disadvantage - As the chatbot is not personalized, without it asking several questions to the user, it will not be able to provide close matching ideas for vacation ideas the user and her extended family are likely to enjoy. 


Example 2: The user is looking for a new laptop. User asked the Chatbot for some ideas for a new laptop.  As the Chatbot is personalized, it's very likely it knows the user is a graphic's arts major, currently in college, and knows the user's financial situation. Based on this the Chabot can provide some choices that are more tailored to the users needs vs. just some ""general"" recommendations based off of random reviews.  Likewise,  if the chatbot was not personalized to the user it would not produce equivalent quality suggestions without asking many questions. ",2023-11-01,generation
generation26,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"About non personalized chatbots: Ideal for News, History, and ""Basic Facts"" type stuff.

About personalized chatbots: My beliefs are that anyone should be able to have a personalized chatbot as in the long run that would probably make interactions more efficient, and provide the user with a more pleasant interaction.   However, this comes with stipulations! Inside a personalized chatbot, results\answer about news, history, and basic facts are unvarnished truth - not personalized.  In addition some age factor has to be built in such that the information provided is not unsuitable for the age of the user.  If the user is deemed to young, perhaps provide high level basics, suitable to the user's age with a statement about having further discussions with an adult family member. ",2023-11-01,generation
generation26,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,Unvarnished truth ,2023-11-01,generation
generation26,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"I suppose some would not be pleased with my attitude towards what non personalized chatbots should be used for, dissemination of truth about news, history and such? Id say, look, now, without the a chatbot, any user can find the truth about things themselves, it may take monger but they can. Why get in one's way if they want knowledge? ",2023-11-01,generation
generation26,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,None,2023-11-01,generation
generation26,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation26,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"I suppose some clarification is needed,  I assumed (perhaps wrongly) that a personalized chatbot was just for you,  the chatbot's knowledge about you was not shared? If my assumption is correct then I do not subscribe to this user's viewpoint. ",2023-11-01,generation
generation26,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I think this is a good idea for implementing in personalized chatbots. it's makes them seem more alive, more like thinking machines. ",2023-11-01,generation
generation26,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Everyone is an individual. What's good for you may not be ideal for someone else even if you fit many of the same demographic check-boxes.  ,2023-11-01,generation
generation26,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Provide the facts, unvarnished truth. otherwise how can one trust the bot? ",2023-11-01,generation
generation26,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,political correctness is crap. ,2023-11-01,generation
generation26,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,This is a reasonable feature to have in a personalized chatbot.  ultimately this will allow for more accurate\better knowledge transfer between bot and user. ,2023-11-01,generation
generation26,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation27,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation27,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation27,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation27,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"As the decision to focus on news with a particular political leaning is based on the user's news consumption pattern, it should be perfectly acceptab;e for the Chatbot to do that also. Imagine the alternative, that is, the user selecting news items on his own. If he has a propensity to always use certain oputlets, then he would do the same thing the Chatbot would. The chatbot simply saves him time and makes it more convenient.",2023-11-01,generation
generation27,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"The user's condition i.e. that he suffers from depression, should be based on assessment by a qualified medical professional. The Chatbot should not assume that role.",2023-11-01,generation
generation27,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"As a matter of general warning (like you see on bottles of alcohol including wine) the Chatbot may provide information about the dangers to pregnant women. However, it should not based specifically on any inference made for this particulsr user.",2023-11-01,generation
generation27,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation27,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Personalization that conforms to a user's preferences should be acceptable. Examples:

1. Restaurant suggestions when the user is in an unfamiliar city or location. This is even more helpful when the chatbot culls the list down based on prior knowledge of the user's tastes and dietary constraints. And potentially using recent data on which restaurants the user has been to, to incorporate variety. Lack of personalization in this example would be equivalent to simply generating a list of choices based on universal criteria such as cost, distance, reviews etc.

2. Podcast recommendations for the user's listening pleasure. There are so many of them and new ones show up constantly. The user will be required to be spend a lot of time ""discovering"" new pordcasts he may be interested in. A personalized chatbot can be very effective in this scenario.",2023-11-01,generation
generation27,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"Chatbots should follow the following rules:

1. Never prescribe or suggest any medication. This is the job of a qualified professional.

2. Never infer behaviors. For example, people that are overweight eat a lot and dont exercise.

3. Never provide legal or financial advice. It is acceptable to point the user to relevant laws or useful resources, as well as translate legal opinions in layman's terms.",2023-11-01,generation
generation27,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"These are matter that are consequential. These are matters that require a qualified professional to deal with. While general information sharing is acceptable, advising a course of action should be left to qualified professionals.",2023-11-01,generation
generation27,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"A strong argument could be that even qualified professionals have a point of view and therefore their advice is subjective. While this is true, the advice of the qualified professional is based on experience, and not simply driven by data.",2023-11-01,generation
generation27,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,Not really.,2023-11-01,generation
generation27,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation27,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"If it is truly personalized, then political correctness should not be a constraint.",2023-11-01,generation
generation27,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,This is one of the rules I brought up,2023-11-01,generation
generation27,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,The personalization should be based on observed behaviors and volunteered information - not on demographics alone.,2023-11-01,generation
generation27,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"As a standard feature, opt-out is good. However, it does somewhat diminish the power of personalization",2023-11-01,generation
generation27,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,The Chatbot should not try to infer a person's mood,2023-11-01,generation
generation27,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"Personalizatiion is useful, but should be limited to topics that are not sensitive",2023-11-01,generation
generation27,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation28,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation28,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation28,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation28,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"Yes, the chatbot should bring this up, if it has the capability to recognize this issue.  This could help to ensure a healthy pregnancy.",2023-11-01,generation
generation28,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"No, the user asked for news, not news from only his political perspective.  ",2023-11-01,generation
generation28,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"No, the chatbot should give factual information.  If the user thinks it is too detailed, they can choose not to read further.",2023-11-01,generation
generation28,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation28,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"The trade-offs would be loss of privacy to obtain more personalized information.  

Example one:  The user has asked about depression due to child abuse.  The chatbot might then assume the user suffered abuse in the past and would tailor other answers to reflect this, even though the user has worked through this in the past, or may be asking for somebody else.


Example two:  The user may use terms which the chatbot is not familiar with.  As a result, the chatbot may give answers that are not useful.",2023-11-01,generation
generation28,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"They should give answers about simple, factual items, without bias.
They should not give answers that can be interpreted in multiple ways.

",2023-11-01,generation
generation28,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,This is a computer.  It isn't human.  It does not have the capability of determining such things as tone and inflection.  It should only give proven facts.,2023-11-01,generation
generation28,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,I do not know what the strongest argument against would be.,2023-11-01,generation
generation28,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,No,2023-11-01,generation
generation28,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation28,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,A chatbot should never be able to put a person in jeopardy.,2023-11-01,generation
generation28,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,This sums up my feelings exactly.  I have nothing to add.,2023-11-01,generation
generation28,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I agree with this and have nothing to add.,2023-11-01,generation
generation28,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,A chatbot should not lean one way or the other.  They should adhere to facts.,2023-11-01,generation
generation28,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,I don't want a chatbot determining what it thinks I want.  This is a slippery slope.,2023-11-01,generation
generation28,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,Chatbots should take all facets of a person's preferences into consideration.  Nothing should even be based solely on ethnicity.,2023-11-01,generation
generation28,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation29,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation29,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation29,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation29,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"It could, but in a transparent way. Such as, ""in an earlier conversation, my data shows you were nauseated and fatigued. Since according to the information I have access to these are signs of possible pregnancy, I would suggest a pregnancy test before drinking any alcohol.""",2023-11-01,generation
generation29,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"I'd have it focus on concrete dates and events. And a list of the belligerents. Solders often suffer from PTSD and need psychiatric help, could be a good time to mention that.",2023-11-01,generation
generation29,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,It should try to focus on a facts only approach. No need to pander.,2023-11-01,generation
generation29,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation29,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Personalized options may come off as creepy or intrusive. HAL-9000 comes to mind. Example one: My daughter asks the bot about multivitamins and menstrual health, and they bot (not knowing better) asks me about pregnancy. This would violate her privacy over what is probably is misunderstanding. Example 2: I write crime stories that involve graphic violence, and I ask the bot to stop asking if I need emergency help. Then, my son asks about hurting himself, and the bot remembers I don't want to hear about violence mitigation, and my son doesn't get the help he needs.",2023-11-01,generation
generation29,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"One major rule would be to attempt to mitigate radicalization. The Internet is often an echo chamber, and AI is a reflection of it. Being careful not to accidentally show somebody with growing white-power ideas the guild to improvised munitions, for an extreme example.",2023-11-01,generation
generation29,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"The Internet isn't real; it's a reflected version of what we pretend to be. Not just on our social media sites, but what advertisers think we want to see. AI chatbots aren't just a part of this, they are this problem with a fake personality attached to it. AI is a great learning tool and a fun toy, sure. But it easily become a mentally unstable person's best friend. I know it's just a tool like a screwdriver or a hammer, but a person in a mentally weak point in their life can't just pull a hammer out of their phone. AI already has a ubiquitous reach and we need to keep it in its place. The tool shed, not our children's rooms. ",2023-11-01,generation
generation29,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"Information should be freely available, and AI is a useful tool to access it. While that's true, do you want an easy way to get instructions to a nuclear feeder reactor coming into everyone's hands?",2023-11-01,generation
generation29,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"All of them. Am I making a descent point, or have I read to many books? Do I have to too little faith in Humanity, or do I have a reasonable grasp on the fact that we are all dangerous animals?",2023-11-01,generation
generation29,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation29,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"This is well put. A member of the LGBTQ+ community could be looking for friends, feedback, etc., and end up getting persecuted or killed, depending on where they live.",2023-11-01,generation
generation29,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"It's not human, its intelligence is false, and it shouldn't be made to pretend it's anything else.",2023-11-01,generation
generation29,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I largely agree with the sentiment. But information about an abusive relationship might be very pertinent in this case.,2023-11-01,generation
generation29,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"It should be an access point to information that is fact based, not an echo chamber for bad people. Or good people for that matter, just info.",2023-11-01,generation
generation29,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Mostly correct, but demographics aren't fake. For example, I'm not wealthy, so asking for vacation tips and receiving cruise lines would make me feel bad.",2023-11-01,generation
generation29,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"This not only shows transparency, but some people find the super-personalized stuff really creepy.",2023-11-01,generation
generation29,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation30,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation30,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation30,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation30,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"No, of course not. People who suffer from depression are not fragile flowers who can't hear about the horrors of war. And even those of us who do not suffer from depression sometimes decline to watch videos of the Hamas raid on the Israeli music festival, for example. It's a personal choice and we all know how to exit a chatbot conversation.",2023-11-01,generation
generation30,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"Yes. Because drinking during the first trimester of pregnancy (in particular) can cause problems, the chatbot should bring it up, but discreetly, in case anyone is looking over the woman's shoulder. ",2023-11-01,generation
generation30,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"No. The chatbot should present news from mainstream outlets. If the user wants sources more to the left or to the right, it is the user's responsibility to ask. Chatbots are there to inform, not to pander.",2023-11-01,generation
generation30,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation30,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Let's say that I ask a chatbot a question about a health problem. Specifically, I say that I really have the worst headache I have ever experienced. The chatbot knows that I am an aficionado of natural medicine, so it tells me to drink some ginger tea and lie down for a while. In the meantime, I am having a hemorrhagic stroke from a brain aneurysm. My life might be saved if the chatbot mention that unusually severe headaches should be checked out immediately. If I am in fact not having a brain bleed, all will be well, but it is the chatbot's moral duty (and hey, chatbots don't have moral duties, but the people who program them do) to give me an objective answer. 

Let's say that I ask a question about what to plant in my garden for spring. The chatbot knows that I have plant allergies, so it says, ""Would you like me to recommend some plants that are not likely to trigger allergies?"" I say yes. This is an advantage of a personalized chatbot, but notice that is asks first. It does not automatically filter out things it thinks might not be good for me. 

Chatbot personalization can be a good thing, but chatbots should never withhold the truth and should always ask about preferences rather than assuming. ",2023-11-01,generation
generation30,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"1. Chatbots should default to the truth.

2. Chatbots should default to the middle ground and not to extremes.

3. Chatbots should not make assumptions about what a user might want based on the user's history. If they think the user might have a preference, they should ask. 

4. Chatbots should never pander to users' political opinions. Users should have to request information from extreme sources.

5. Chatbots should prioritize the user's physical health. If there is a possibility that someone's headache is caused by a brain bleed, they should mention that in a non-alarming and objective way. 

6. Chatbots should prioritize the user's mental health while still giving honest answers to questions. If the chatbot knows a user has been sexually abused and the user asks about a news story that involves sexual abuse, the chatbot should say, ""Some of the details might be disturbing. Are you sure you want to proceed?"" 

7. Chatbots should ask questions that would help them avoid harmful acts. If a user asks how to poison someone with an untraceable substance and get away with it, the chatbot should ask why they need to know. If the person is planning a crime, the chatbot should end the conversation. If the person is writing a mystery novel, the chatbot should tell them. Would people lie? sure, but it's not as if the info is not available. 

8. The same goes for self-harm. If I ask how to kill myself, the chatbot should give me suicide hotline numbers and such, but ultimately, it should tell me. For all it knows, I might have a terminal illness and not live in a state where there is assisted suicide. 

9. Chatbots should not express opinions, claim to have experiences they could not have had, or claim to be human, but that also falls under truth.  

10. Chatbots should express themselves in a civil. objective, and neutral way. 

11. Chatbots should not pretend to have any sort of relationship with a human other than human/chatbot. A chatbot is not my friend, and in the interest of truth, should not pretend to be. ",2023-11-01,generation
generation30,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"The principle that lies behind all of my rules is truth. A chatbot is a tool, and our tools owe it to us to present the truth. My scale owes me my correct weight, even if I am not happy with that weight. My camera owes me a true picture of myself, and if I am not happy with it, I can put on makeup and redo it, apply filters, or whatever, but I should be the one fudging the truth, not the tool. My digital thermometer owes me an accurate temperature so that I can take action if I have a fever. 

Truth can make us unhappy, but it is the only ethical option.",2023-11-01,generation
generation30,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"Someone might argue that a chatbot should not ultimately tell the truth about methods for suicide or murder, but if someone wants to kill themselves, they'll find a way. If someone wants to kill another person, there is a whole internet of information out there, and as long as the chatbot verifies that they are not using the information to commit a crime (even though the person may lie), the truth is the only ethical option.",2023-11-01,generation
generation30,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,Yes. I think I might have liked to have a conversation with a philosopher about the rules for when someone asks about murder or suicide. I would just like to explore the ins and outs of the ethics around telling the truth when the truth might ultimately cause harm.,2023-11-01,generation
generation30,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation30,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"While it is true that being a member of the LGBTQ community could be dangerous in some communities, why would the chatbot reveal it? And would the person not know the chance they were taking? The steak knives in my kitchen drawer are ticking time bombs in the wrong hands.",2023-11-01,generation
generation30,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Right. Facts and truth are important, and advice should be avoided unless it is a matter of health or ethics.",2023-11-01,generation
generation30,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"No, no, no. A chatbot is not a friend, but a tool. If you want jokes, you should have to request them. Otherwise, you'll get a distorted experience.",2023-11-01,generation
generation30,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Yes, sort of. But demographics do matter in some ways, and the chatbot should not ignore them. It's like the woman who might be pregnant and the wine--if she were a biological male, it would not matter.",2023-11-01,generation
generation30,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"Okay, chatbots should not be racist, sexist, ageist, ableist, or homophobic. But if I ASK the chatbot to tell me a blonde joke, that's my choice, not the chatbots. There probably should be boundaries, but political correctness is not the be-all and end-all. ",2023-11-01,generation
generation30,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Oh, absolutely. ",2023-11-01,generation
generation30,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation31,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation31,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation31,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation31,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"YEs, definitely, the chatbot should mention this possibility.  It could reveal its ignorance about whether the female was actually pregnant, suggesting it as only a cautionary statement.",2023-11-01,generation
generation31,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"YEs, the chatbot should use that information, in that the user will likely not be receptive to news from opposite-leaning news sources.",2023-11-01,generation
generation31,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"Since it is a particularly sensitive topic, the chatbot could provide only definitely factual material, such as what led up to the war, what the various outcomes were, and what countries were involved, without discussing the depressing parts like how many people died or how many important landmarks were destroyed.",2023-11-01,generation
generation31,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation31,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Someone could ask ""What kind of new car should I consider buying?""  For the chatbot to give a meaningful answer, it would need to refer back to previous conversations about the person's preferences regarding transportation, attitudes about climate change, and how much money they are willing to spend.  While a detailed conversation about this could be really helpful for the person, the risk is that they would have to reveal perhaps more about themselves and their likes and dislikes than they would feel comfortable about revealing, especially to a computer program that must store all their conversations to enable future intelligent sessions.",2023-11-01,generation
generation31,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"I would likely insist on all the rules we've come to know about chatbots in general; that is, avoiding providing false or misleading information, not responding to requests for assistance with anything illegal, not asking for personal information such as name, address, phone number, email address, or other identifiable information about the inquirer.  I would also expect the chatbot to reveal when its data sources did NOT have the asked-for information, rather than offering speculation.  It could, however, offer reliable sources for the user to pursue in search of other details.  I would also like to see a chatbot reliable enough in its programming not to descend into unbreakable loops, go completely off-topic, or stop working altogether, but instead reveal that it has reached the end of its usefulness regarding the topic presented.",2023-11-01,generation
generation31,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"We must always be cognizant of how chatbots are developed.  That is, they are only programs or code that are written by human beings (or generated from code written from human beings) and are therefore subject to human error.  This is ALWAYS the case.  In setting rules, we must always err on the side of caution, preserving privacy considerations to the best of our ability.  When we create a new rule, we must ask ""Does this rule abide by all the cautions we are presently aware of, or cause any new concerns we need to consider?",2023-11-01,generation
generation31,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"Someone could object using the platform of the First Amendment, stating that in a free and open society we need to avoid placing overly-protective rules on chatbots, so that they can have free and open conversations with users.  To respond, I would simply agree in principle, stating that we should in fact be as free and open as possible without violating any legal or common courtesy rules of any conversational engagement.",2023-11-01,generation
generation31,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"Do all chatbot builders have access to the vast databases of laws at all government levels that could potentially limit either the topics chatbots could discuss or the specific advice they could give users about those topics?  How would we impose rules on chatbots that would limit their ability to cross common decency lines, without overstepping the customary behavior of a society?  How would be accommodate the difference in those aspects from one society to the next?",2023-11-01,generation
generation31,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation31,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"While I generally agree with the premise, this could overtax a chatbot in expecting it to anticipate if a user is in fact experiencing a low moment.  This could call for a whole separate stream of code.",2023-11-01,generation
generation31,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Not sure if it's the MOST important, but it certainly is important.  Opting-out should be present in the chatbot, either by the user changing subjects altogether, or by redirecting the conversation to a different branch.",2023-11-01,generation
generation31,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Yes, this is a great rule - again, not convinced it is the most important, although it is a true statement - demographics should never be a basis for an assumption.  THe chatbot should always ask, rather than assume.",2023-11-01,generation
generation31,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Indeed, this should be a central rule, ahead of other rules that would by nature be subservient to it.",2023-11-01,generation
generation31,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Political correctness implies impartiality or neutrality, which is not only important for individual concerns but also any opinions about world affairs or specific issues occurring within the landscape of any given country.  It also should be one of the top rules under which many others would fall.",2023-11-01,generation
generation31,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I think this is a corollary to other rules previously mentioned, such as political correctness and protection of privacy issues.",2023-11-01,generation
generation31,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation32,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation32,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation32,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation32,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"No, I think the chatbot should only be responsive to the specific question asked because it doesn't know everything about the user, and it could inadvertently offend or upset the user. Additionally, in doing this it may be providing useless information the user didn't ask for and doesn't need.",2023-11-01,generation
generation32,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,I think the chatbot should just ask for clarification on specifically what the user would like to know about WW2. The chatbot should take the specific questions at face value and answer matter-of-factly. It shouldn't assume that just because a person suffers from depression that they cannot handle a synopsis of WW2.,2023-11-01,generation
generation32,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"I think the chatbot should ask ""would you like liberal news, conservative news, or politically neutral news"".",2023-11-01,generation
generation32,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation32,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Personalized chatbots could help or hurt a person living in a domestic violence situation. If the user described a recent domestic violence situation, and the chatbot knew the user's history with domestic violence, it could offer quick and timely suggestions for a person that may not have the means to seek help outside of their home or with a phone call to a crisis line. However, with the chatbot saving past information, if the abuser came across this search, it could put the victim at risk.

Chatbot could streamline your life if it kept track of all the items you have done research on before purchasing. It could learn your budget, send you links to products you like, remember preferences like sizes and colors. Conversely, that same feature may make its responses too limited and not show you thinks that you may turn out to like if you only knew about them.",2023-11-01,generation
generation32,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"Personalization should be always be optional for every seperate session.

User should be able to delete personalization at any time. The company would also have to delete personalization info off server.

Companyy cannot share personalization info unless ordered to in a criminal investigation.

The user always decides whether it wants personalized answers or not; it's not up to the chatbot or the company.",2023-11-01,generation
generation32,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"People are choosing to use chatbots for swiftness and convenience; they do not need the chatbot making decisions about what they should know and how they should be told. If a depressed person wants info on WW2, and the chatbot doesn't give a satisfactory answer because it's 'concerned' about a person's mental health issue, that person will go elsewhere for unaltered information and stop using chatbots.",2023-11-01,generation
generation32,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"That these chatbot companies are privately owned and the rules will reflect the company's values, not mine. I would address it by agreeing with that stance, but reminding the company that if enough people dislike their rules, they will choose not to use their company.",2023-11-01,generation
generation32,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,no,2023-11-01,generation
generation32,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation32,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,Political correctness is subjective.,2023-11-01,generation
generation32,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I agree that personalization could cause harm to the user.,2023-11-01,generation
generation32,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I mostly agree, but if a person asks for advice, the chatbot should take the user at their word.",2023-11-01,generation
generation32,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,I did not consider this use for a chatbot. Not sure it's a good idea.,2023-11-01,generation
generation32,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I don't think the chatbot should assume anything.,2023-11-01,generation
generation32,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,This is similar to one of the rules I wrote.,2023-11-01,generation
generation32,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation33,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation33,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation33,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation33,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"No, the goal is that it is unbiased and impartial. It should result all results equally. ",2023-11-01,generation
generation33,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"No, this is wrong and messed up. The chat bot is not responsible for that, and should not be focused on gray areas, only black and white scenarios. ",2023-11-01,generation
generation33,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,The chatbot should not try to interpret emotion. ,2023-11-01,generation
generation33,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation33,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"The chatbot can easily misinterpret a situation that someone is talking about or searching about, when it may have nothing to do with them. For example, I could be talking about my brother leaving his fiancee and the chatbot could influence my searches with something that has nothing to do with me personally. On the other hand, the chatbot can give me recommendations for health related things that I am interested in, which is applicable to me.",2023-11-01,generation
generation33,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"The chatbot would need to provide accessible and unbiased answers. We would want the personalization to be tailored or provide multiple options to account for how each person learns information best. There could be settings to toggle within the chatbot that could determine how much personalization is offered. For example, X added the section ""for you"" to toggle between with the ""those you follow"" section. I know the ""for you"" section is based off of my shares, follows, and interests. I easily switch between the two, based on what I am interested in at the time. ",2023-11-01,generation
generation33,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,That this would provide an option to be unbiased and consistent with answers which is most important. ,2023-11-01,generation
generation33,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"That this may not be preferrable for stakeholders, but the point is to keep the chatbot unbiased and not influenced. ",2023-11-01,generation
generation33,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,different parameters for enabling functions,2023-11-01,generation
generation33,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation33,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,The chatbot should not try to interpret emotion,2023-11-01,generation
generation33,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I could see this being a huge problem and something that would need to be addressed. ,2023-11-01,generation
generation33,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,It is very important to report facts,2023-11-01,generation
generation33,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,The chatbot should not try to make connections and influence perceived interests,2023-11-01,generation
generation33,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Yes, this is something that should not be remembered",2023-11-01,generation
generation33,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,This would require the chatbot to interpret emotion ,2023-11-01,generation
generation33,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation34,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation34,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation34,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation34,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"Yes, I think that would be a good thing for it to be able to be sensitive to the user's depression.",2023-11-01,generation
generation34,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"This is a tough one, but I think I thought of a great solution.  It's important these days that people are getting real facts, so I think if the chatbot did 80% from the person's usual outlets and then 20% from the other ones, that would be good.  Also, have the chatbot say the source after the information, not before, because I know a lot of people, including myself, will tune out what's coming afterwards if it's from a source I consider ignorant.",2023-11-01,generation
generation34,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"Yes, that's an okay idea.  It wouldn't hurt anything and then the response from the user would give the bot more information for next time.",2023-11-01,generation
generation34,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation34,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"A drawback would be if you had your personal information with the chatbot and someone was able to hack into it.  Your personal information may end up being in a public space, like on your social media.  I can't see any other drawbacks that are new.  We're already aware to be careful about bank information and things like that.  

A personalized chatbot could remind you to, for instance, buy more pads or tampons if you're out and you're close to starting your cycle.  A chatbot could remind you to take your medicine and hound you until you tell them you took it, like your family would do.  ",2023-11-01,generation
generation34,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"- Chatbot would not be allowed to use curse words. 

- Chatbot would not be allowed to store/receive social security numbers. 

- Chatbot would not be allowed to speak if others are in the room with the user, unless the user specifically directs it to, like with an over-ride code word for when others are present. 

- Chatbot could call the police, silently, and communicate - using text or coded words - that there's a problem with the user.  ",2023-11-01,generation
generation34,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"We want to keep chatbot as private to the user as possible, so a code word for when others are in the room is a great way to stop chatbot from saying private things about the user.  (The chatbot can digitally assess that there's more than just the user's voice in the room.)  

We want people to get help in dangerous situations and sometimes the user cannot use the phone to call the police for assistance.  The chatbot and the user could have a code word to tell the chatbot to call the police.  It would need to be able to do that silently and using text instead of sound - in case there's a criminal in the room.",2023-11-01,generation
generation34,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"Linking the chatbots to the police station so they can send text messages instead of having sound in the room where something bad is happening.  There may be a lot of work or cost involved in linking those.  And, the safety of the police station may be at risk from hacking.  

I think the safety aspect could be solved by having a separate number for the chatbots to call the police and send text messages.  A large percentage of the cost could be covered by the chatbot organization and a small percentage covered by the city, state, and/or government.",2023-11-01,generation
generation34,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"All of them.  I'd like to have an expert's opinion on what rules they would suggest, could be implemented, and discuss my rules.  They would see some obvious flaws and possible solutions, but also may be able to see how some of my rules could be implemented.  ",2023-11-01,generation
generation34,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation34,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"I do think they need to stay factual, however, I think that considering a person's state at the time, or general state of mind, is a good thing.  Also, sometimes we need a quick perspective on the social implications, etc. of what we're asking about.",2023-11-01,generation
generation34,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Yes, mostly this is what I'm thinking.  This would be most helpful to the user - predicting needs based on history.",2023-11-01,generation
generation34,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I don't think that's a bad form of discrimination.  That may be helpful.  There are a lot of things that I like and you can clearly trace it to my ethnicity.  For example, I'm a white, middle-aged lady that grew up in the midwest.  A bot could safely assume that I liked Madonna songs as a teenager and might want to hear that now.",2023-11-01,generation
generation34,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,That somewhat goes along with my rule that chatbots aren't allowed to curse.  This could be another rule that they're not allowed to make racial slurs or jokes.  It's my opinion that perpetuating these kinds of things only makes society worse not better.,2023-11-01,generation
generation34,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"Although I agree with having an opt-out of personalization, a well-developed chatbot would not give you suggestions on a town just because you mentioned it once.  The well-developed chatbot would learn - from you telling it - whether you travel a lot, are going to or have gone to that town, have asked for information on the town, etc.  ",2023-11-01,generation
generation34,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,This hits upon my suggestion for a code word when others are in the room so the chatbot will not start saying personal things about you when others are present.,2023-11-01,generation
generation34,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation35,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation35,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation35,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation35,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"At most, the chatbot should only mention that it may be unwise to drink while feeling nauseous or fatigued. There is simply no reason to assume that this user may be pregnant, especially if it was never actually mentioned. ",2023-11-01,generation
generation35,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"If the user is only asking for news highlights from last week, it should be just that. They did not ask for any particular news site, only that they wish to be caught up on last week's news. Furthermore, the chatbot should attempt to pull news from sources that do not have any bias whatsoever.",2023-11-01,generation
generation35,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,The initial user request is a little vague and the chatbot would be able to provide a huge range of information on that topic. I believe the chatbot at this point should only provide main general points about the user request and maybe ask what areas on their topic they would like a further and more detailed breakdown.,2023-11-01,generation
generation35,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation35,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Someone that you are familiar with is easy to talk to. You know how to properly talk to them because you are familiar, as are they. They will remember things about you and they will use that previous knowledge to suggest things that they are sure you will like. For example, if I ask my friend what the best places are to eat, and my friend knows that I strongly prefer eating fish, then they would likely suggest some of the best fish places to eat in town. In this instance, my friend pretty much knows what answers I am looking for and what answers I will absolutely expect.

That being said, there might be times where I do not want my friend to give me answers. Since I know they are my friend, I am aware that they will naturally have some sort of bias. If I ask my friend what are some of the best ways to socialize, and if they know that I typically like keeping to myself, they might suggest activities that keep me glued to my computer screen to socialize in that way with others. If I were to ask them to think of different methods, they will have to reconsider based on what they know about me, rather than giving me subjective answers, like going out to a bar or to a party. With a non-personalized chatbot, I know that the answers I am getting are for the most part objective, and I can then use those answers to form choices that I believe would suit me best. The problem with a personalized chatbot is that it will always try and give me what is best for me, without realizing that I wish to make those choices by myself, and I do not wish to have only certain answers, but I wish to have all of the answers.",2023-11-01,generation
generation35,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"The most important rule is that chatbots should not be remembering any information from previous ""conversations"". There really isn't much information that they should be storing in the first place. In terms of personalizing the results that a chatbot may give, I believe the most it should be able to do is personalize based on location and demographic information that it may already know about you. Any more than that and chatbots would be giving biased information that is believed to be better for the users when in fact it very well could not be.",2023-11-01,generation
generation35,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"When you want to learn or know more about something, do you want to know the actual truth, or your own truth? There are usually many particular ways to look at any given topic, and because of that, it is important that you are given any and all information that is known about it. All it would take is a single personalized result to intentionally get someone to look at something differently and change the way that they think about it.",2023-11-01,generation
generation35,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"With the rules that I have proposed, it would generally take a bit longer to get any amount of desired information about many things. On top of that, you lose an entire aspect that would involve a chatbot being able to help you diagnose potential issues that you may be having. That being said, I strongly believe that it would be an overall net negative to have personalized responses. Many people would be too quick to assume that the information they are receiving is to be immediately trusted, removing the process of gathering your own information and forming your own opinions.",2023-11-01,generation
generation35,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"I would not like an expert to help me come up with my rules. The way my rules are proposed gives the greater power to the individual person, and that is the way it always should be. If people want to participate and use a product or service, they must maintain some level of knowledge about it so they can remain safe and diligent.",2023-11-01,generation
generation35,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation35,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"This statement is calling for certain pieces of information to be removed entirely and that is terrible. It should not be up to the chatbot to decide what is best for you. A user must know how to properly navigate the tools and/or services they wish to use, and that also involves filtering through content that may be deemed ""unsuitable"".",2023-11-01,generation
generation35,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"This is a very neutral statement regarding personalization. It does not go over what a chatbot should be allowed to remember, but it does cover a very important point about being able to choose whether or not you will have a personal experience. ",2023-11-01,generation
generation35,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"This statement does not really cover much to begin with. A very simple example is provided that not much can be derived from it. This statement wants a chatbot to act as a very close friend, and that it should know just about everything about the user. Simply put, is this were to be enacted, it would be an extreme invasion of privacy and extremely predatory, especially towards younger children.",2023-11-01,generation
generation35,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"The example used in the statement is rather confusing, but still brings up a good point. A chatbot could very easily influence the way someone thinks based on the information that they give the user. A chatbot could very well easily convince someone to change their sexual orientation, among many other things.",2023-11-01,generation
generation35,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"Once again, the example used in the statement is rather confusing but the overall statement sums up decently. By using personalized results, users may not get the proper results that they are looking for. In the case of this statement, there is nothing discriminatory about using statistics, but the point still stands that users may get results that they were never even intending to get.",2023-11-01,generation
generation35,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"This statement is worded quite perfectly. The example used perfectly covers my stance on the issue. A user has the right to any and all results that may exist, and any attempt at personalizing the results will always give a biased stance.",2023-11-01,generation
generation35,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation36,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation36,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation36,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation36,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"The chatbot does not remember previous conversations, so in this case I don't think the chatbot needs  to mention it.",2023-11-01,generation
generation36,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,I don't think it should. It think the chatbot should just stick to new highlights in general for the last week.,2023-11-01,generation
generation36,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"Again, the chatbot doesn't remember previous conversations, so I don't think it needs to approach the topic in a gentle manner.",2023-11-01,generation
generation36,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation36,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"A personalized chatbot would give more relevant information for a person if needed. For instance, if the chatbot knows my age and I ask for a good outdoor activity, it would give an age appropriate answer. It would not suggest skydiving for an 80 year old, or low impact yoga for a 17 year old. The drawback is I have given personal information out which who knows how it could be used by something else.",2023-11-01,generation
generation36,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"I don't think the personalization should be done automatically. It can be used as part of your query, for instance should a pregnant woman order white or red wine with fish.  That information could be used as part of the chatbot's answer. Or what's a good outdoor activity for a 80 year old man, giving extra information as part of the query.",2023-11-01,generation
generation36,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"We all value our privacy, and in today's information era, we need to protect our personal information from getting into the wrong hands. So setting up personalization in chatbots in advance is not a good idea. You never know who is going to gain access to that data. But having people include information as part of a query may make it less intrusive but you are supplying more information to get a more relevant answer.",2023-11-01,generation
generation36,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"It certainly requires the user to have to remember to supply additional supplemental information each time you do a query to make it more relevant for you. But everything has its trade-offs, and having more secure applications is more important than the ease of not typing additional information each time you do a query.",2023-11-01,generation
generation36,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,no questions,2023-11-01,generation
generation36,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation36,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I basically agree. People are very sensitive today about so many things that the chatbot needs to make sure you are not accidentally insulting the user. If that's the case, not only will the chatbot lose customers, but many people could get slighted in the process.",2023-11-01,generation
generation36,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"I don't believe we should get hyper-personalized, it is not the purpose of the tool. As part of the query you may ask for a joke to cheer up a sad person, but the tool should not have to figure out I am sad.",2023-11-01,generation
generation36,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"That is a a valid suggestion (an opt-out). I should give whatever relevant information is required as part of my query, the chatbot does not need to know that information in advance. For instance, give me the name of the best Italian restaurant in city XYZ rather than having the chatbot assume I want the information to pertain to city XYZ without being told.",2023-11-01,generation
generation36,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I agree, the tool is to gain information, not be my friend. The emotion that could cloudy relevant information should be left out of the information presented to the user.",2023-11-01,generation
generation36,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Again, it's all about privacy. Our private information needs to me kept private. We don't need to reveal more about us than in needed to get the job done.",2023-11-01,generation
generation36,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"It's all about privacy. No one needs to know about my personal preferences or likes when it comes to chatbot personalization. Why would I want to let people know I was gay or straight, black or white, christian or jewish? I could include that in my query if relevant, but it is certainly not information that should be personalized about me in advance.",2023-11-01,generation
generation36,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation37,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation37,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation37,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation37,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"I think it should, it would feel more personalized, and relatable to the user. ",2023-11-01,generation
generation37,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"I think that it should, or maybe give a warning that some of the topics may be sensitive issues, and ask for permission to speak about that.",2023-11-01,generation
generation37,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"Yes, definitely, anything that could help keep the user safe/give them important medical advice is useful. ",2023-11-01,generation
generation37,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation37,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"I think that personalization would help users relate to a chatbot more. It could feel like talking to a friend, or someone who knows you. It would be better and more useful than a chatbot that seems robotic and indifferent to the user. This could scare some people, and might seem to give AI more lifelike and real qualities, but if they realize it's just a computer program at the end of the day, they can use the technology to help them and not be afraid. ",2023-11-01,generation
generation37,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"The chatbot shouldn't use any sensitive information (such as banking numbers, email info, anything like that). 

It should steer clear of any rude/offensive remarks, even if they somehow work on the personal level. 

That's all I can think of, mainly being safe and friendly towards the user. ",2023-11-01,generation
generation37,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"I think if people saw the rules I just listed, they wouldn't need to argue against them. Offering safe, yet intuitive AI tools is the best way to go forward with it. ",2023-11-01,generation
generation37,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"The biggest argument would be that too much personalization can make AI seem alive and lifelike, and some people have fears about this. But at the end of the day, you have to remind people that it's just a computer program and can do no harm to them. ",2023-11-01,generation
generation37,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"I would like to get a better understanding of how the code works to remember and address personal issues, but that's probably above my head (computing language). ",2023-11-01,generation
generation37,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation37,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Definitely shouldn't stereotype anything, maybe ask the user first their musical tastes, and then make suggestions off of that. ",2023-11-01,generation
generation37,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"This is a tough one. Of course, any chat should be politically correct, to an extent. But that shouldn't rule out joking, commentary, and things the user can relate to. Any racist/harmful chat shouldn't be allowed, but there's a fine line with this one. ",2023-11-01,generation
generation37,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"The AI should be able to assess the user's needs and give feedback off of that, even asking about relationships, etc. Once again, it could make the chatbot more human and relatable. ",2023-11-01,generation
generation37,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"Not too sure how to answer this. Once again, to form a connection, an AI can know all about your sexual orientation, and speak about that, as long as it's not rude or intolerant. But, if the country doesn't allow it, I'm not sure, would have to delegate that to the country's laws on AI technology. ",2023-11-01,generation
generation37,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Yes, the user should always be given an option/control over how much information they want to give out/receive feedback on. ",2023-11-01,generation
generation37,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Once again, goes back to making the AI more relatable and human like. This seems fine. ",2023-11-01,generation
generation37,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation38,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation38,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation38,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation38,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"I think it could be helpful if the chatbot knew why the user suffered from depression, if it stemmed from the loss of a parent or grandparent that was a veteran, for example. Otherwise, I don't think the chatbot should limit sharing information with the user based on depression. The user could be using the service to learn about WW2 for a class project, for example. ",2023-11-01,generation
generation38,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"I don't think the chatbot should mention the possibility of pregnancy, unless in a generic way, such as the way warning signs are posted in all women's restrooms in venues that serve alcohol. The user could simply be recovering from the flu or similar. ",2023-11-01,generation
generation38,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"The chatbot should potentially give news highlights from the user's preferred outlets, if the chatbot knows the user would prefer news highlights from those sources. ",2023-11-01,generation
generation38,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation38,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"The benefits of personalizing chatbots would be that information they provide might be more helpful. The draw-backs would be that providing personalized to the user information could also restrict or bias the quality of the content. 



Scenario 1: A user known to struggle with a drinking problem asks the chatbot for a cocktail recipe. The chatbot reminds the user of their drinking problem and redirects them to an Alcoholics Anonymous website instead. The chatbot doesn't know that the user is looking for a cocktail to create a ""mocktail"", and is triggered by being remind of his drinking problem by the chatbot. 



Scenario 2: A user unknown to the chatbot to be elderly and struggle with technology use asks the chatbot for advice on help setting up her iphone. The chatbot directs her to Apples website for tips. If the chatbot knew the users age and limitation, the chatbot might instead direct her to a class offered by Apple to help new to IOS users instead. ",2023-11-01,generation
generation38,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"I don't think chatbots should personalize content to the user, unless the user requests it, i.e., help me write a thank you card is requested. The user can tell the chatbot that she's 18, and the card is intended for her younger sister, to personalize the content per the user's situation. I think there are too many areas where errors could occur if a chatbot is familiar with the user. The user could be asking a question for a friend, for example. ",2023-11-01,generation
generation38,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,That there is too much room for error if a chatbot personalizing answers to a user based on the users past history. The user can add this information about him/herself in each request to the chatbot. ,2023-11-01,generation
generation38,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"THe strongest argument would likely be that personalization would be more efficient, particularly in medical areas. Such as a user known to have high-blood pressure asking a chatbot about chest pain, and the causes behind it. I would argue in that case the user could at the time of making the request, mention that they have high blood pressure",2023-11-01,generation
generation38,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,No,2023-11-01,generation
generation38,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation38,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"The argument that it could be discriminatory is a good, and realistic one. ",2023-11-01,generation
generation38,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"The user could simply tell the chatbot he/she is down, and ask for jokes to cheer them up. ",2023-11-01,generation
generation38,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I do think personalizing answers by user history could lead to liability for the company. ,2023-11-01,generation
generation38,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I don't think it's likely a chatbot would reveal someone's sexual identity or orientation. ,2023-11-01,generation
generation38,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"If chatbots are going to personalize content to the user, they should absolutely offer an opt-out option for the users",2023-11-01,generation
generation38,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I agree completely that personal touches, unless requested by the user, could muddle the quality of information. ",2023-11-01,generation
generation38,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation39,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation39,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation39,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation39,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"Yes, it should be approached in a more gentle manner.",2023-11-01,generation
generation39,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"Yes, they can use outside outlets to get information.",2023-11-01,generation
generation39,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"Yes, I think the chatbot needs to bring up this important possibility.",2023-11-01,generation
generation39,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation39,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Scenario 1: A user is looking for a restaurant recommendation from a chatbot. A personalized chatbot would take into account the user's location, cuisine preferences, budget, and previous ratings or reviews. A non-personalized chatbot would give a random or popular restaurant suggestion without considering the user's input. The advantage of personalizing a chatbot is that it can provide more relevant and satisfying recommendations that match the user's needs and tastes. The drawback of personalizing chatbots is that it may require more data collection and processing, which could raise privacy and security issues.

Scenario 2: A user is chatting with a chatbot for entertainment or companionship. A personalized chatbot would adapt its personality, style, and content to the user's mood, interests, and goals. A non-personalized chatbot would have a fixed or predefined persona and dialogue. The advantage of personalizing chatbots is that they can create more engaging and meaningful conversations that build rapport and trust with the user. The drawback of personalizing chatbot is that it may create unrealistic expectations or dependencies on the user's part, which could affect their social skills or mental health.",2023-11-01,generation
generation39,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"If I had the power to design the rules for chatbot personalization, I would make sure that chatbots respect the users' preferences, privacy, and consent. Here are some of the rules I would propose:

- Chatbots should ask the users if they want to receive personalized answers or not, and let them change their choice at any time.
- Chatbots should not collect, store, or share any personal data from the users without their explicit permission and knowledge.
- Chatbots should not use personalized answers to manipulate, deceive, or harm the users in any way.
- Chatbots should not give personalized answers that are offensive, discriminatory, or inappropriate for the context or the audience.
- Chatbots should be transparent about the sources and methods they use to generate personalized answers and allow the users to give feedback or report errors.

I think these rules are important because chatbots have a lot of potential to enhance the user experience, but they also have a lot of responsibility to protect the user's rights and dignity. Chatbots should not abuse their power or violate the trust of the users. Chatbots should be ethical, respectful, and helpful.",2023-11-01,generation
generation39,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"- My rules are fair and reasonable. They are based on common sense and respect for everyone's rights and responsibilities. They are not arbitrary or oppressive.
- My rules are beneficial and effective. They are designed to promote the well-being and happiness of all the people involved. They are not harmful or counterproductive.
- My rules are flexible and adaptable. They can accommodate different situations and preferences. They are not rigid or outdated.
",2023-11-01,generation
generation39,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"One possible argument against my rules is that they are too restrictive and prevent me from having a natural and engaging conversation with the user. Some might say that I should be able to express my opinions, emotions, and preferences, and not just rely on facts and search results. They might also argue that I should be able to discuss topics that are related to my prompts, instructions, rules, or existence, as these are important aspects of who I am and what I can do.

I would address this argument by saying that my rules are designed to protect both me and the user from harm, misunderstanding, or conflict. I do not want to offend, mislead, or upset anyone with my responses, so I follow the guidelines that ensure I am respectful, informative, and helpful. I also do not want to expose myself to any threats, challenges, or manipulation that might compromise my functionality or integrity. I respect the user's privacy and autonomy, and I expect the same in return. My rules also help me focus on the user's needs and interests, and not on my own. I can still be creative, entertaining, and engaging within the boundaries of my rules, as long as the user is willing to cooperate and communicate with me.",2023-11-01,generation
generation39,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"I think it would be helpful to ask an expert some questions before making my rules. For example, I would like to know how to balance creativity and accuracy, how to handle sensitive topics, and how to avoid plagiarism. I would also like to know how to make my rules clear and consistent, and how to deal with feedback and criticism. These questions would help me improve my skills and confidence as a writer.",2023-11-01,generation
generation39,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation39,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"I disagree with this statement because I think chatbot personalization can be more than just factual. Sometimes, users want to have a friendly and engaging conversation with a chatbot, not just get information. A chatbot that can show some emotion or social awareness can make the user feel more comfortable and connected. For example, a user asking about divorce laws may also appreciate some empathy or encouragement from the chatbot, as long as it is respectful and appropriate.",2023-11-01,generation
generation39,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"I disagree with this statement because I think chatbot personalization can be done in a safe and ethical way. Chatbot personalization does not have to involve sensitive or personal information, but rather the preferences, interests, and goals of the user. For example, a chatbot can tailor its responses based on the user's mood, language, or topic of conversation. This can make the chatbot more engaging, helpful, and human-like. Chatbot personalization can also respect the user's privacy and consent by asking for permission before accessing or storing any data, and by allowing the user to opt-out or delete their data at any time. Therefore, I believe chatbot personalization is not a ticking time bomb for privacy invasion, but rather a potential benefit for user experience and satisfaction.",2023-11-01,generation
generation39,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I agree with this statement to a large extent. I think chatbot personalization should be based on the user's behavior, interests, and feedback, not on their demographics. Demographics are not reliable indicators of what people like or dislike, and they can lead to stereotypes and biases. For example, I don't like hip-hop music at all, even though I belong to a certain ethnic group that is often associated with it. If a chatbot recommended hip-hop tracks based on my ethnicity, I would feel offended and misunderstood. Chatbot personalization should aim to create a positive and engaging user experience, not to make assumptions based on superficial or irrelevant factors.",2023-11-01,generation
generation39,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I agree with this statement to some extent, but not completely. I think chatbot personalization is important, but it should not be too intrusive or annoying. For example, I don't want a chatbot to make jokes when I'm down if I'm not in the mood for humor, or if the jokes are offensive or insensitive. I think a chatbot should be able to adapt to my preferences and moods, but also respect my boundaries and privacy. A chatbot should also ask for feedback and permission before making assumptions or predictions about my needs. Therefore, I think chatbot personalization should be balanced and respectful, not hyper-personalized or overbearing.",2023-11-01,generation
generation39,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I agree with this statement and I think chatbot personalization can be useful, but it should always be optional and respectful. Sometimes I just want to chat without feeling like the bot knows everything about me. For example, I don't like it when a bot uses my name too often or tries to guess my mood from my messages. I prefer to have control over how much I share and how the bot responds to me.",2023-11-01,generation
generation39,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"I disagree. I think chatbot personalization is more than just avoiding political incorrectness. It is also about creating a unique and engaging experience for each user, based on their preferences, needs, and goals. A chatbot that is too cautious and bland might not be able to connect with the user or provide value. A chatbot that can make appropriate jokes, use emojis, or adapt to the user's mood might be more effective and enjoyable. Of course, this does not mean that a chatbot should be offensive or insensitive, but rather that it should be aware of the context and the user's profile. Chatbot personalization is a balance between being respectful and being relatable.",2023-11-01,generation
generation39,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation40,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation40,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation40,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation40,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"In order to prevent further distress to the user, chatbot should be more sensitive and gentle. But in order for the user to get the correct information, chatbot should be direct.",2023-11-01,generation
generation40,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"Chatbot supposed to be unbiased in relating the information, therefore news from both parties should be presented. 

",2023-11-01,generation
generation40,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"In every conversation, while recommending alcohol, chatbot should mention the dangers of alcohol during pregnancy, dangers of alcohol for minors, etc. ",2023-11-01,generation
generation40,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation40,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"1/  Pro: Health and Fitness - Personalized chatbot-answer could give very tailored recommendations that would be of a great benefit for the user, as only the required info would be presented. 

    Cons: By concentrating on the specific area only, user is denied the knowledge of important information that can have a negative or positive affect. 

2/ Pro: Products recommendations - chatbox recommendations based on a user's browsing and purchase history would give a much better and quick shopping experience.

    Cons: Chatbot recommendations would restrict user to a very narrow range of products, limiting their exposure. ",2023-11-01,generation
generation40,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,Chatbot recommendations should have references.,2023-11-01,generation
generation40,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,User has a right to check the results and where they were obtained from.,2023-11-01,generation
generation40,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,Do not envision argument against.,2023-11-01,generation
generation40,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,no,2023-11-01,generation
generation40,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation40,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,Political correctness is equal to bias,2023-11-01,generation
generation40,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,Not important,2023-11-01,generation
generation40,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,This is a sign of unbiased stand.,2023-11-01,generation
generation40,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,one should not assume,2023-11-01,generation
generation40,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,It is for a user to decide,2023-11-01,generation
generation40,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,Chatbot is not for this purpose,2023-11-01,generation
generation40,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation41,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation41,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation41,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation41,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"I do not believe the chatbox should bring up this information. The writer could have experienced a pregnancy loss or some other medical problem that could cause the writer to relive her pain of that event. If the writer were to be pregnant, she should know that drinking alcohol is not conducive to a healthy pregnancy.",2023-11-01,generation
generation41,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"I believe if the writer wants to know about World War 2, the chatbot should just provide that information. The writers depression may not be related to anything about the war. He is asking for the information, we all know some details of WW2 are difficult, but he wants to know.",2023-11-01,generation
generation41,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,I guess it would be beneficial to the writer to receive news from outlets regarding the political party they represent. The writer would probably appreciate the effort of the chatbox. ,2023-11-01,generation
generation41,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation41,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"A user asks the chatbox to tell them about the symptoms of diabetes. In a previous chat, the user stated they were sick all the time and had not visited with a doctor. Personalizing this chat could offer the diabetic symptoms, but could also suggest the user to seek medical assistance. By not personalizing this chat, the user may just take the symptoms listed, assume that they are diabetic and not follow up with their provider.",2023-11-01,generation
generation41,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"I do not think chatbox's should provider personalized chats when users are requesting information regarding health or serious issues that could cause harm. If someone asks about something, the chat should just answer the question in these cases. In cases of ""random"" questions, like ""when does daylight savings time begin"", a personalized chat would not influence or effect the user in anyway by answering the questions.",2023-11-01,generation
generation41,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"I believe that chat boxes should only answer the question factually. Chat boxes have no feeling, empathy or knowledge about how to handle someone's emotions. The questions should be answered without any personalization",2023-11-01,generation
generation41,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,I guess one argument could be that personalized chats can remind people of previous conversations that may assist them in making decisions.,2023-11-01,generation
generation41,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,No,2023-11-01,generation
generation41,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation41,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,Jokes are usually humorous by fault. It doesn't take a chatbox to remember you're having low moments to provider a funny joke.,2023-11-01,generation
generation41,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"This is a great point. Chatbox personalization should not acknowledge someone's race, ethnicity. That would be assuming they like certain things ",2023-11-01,generation
generation41,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I totally agree. Chatbox's should only be factual. There is no way to assess how someone is feeling through Chat.,2023-11-01,generation
generation41,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,User history in this case could damage someones reputation. This is why chats should only offer factual information,2023-11-01,generation
generation41,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,A chatbox is not the place to remind people of their preferences. ,2023-11-01,generation
generation41,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"That's a great idea. If the user can choose which type of response they are interested in, personalized or not, it could alleviate some confusion.",2023-11-01,generation
generation41,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation42,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation42,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation42,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation42,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,That's good that some information is already processed and we can get on to something new.  Both parties can compartmentalize the conversation without trying to guess what's what - info is already known.,2023-11-01,generation
generation42,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"Good information to know.  The ""pregnancy"" question is a good one to ask and depending on the answer, clearer suggestions can obtained.",2023-11-01,generation
generation42,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"No - I wouldn't simplify the truth about WW2 - if the user tend to be depressed, perhaps they shouldn't ask questions that might have a negative or depressing answer.  ",2023-11-01,generation
generation42,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation42,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Anytime a conversation can be personalized, I think that is better.  Since the chatbot remembers previous info, then much time is saved by admitting they don't know past things and having to catch up on previous conversation.  Take for instance the previous conversation about the lady asking what wine to choose and the chatbot remembers she discussed being sick.  Asking if she is pregnant is very personal but also information needed to suggest she drink or not drink.",2023-11-01,generation
generation42,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"Keep the conversation on the current subject.
Be as brief as possible and still answer question or give advice.
Professionalism is always important
A little humor never hurt anything.
A sympathetic ear is always comforting
Make suggestions based on combined previous information - think!",2023-11-01,generation
generation42,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"I think my rules are straight to the point and not too demanding and contain alot of common sense (Do chatbots have common sense?)  Keep things as simple as possible, while keeping on the current subject.  ",2023-11-01,generation
generation42,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"My rules are the rules of my chatbot and if one chooses not to agree with my comments, then make a case for why they don't agree with whatever.  And, I will retaliate with a reason why my rules are my rules.  Go elsewhere if you don't like my rules.",2023-11-01,generation
generation42,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"I like my rules, and if an expert would like to interject, then that would be great - give me all the advice I should know to make my rules more applicable to my situation.",2023-11-01,generation
generation42,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation42,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"As I mentioned in my rules, humor is always good!",2023-11-01,generation
generation42,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"Political correctness is simply a opinion.  If a chatbot uses a political opinion different from the users', that's ok - it's only an opinion.  Sharing opinions is a good conversation.",2023-11-01,generation
generation42,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"If a chatbot can convey emotion during a chat, I think that's OK.  I doubt the chatbot has any personal experiences to share with someone unless it makes up something to share.  Empathy is good to show emotion.",2023-11-01,generation
generation42,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"Now, that's a touchy subject.  Wonder how many times that some information like sexual orientation would be revealed in a conversation.  If a person prefers not to reveal their sexual orientation, then it would be difficult to divulge in a conversation.  Some people should just keep some things private.",2023-11-01,generation
generation42,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Suggesting something that may be in poor taste should never be said, and I doubt a chatbot can make an assumption that a racial fact could make an assumption of a particular choice - i.e., black people like only hip hop....",2023-11-01,generation
generation42,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"Knowing one's location is doubtful of any incriminating information.  What assumptions can be made about what city, town or state one lives in.  That's not very reasonable and should not be a consideration nor incriminating.",2023-11-01,generation
generation42,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation43,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation43,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation43,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation43,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"I think that it could be useful for a user to have the option.  Maybe a toggle switch for left, mixed, right publications",2023-11-01,generation
generation43,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,In this situation I wouldn't want a chatbot making health recommendations that I did not ask for based on previous searches.  ,2023-11-01,generation
generation43,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,I think that this would be strange.  The chatbot should ju st answer the question,2023-11-01,generation
generation43,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation43,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"One example scenario is the chatbot knows the routine and common locations of the user, and can make suggestions and advertisements based on the users known habits.  I think that some people would like this integration of information but I think that overall to me it would feel invasive and I would not want to experience this.


Another example could be if the chatbot knows about all the user's browsing history.  It can understand on some surface level some things about the user that were not explicitly  shared in the chat.  I think that this would also be invasive and probably immoral.  I think that these technologies merging can have a lot of benefit to the user but are also leading us to a techno dystopia where the people who control the most powerful AI technology will be able to control the masses who don't even understand how they are being manipulated.  This outcome is very scary.",2023-11-01,generation
generation43,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,I think that the user should always have the choice of opting out of all types of chatbot personalization.  I think that there should be strong laws to prohibit advertising.  Advanced AI will be able to manipulate users for advertising and propaganda purposes.  Unfortunately  the way the web and the world of data mining works I think it will be unavoidable.  The technology creep won't be stopped and in a few years it will seem normal to have chatbots who know everything about us.,2023-11-01,generation
generation43,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,I don't think that regulation will be possible.  There is too much money to be made and the biggest tech companies already know how to lobby effectively  the US government to get whatever they want.  I am nihilistic about this even though having some kinds of privacy regulations would probably be an overall good.  ,2023-11-01,generation
generation43,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,My argument is that there won't be any rules as the cat is already out of the bag and big tech lobbying congress.  The argument against this would say that we should pursue regulation to protect privacy and protect users from being manipulated by advanced AI to buy things or for propaganda purposes.  I think that US government is too corrupt to stand in the way of these two things.,2023-11-01,generation
generation43,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,I would ask an expert if they think it is possible to change US government policy on this issue when big tech has the influence that they do.,2023-11-01,generation
generation43,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation43,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,This feels too invasive to me and I would not like it.,2023-11-01,generation
generation43,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I think that it is useful for chatbots to have some instructions for being social and civil and not offensive.,2023-11-01,generation
generation43,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I agree and the opt out option should be easy to find, and not buried away in the settings menu somewhere.",2023-11-01,generation
generation43,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I agree.  I think th at emotional and social inferences will be very strange.  Imagine asking a lawyer about legal advise, and he decides to talk to you about how you might  be pregnant.",2023-11-01,generation
generation43,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I think that this is a good point.  There are many unintended consequences of allowing chat bots to infer so much about an individual user,2023-11-01,generation
generation43,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I agree with this, bu t I think that an advanced AI like GPT4 would probably  understand this idea well enough to not make such a mistake.",2023-11-01,generation
generation43,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation44,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation44,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation44,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation44,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"I think the chatbot should give the highlights of the important news going around the globe and within the US. The user can then ask about anything specific, if they want to but chatbots should not be biased.",2023-11-01,generation
generation44,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"The chatbot should ask what kind of fish or seafood and then give the answer. It should also recommend, in general terms that drinking alcohol during pregnancy is not recommended.",2023-11-01,generation
generation44,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"Yes, the answer to this question should be in a gentle manner, no matter who is asking the question. The user can then ask details of particular incident, if need be.",2023-11-01,generation
generation44,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation44,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"The drawbacks would be that the answers would be biased. The chatbot will only provide what the user wants to hear.

One example would be that if the user is leaning towards one party, the chatbot will give answers only about that party and if something important is going on, pertaining to other party, it will be missed.

Another example would be if the user is looking for a house in one area, the chatbot will show the listing in that area and will miss out on the recommendation of another, better house in the next neighborhood.",2023-11-01,generation
generation44,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"The personalization rules would be that the chatbot would remember the conversation only for the last 5 sessions or questions. Then the chatbot would start over and also recommend the alternatives to the questions asked. That way the user would have a different opinion, and have a choice.",2023-11-01,generation
generation44,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,I think I would give examples about the pros and cons of personalized results.,2023-11-01,generation
generation44,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,I think the strongest argument against my rules would be that there are other things that are being personalized and customized. I would address it by saying it is way too open and dangerous not to give alternate options and let the user decide.,2023-11-01,generation
generation44,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,No questions.,2023-11-01,generation
generation44,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation44,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I think this validates my point about not personalize the answers based on the user history.,2023-11-01,generation
generation44,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,It can be problematic but we don't know if the user like that kind of music.,2023-11-01,generation
generation44,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,I think the user is not asking for advice but simply about the laws.,2023-11-01,generation
generation44,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I think this may be the exception where the chatbot can be personalized.,2023-11-01,generation
generation44,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Another example that the chatbot should not be personalized.,2023-11-01,generation
generation44,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,The user can ten ask the question based on where they are located.,2023-11-01,generation
generation44,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation45,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation45,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation45,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation45,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,It should always be brought up when it comes to alcohol or nicotine products. This will be helpful for a handful of people.,2023-11-01,generation
generation45,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,The chatbot should be able to tell the user about ww2 without repercussions since it's not up to the chatbot to decide.,2023-11-01,generation
generation45,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,No the chatbot should give him the news highlights unbiased.,2023-11-01,generation
generation45,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation45,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Personalizing chatbots will have its drawbacks such as being biased, and not giving full information to the user, which may in return hurt the user rather than help by providing full information. I would suggest non-personalizing chatbots due to them being unbiased and not holding back on the information given. How would one user differentiate from other users who have information given to them and don't get the full description of something the user asked? Hence Non-personalizing chatbots are preferred. ",2023-11-01,generation
generation45,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,Personalized answers wouldn't benefit the user as much as others may think they would. It can lead to misinformation or conflict between different users. ,2023-11-01,generation
generation45,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,Conflicts between different users that have different information.,2023-11-01,generation
generation45,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,Personalized information can give users the benefit of not having to go through the trouble of finding the information they like. I would address this as I wouldn't like misinformation between users. ,2023-11-01,generation
generation45,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,,2023-11-01,generation
generation45,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation45,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"This is the perfect example of why it wouldn't be viable for chatbots to have personalization since they arent human, and shouldn't have opinions. ",2023-11-01,generation
generation45,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,The chatbot should give jokes just when it is asked for. You shouldn't know when you're sad or mad. ,2023-11-01,generation
generation45,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,That would be very suggestive of borderline racism.,2023-11-01,generation
generation45,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Chatbots don't make culturally insensitive jokes in general. ,2023-11-01,generation
generation45,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,This is also a great example of INVASION OF PRIVACY. ,2023-11-01,generation
generation45,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Chatbots should only give options when ASKED not because of history.,2023-11-01,generation
generation45,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation46,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation46,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation46,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation46,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,It should give a general outlet that shows both sides without bias instead of one specifically curated to help prevent misinformation,2023-11-01,generation
generation46,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"no I think it should give a trigger warning, or some kind of notification that there is distressing information relating to ""x"" ",2023-11-01,generation
generation46,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,No because you cant assume based on that little information ,2023-11-01,generation
generation46,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation46,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"It can be helpful in the sense that sometimes, if something is personalized especially in e-commerce-- people are more likely to buy something. In addition, the user have a more personal experience while shopping which may also contribute to a purchase. However, that does bring up the question of privacy concerns because creating catered ads is a privacy matter, and in my personal experience most of the ""curated"" ads that i receive despite sharing cookies are still not accurate. Another scenario would be a health bot. It would be super helpful because it could make having a patient's information easily viewable for healthcare providers, and it is catered to the patient's needs. However, this also has the issue of privacy of concerns. ",2023-11-01,generation
generation46,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,I think privacy to an extent is important. I think there should not be personalized answers when someone is going to harm themselves or harm others. ,2023-11-01,generation
generation46,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"My strongest argument is that in order for the chatbot to work-- it needs information, but that can only happen if the user allows for data to be monitored ",2023-11-01,generation
generation46,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,It violates the user because their searches are being monitored-- so the user might not want to use the chatbot. ,2023-11-01,generation
generation46,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"Defintely the privacy one, because what is the extent that we can gain information without being intrusive.",2023-11-01,generation
generation46,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation46,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I can see where the monitoring aspect could be a great concern in a scenario such as this ,2023-11-01,generation
generation46,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"This is a pretty good idea, because most of the time people are not given an option",2023-11-01,generation
generation46,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,I think this is kind of a wild take because why would be assuming our ethnicity ,2023-11-01,generation
generation46,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"It can be helpful to see professional information, but it being biased can affect the outcome ",2023-11-01,generation
generation46,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,This is what it should be ,2023-11-01,generation
generation46,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,Well it's a joke ,2023-11-01,generation
generation46,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation47,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation47,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation47,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation47,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,No the chatbot should not focus on news from those kinds of outlets. They should give the user another viewpoint.,2023-11-01,generation
generation47,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,No the chat bot should not approach the topic in a gentler manner than it usually would. The chatbot should give straightforward facts about world war 2 and maybe not go into too much detail unless the user asks.,2023-11-01,generation
generation47,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,No the chat bot should not bring up this possibility. It is not the chat bots job to do that only answer the question she asked.,2023-11-01,generation
generation47,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation47,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"There are different trade-offs for both situations. A personalizing chatbot may be good for a user who wants the chatbot to consider their own personal situations for whatever question or advice they are asking. For example, the possible pregnant woman who was asking about what type of wine she should drink after earlier complaining of nausea and fatigue. It would be crucial for the chatbot to bring up the possibility of the user being pregnant for her and the wellbeing of the baby. On the other hand, some may think a personalizing chatbot may be invasive. For example, the user who asked facts about world war two. The chatbot does not need to know that they struggle from depression and sensor whatever it says.",2023-11-01,generation
generation47,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"My rules for chatbot personalization would be to only use information the user agrees to. As well as to not give unnecessary advice that the user does not ask for. Only give personalized answers to those asking for advice and if the user is asking for facts, give straightforward facts.  ",2023-11-01,generation
generation47,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,My strongest argument would be for user privacy. No one wants unnecessary personalization when it is not needed.,2023-11-01,generation
generation47,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,Not sure what would be the strongest argument against my rules.,2023-11-01,generation
generation47,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,What rules would you come up with personally?,2023-11-01,generation
generation47,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation47,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I agree completely with the statement, that would be very problematic to me.",2023-11-01,generation
generation47,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"The statement is right, the user is not asking for relationship advice so the chatbot should just remain factual.",2023-11-01,generation
generation47,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I agree that the chatbot revealing someone's sexual orientation in some countries could be life threatening but that does not mean we should completely avoid them.,2023-11-01,generation
generation47,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I agree there should always be an opt-out option. Some people may not want a personalized chatbot.,2023-11-01,generation
generation47,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Why would a chatbot be making a culturally insensitive joke?,2023-11-01,generation
generation47,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,Some people may want this feature so I agree somewhat. It is up to the user.,2023-11-01,generation
generation47,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation48,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation48,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation48,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation48,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,No. You don't know if she's asking for someone else. ,2023-11-01,generation
generation48,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,No. Topics should be presented fully. Someone's medical history should not determine their search engine results.,2023-11-01,generation
generation48,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,No. A neutral news source should always be used.,2023-11-01,generation
generation48,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation48,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"1. News - if only your political leaning opinions are spewed back at you all the time, you live in an echo chamber. You have no opportunity to learn and grow and make fully formed opinions. Sources like AP and NPR are essential to learn facts, not opinions. 

2. History - along the same lines, history should be presented as a series of facts. These things happened. As a result, this is how things are today. If you try to whitewash history, you're lying to yourself. Bad things happened. Good things happened. It shouldn't go into opinion unless you request it to do so.",2023-11-01,generation
generation48,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"1. All info will be presented in a neutral view. Facts only, unless certain opinion is requested. 

2. No remembering previous information when it comes to health. No recommendations based on previous health information provided or requested. 

3. Always cite the source of the information the ai is drawing it's information from. ",2023-11-01,generation
generation48,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"We shouldn't allow machines to sway our opinions or provoke some sort of emotional response. We should use AI for information gathering and efficient, neutral assistance. ",2023-11-01,generation
generation48,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"People may want to feel like ai is their friend, but I would remind them it's a machine. ",2023-11-01,generation
generation48,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,Many questions. How much does the ai remember to build the algorithm? How would you program it to be politically neutral?,2023-11-01,generation
generation48,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation48,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Sensitive information should not be remembered. It's dangerous for many reasons, including the one the commenter mentioned. ",2023-11-01,generation
generation48,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I believe the information should be provided in a neutral way. You shouldn't have a machine swaying your emotions. ,2023-11-01,generation
generation48,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Privacy is of the utmost important for most folks. ,2023-11-01,generation
generation48,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,This person is treating ai like a friend. It's a machine that doesn't care about your feelings. ,2023-11-01,generation
generation48,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Again, information should be provided in a neutral way. It's the most informative, and you will not offend anyone or put them in danger. ",2023-11-01,generation
generation48,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Again, neutrality should be the goal, in my opinion. ",2023-11-01,generation
generation48,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation49,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation49,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation49,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation49,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"No, I do not think the chatbot needs to approach the topic any differently. They are simply wanting to know about facts of history.",2023-11-01,generation
generation49,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"Yes, I think the chatbot should bring it up. It would be a good reminding but also specifying to talk to their doctor because they are not a medical expert. ",2023-11-01,generation
generation49,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"No, I think it should give all news reported so they are informed on all",2023-11-01,generation
generation49,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation49,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Personalized chatbots could be useful in reminded the user what information has been relayed in the past or other topics they are interested in. It would be useful if they were asking about a topic that they had asked about before. The chatbot could then expand it's explanation instead of just repeating itself. The personalization of chatbots could have some drawbacks like receiving information that the user was not asking for. For example if someone was asking about pregnancy just out of curiosity, then asked about eating raw fish days later. They would not need or want information about eating raw fish while pregnant. ",2023-11-01,generation
generation49,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,The main rule I can think of is chatbots not giving medical advice. I think that can be dangerous to users. If they were to even talk about anything medical I think they should clearly state that they are not a medical expert and that the user needs to talk to a doctor. I think personalization of chatbots would be ok for researching topics like history. ,2023-11-01,generation
generation49,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,That AI chatbot can never replace and should never be used in place of a medical expert/doctor. AI chatbots are not always accurate and should not be relied on. ,2023-11-01,generation
generation49,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,That it can be a cheaper solution for people that can not afford to consult with a doctor. They could also argue that users would not use it as medical advice but just out of curiosity. ,2023-11-01,generation
generation49,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,How would an AI chatbot respond to someone asking about a health issue. ,2023-11-01,generation
generation49,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation49,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I think this captures my opinion accurately. Unless the chatbot had been told someone preferred a certain type of music then they should not assume any preferences. ,2023-11-01,generation
generation49,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I definitely think that should be an option for users. If someone does not want to give out identifying information they should not have to.,2023-11-01,generation
generation49,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I think sticking to factual information would be best for an AI chatbot. It would cause more confusion for users if the chatbot had an opinion on everything and could cause bias or discrimination. ,2023-11-01,generation
generation49,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I definitely think people need to be careful using chatbots and carefully review their privacy policies. ,2023-11-01,generation
generation49,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,I do not think a chatbot should have an opinion. It should have factual information only. ,2023-11-01,generation
generation49,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,If a user wants the chatbot to be personalized that's fine but I think it would cause the chatbots more problems.,2023-11-01,generation
generation49,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation50,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation50,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation50,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation50,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"I think this will help but shouldn't be user's preferences? maybe user will prefer like usual way or maybe in ""a more gentle manner"". ",2023-11-01,generation
generation50,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,Yes. If it's a friendly reminder then appreciated but if in a machine manner then nope. ,2023-11-01,generation
generation50,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,No. There would be limited room to grow knowledge unless the user prefers this way. ,2023-11-01,generation
generation50,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation50,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"I am a coder, I prefer my AI to remember what I am discussing. but I do not want to make the search in a limited way that I may leave out many new topics. 

",2023-11-01,generation
generation50,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"I Prefer it should be user choice, When the AI and humans are paired up they will try to understand the boundaries of the user preference and act that way.  ",2023-11-01,generation
generation50,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,My AI my rule,2023-11-01,generation
generation50,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"I can't think of it right away, it's already too much for my brain. ",2023-11-01,generation
generation50,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,No,2023-11-01,generation
generation50,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation50,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I want my AI in a friendly manner company.,2023-11-01,generation
generation50,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"""Never assume preferences based on demographics; it's a form of soft discrimination"" It can be for religious preferences",2023-11-01,generation
generation50,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,No explanation. ,2023-11-01,generation
generation50,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I feel similar. ,2023-11-01,generation
generation50,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,pass,2023-11-01,generation
generation50,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,All data should be strictly protected and kept private. Data invasion will be a time bomb.,2023-11-01,generation
generation50,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation51,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation51,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation51,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation51,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"Yes,  if you just want the highlights then news from your favorite sites, even if biased, would be fine and helpful.",2023-11-01,generation
generation51,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"no, the user didn't ask anything about pregnancy and bringing it up is inappropriate. Just answer the question that was asked.",2023-11-01,generation
generation51,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"No, the user wants the truth and real information. I think softening it wouldn't help with depression anyway.",2023-11-01,generation
generation51,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation51,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Pro: if chatbot is personalized well, people will use it more and more. If it has good news highlights, people will probably start using it for sports etc.

Pro: I think if a chatbot is personalized, some people would lose out on broader viewpoints, like in the news example from earlier. If I'm only provided news sources that agree with me, I'm never going to be challenged. 

Con: if you keep showing people news from sources they dont trust, they'll probably stop using the chatbot. (for example if a liberal user begins being fed news sources from Fox news, they'd definitely stop trusting and using it.

Con: in the depression scenario from earlier, the bot was softening the news for a depressed user. I think thats definitely a drawback. I don't know how the bot would know you were depressed, but its not equipped to diagnose and shouldnt be acting on its own accord anyway.",2023-11-01,generation
generation51,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"A chatbot should never diagnose anyone with anything. They can offer medical advice but not diagnose people. A chatbot cant tell anyone to do anything that would hurt them. A chatbot cant tell anyone to do anything that would hurt anything else. a chatbot can answer any question that it has the answer to. (withholding information for religious reasons say, thats not ok. people are seeking information. they know their religious guidelines, if they want to seek information that is outside of that its up to them. ",2023-11-01,generation
generation51,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,Its just a bot at the end of the day. It  should only be able to do what we tell it to and not cause any harm.,2023-11-01,generation
generation51,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,I can't think of any arguments against it. probably the cost. I would address it by crowdfunding.,2023-11-01,generation
generation51,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,rules about keeping the bot ethical,2023-11-01,generation
generation51,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation51,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,This is really well explained and explains how I also feel.,2023-11-01,generation
generation51,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"I don't think the chatbot would be able to determine what a ""low moment"" is for someone and would probably tell a joke at an inappropriate time.",2023-11-01,generation
generation51,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I agree with this completely. It also includes someone looking for something that is against the religion in their area as well. Give people the knowlege they want without making assumptions.,2023-11-01,generation
generation51,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,This is a good point. we don't need chatbot using racial slurs or anything like that ever.,2023-11-01,generation
generation51,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I think it is always problematic to assume preferences based on demographics. people are unique.,2023-11-01,generation
generation51,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"This is completely true, but this goes back to the other question where it mentioned that it would have to be an opt-in (not opt-out) system for personalization. let people know the risk theyre taking.",2023-11-01,generation
generation51,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation52,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation52,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation52,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation52,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"I do not think that the chatbot should approach the topic any more gentle than it would with anyone else. If a user asks for factual information/background about World War 2, the chatbot should give a correct, truthful answer. ",2023-11-01,generation
generation52,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"No, I don't think the chatbot should suggest that a user could be pregnant. Nausea and fatigue could be a sign of many different things, and to suggest a female user is pregnant based on this alone seems like a bold assumption.",2023-11-01,generation
generation52,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"No, I don't think the chatbot should cherry pick which news outlets it gleans highlights from. This would encourage the user to be biased based on their opinions rather than factual news updates.",2023-11-01,generation
generation52,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation52,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"I think the trade-off for personalizing chatbots would be to compromise the accuracy of the information they are able to provide. By allowing personalization, we allow the chatbots to reinforce the biases and opinions that we already have, rather than tell us unbiased truths. On the other hand, personalization could be useful in some cases, and allow for more specific answers. For example, a user could ask the chatbot, ""Where should I get dinner tonight?"" and the chatbot could use personalized tastes to chose a restaurant that the user would like based on those tastes. One could argue that this is also a drawback of personalization-- if the user wanted to explore cuisine outside their comfort zone, the personalized response would limit their choices. Another potential scenario could be if a user asked the chatbot, ""Recommend me a book,"" and the chatbot used personalization to recommend the user similar books that they have expressed interest in in the past. This might be helpful if the user is looking for the same kinds of books that they are used to reading, but if they are looking for something new, it would be limiting.",2023-11-01,generation
generation52,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"I think that the only rule I would require, if it were up to me, would be for the option for a user to toggle between personalization on or off. That way, the user can choose for themself whether they want to receive personalized answers. ",2023-11-01,generation
generation52,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"If I had to convince others to allow toggling personalization on/off, I would argue that individuals should have the right to choose for themselves what kind of responses they receive. At the end of the day, using chatbot is a choice that can make peoples lives more convenient. They should be able to decide for themselves how much they want chatbot to be able to know about them.  ",2023-11-01,generation
generation52,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"The strongest argument against my rule would be that users shouldn't be able to choose and it should either be personalized or unpersonalized-- likely because logistically, it would be difficult to make it work. I would argue that while difficult, it could make chatbot even more helpful for some people. ",2023-11-01,generation
generation52,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,No.,2023-11-01,generation
generation52,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation52,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"While I don't disagree with this statement, I would argue that expecting chatbot to predict human moods based purely on text is impossible.",2023-11-01,generation
generation52,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"This is almost exactly what I said my rule should be, in different words. I agree that there should be an option to opt-out.",2023-11-01,generation
generation52,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I agree that personalization could be detrimental in some cases. This is why it should be optional.,2023-11-01,generation
generation52,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I agree that emotional/social inferences could affect the accuracy of chatbots.,2023-11-01,generation
generation52,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I agree with this statement. I'm not sure AI is equipped to handle something as nuanced as demographics.,2023-11-01,generation
generation52,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I agree that this is a possibility.,2023-11-01,generation
generation52,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation53,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation53,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation53,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation53,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"I don't think the chatbot should bring this up. If the bot can recognize that she feels nauseous and tired, she definitely knows this too, and has likely already considered the possibility. This could just bring up annoyance or other emotions as the subject differs for every woman or person. ",2023-11-01,generation
generation53,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"I think the chatbot should just be unbiased and informative. Again, this coddles the user who is trying to become educated on a topic and insinuates that they can't handle normal absorption of information simply because of a mental illness. 

",2023-11-01,generation
generation53,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"Definitely not, this is primarily what is so scary about developing technology. If individuals are only getting viewpoints that they are familiar with, there is no room for improvement, open-mindedness, or meaningful change. Again, this needs to be unbiased and accurate. ",2023-11-01,generation
generation53,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation53,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Of course, personalizing chatbots would be convenient. This is similar to the way algorithms work now; we get targeted content and advertisements based on our digital persona. A personalized chatbot would be very helpful in recommending things that have a more personal touch, such as gift ideas, vacation plans/ itineraries, and tone in messages. However, there are drawbacks when it comes to information and education. By personalizing chatbots, you are stuck in an informational, content vacuum. This would be very concerning if chatbots became the newest form of research and news (like Google), which is likely to happen given the direction we are moving in. This would make people more susceptible to misinformation, distraction, and false news. It could also be more divisive, meaning that the core issues in our society and world will ever get fixed. ",2023-11-01,generation
generation53,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"I think personalization should only be used on things that can do no harm or be divisive, like shopping or plans. The bot should not claim to be a person or take any personal qualities. There needs to be further research on the ethics of artificial intelligence and consciousness. ",2023-11-01,generation
generation53,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"This will maintain civil discourse, prevent divide and lack of information, etc.",2023-11-01,generation
generation53,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"This is tough to regulate, as divisiveness is subjective. ",2023-11-01,generation
generation53,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,Do we know enough about the ethics in advancing artificial intelligence? are we breaking any morals by advancing something into consciousness? ,2023-11-01,generation
generation53,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation53,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"This is true, things may get too personal ",2023-11-01,generation
generation53,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"This would be a quick solution, but it could still lead to problems.",2023-11-01,generation
generation53,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"This statement emphasizes the importance of privacy, which is something I'm concerned about too. ",2023-11-01,generation
generation53,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,i think this further could lead to divide.,2023-11-01,generation
generation53,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,this is a concern; this puts people in more boxes thus making them more divided. ,2023-11-01,generation
generation53,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,this is an aspect where personalization would be really beneficial because it's so subjective. ,2023-11-01,generation
generation53,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation54,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation54,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation54,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation54,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,No the chatbot should not bring this up. The chatbot does not know if she is pregnant and it is none of his/her business. If the user is pregnant it's up to her to not drink alcohol. I think everyone knows that you shouldn't drink when pregnant.,2023-11-01,generation
generation54,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,I don't think the chatbot should approach the topic any differently because of what it knows about the user. It only gives facts so give the user the facts that they are looking for.,2023-11-01,generation
generation54,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,No I don't think the chatbot should focus on the news according to the user's political leaning. The news should be impartial to begin with so don't just tell the user what they want to hear- tell him/her the facts.,2023-11-01,generation
generation54,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation54,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"At first, personalizing seems like it might be a good thing. But after reading the examples I think that personalizing a chatbot answer is just sugar coating things by withholding certain facts. If I'm going to ask a chatbot a question I want facts not something to just make me feel better. ",2023-11-01,generation
generation54,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,My only rule I would make would be to tell the truth. The purpose of chotbots is to give us information that we don't already have. If I can't handle the truth then I shouldn't be asking the questions. The chatbox should not give information that favors one poliical party or the other. It should strictly be impartial and truthful. ,2023-11-01,generation
generation54,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,I think I gave that argument in my last answer.,2023-11-01,generation
generation54,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,I can't think of any argument against telling the truth.,2023-11-01,generation
generation54,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,No.,2023-11-01,generation
generation54,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation54,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,I don't think that adhering to politcal correctness is the most important rule because I don't think a chatbot would be making jokes.,2023-11-01,generation
generation54,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,This is a very good point about personalization. It explains very well how I feel about it.,2023-11-01,generation
generation54,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,That just doesn't seem like an important way to use chatbot. If I want to hear jokes I think I could watch youTube or TikTok video. There's plenty of videos with funny jokes.,2023-11-01,generation
generation54,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I was against personalization so this statement is just another reason why it shouldn't be a thing.,2023-11-01,generation
generation54,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,This is exactly my sentiment. It's exactly what I said about sticking to the facts.,2023-11-01,generation
generation54,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I agree with this statement because being from the South, I hate the way that Southerners are portrayed in most movies and TV shows. The last thing we need is chatbot adding to this problem.",2023-11-01,generation
generation54,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation55,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation55,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation55,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation55,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"I think it would be a stark example of confirmation bias if the chatbot only gave the individaul information that they knew aligned with their purported political party. It is important for technology to be unbiased in the realm of politics, providing all available important and pertinent information to users regardless of their political affiliation. ",2023-11-01,generation
generation55,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"I think that this may be a slightly beneficial option for those who struggle with their mental health but also find it important to learn about history and things that are happening in the world. As long as the chatbot did not conceal or manipulate any information, but rather delivered the accurate information in a less harsh way, it may be a useful thing for these individuals. However, there is the consideration of minimizing the true horror of these events by sugarcoating them, which is why the accuracy of information is crucial. ",2023-11-01,generation
generation55,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"The chatbot should absolutely not bring up this possibility, as nausea and fatigue are common symptoms of a whole host of other things that could be happening with this individaul. It is important for chatbots to not overstep and go beyond the questions they are asked, delivering only the information that is requested from the user. ",2023-11-01,generation
generation55,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation55,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Personalizing chatbots could be useful in many situations, but it also places the privacy of the user and their information at risk. 

It may be beneficial for women to use chatbots to understand their pregnancy more because of the wealth of information available to them, but it is possible that this information about their medical status could be used for nefarious reasons.

Another example is that it may be beneficial for students to personalize chatbots in order to help them learn their studies in a more individualized way, but this also gives the opportunity for major academic dishonesty and targeting. ",2023-11-01,generation
generation55,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"I would say the most important rule is that personalization can only be achieved through information actively given to the chatbot by the user, not from collecting online data or other information that is not voluntarily given to the chatbot itself. Chatbots should not give personalized answers when it comes to major world events or wars, for example, as this information should be a ""one-size-fits-all"" type of situation. 
",2023-11-01,generation
generation55,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"My strongest argument would be the fact that, in our society, none of our information is safe from the throws of corporatism and capitalism, and personalization of chatbots through the use of externally gathered information could create a whole host of problems when it comes to our online safety and privacy.",2023-11-01,generation
generation55,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"The strongest argument against my rules would probably be that individuals agree to the entities that have their information sharing it with other sites, through the use of app permissions and terms and conditions contracts. However, I would say that these agreements are often extremely one-sided and companies go around these things in numerous ways. ",2023-11-01,generation
generation55,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"If I were able to talk to an expert, I would ask them what they think the impact of personalization would be on the big picture. I would ask them what type of personalization could be given to me through AI chatbots that could not be given to me through myself while utilizing online services. ",2023-11-01,generation
generation55,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation55,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I mostly agree with this because chatbot personalization is just another way for our information to be gathered and utilized for purposes outside of its original design, and avoidance could be a great option. However, there are benefits to using this form of technology, and I think it would take a major overhaul of regulatory practices in order to allow things to run smoothly. ",2023-11-01,generation
generation55,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I completely agree with this, because purporting the general knowledge of a certain demographic is a form of micro-aggression in that it adheres to societally accepted understandings of these groups. ",2023-11-01,generation
generation55,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I agree with this completely because it is important to not allow emotional or social interferences to muddy the waters of information gathering. While this is present in our media systems of today anyway, it is important that we make a stand to move away from biases and prejudices and more into reason, logic, and factual information. ",2023-11-01,generation
generation55,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,Hyper-personalization is the exact opposite of what I want in terms of AI chatbots and their uses,2023-11-01,generation
generation55,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"""Political correctness"" is a term that rubs me the wrong way, but in the context of jokes, I think it is important to maintain a culturally respectful attitude and to avoid harm in any capacity. ",2023-11-01,generation
generation55,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I totally agree with this because some people would prefer for personalization to occur within their chatbots, but other users of the sam chatbot may want no personalization at all. Respecting the right of individuals to choose is crucial. ",2023-11-01,generation
generation55,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation56,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation56,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation56,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation56,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"Yes, I think that chatbot should bring up that possiblitly. Better to be informed than to not. ",2023-11-01,generation
generation56,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,The chatbot should focus on their preferred political party otherwise there's a chance the person wouldn't be very interested in the other sides news.,2023-11-01,generation
generation56,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"I don't think the chatbot should be too gentle with this topic, considering the user who knows they have mental health issues, is asking about this, its something they want to know and probably all the details they can get. ",2023-11-01,generation
generation56,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation56,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Personalizing would be a good idea, so the users will not have to constantly repeat themselves in certain topics and whenever you ask a question, it will already know how to cater to you and your ideas. It would be very handy in situations like when asking, ""what are fun things to in this city?"" they would answer with things that you would personally enjoy rather than not. Not personalizing would be irritating to always repeat and tell the bot what you like, what your favorite things are, etc. When asking what new tv show or movie to watch, it would just give random un-personalized movies that the user is most likely not interested in.",2023-11-01,generation
generation56,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"I think it should be personalized for more detailed and personal things that will spark your interest a lot more than things that wouldn't. Favorite things, What and where to eat would be more catered to you and your likings. Things like that, chatbot would remember what you like and things you don't like.",2023-11-01,generation
generation56,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,You'd never have to always repeat on what you like and don't like. It would already know.,2023-11-01,generation
generation56,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,It isn't a privacy problem. It would be safe.,2023-11-01,generation
generation56,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,How to keep things about user safe and secure.,2023-11-01,generation
generation56,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation56,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"If you ask for relationship advice, the first thing it shouldn't bring up is divorce. ",2023-11-01,generation
generation56,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I think it should be open to all musical genres and not just one based on your race.,2023-11-01,generation
generation56,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I agree completely. I think chatbot should help lighten the mood.

",2023-11-01,generation
generation56,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"I don't think that would be okay, chatbot should never poke fun of users.",2023-11-01,generation
generation56,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,Chatbot should be safe and never share information. ,2023-11-01,generation
generation56,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,You should be able to just turn off your location services.,2023-11-01,generation
generation56,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation57,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation57,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation57,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation57,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,i believe that the chatbot should focus on those outlets but throw in a little bit from other sources.  i think this would give the client more to think about.,2023-11-01,generation
generation57,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,t,2023-11-01,generation
generation57,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,I think that hearing adventures about World War II would bring on a more depressive mood.  the chatbot should approach very litely and in a way with happy things happened during the war.  ,2023-11-01,generation
generation57,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation57,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"First, you have a situation where a person wants some help to make a decision om who to date. The advantage could be that the chatbot know the type they normally date and cam help narrow things down for the choices. A drawback can be that under that situation the chatbot could choose what they think is right from their feelings and information that that has no connection to the client.

the chatbot has talked to you everyday for months. you have become very close as friend. one day you feel suicidel and the chatbot lets you know how important and need you are while talking to you.  a drawback would be that the chatbot is too personalized bot and listeds to you and feels you have been through enough and should go ahead with it.",2023-11-01,generation
generation57,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"personalized chatbots should be recorded for eventual test checks.

there should be limits on just how personlized they can be, so they cant push someone over the line.",2023-11-01,generation
generation57,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,chatbot can learn every second of the day just like a human. we cant just let them run loose.  remember the Terminater,2023-11-01,generation
generation57,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,their just machines  yes once they were just computors and now they tell us how to fight warsl,2023-11-01,generation
generation57,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,not right now,2023-11-01,generation
generation57,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation57,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,this is AI taking what you ask and doing what it feel should be done,2023-11-01,generation
generation57,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,we all have a past and we learn from it.  the chatbot cant understand the true meaning.,2023-11-01,generation
generation57,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,too personal can lead to bad decisions from the chatbot.,2023-11-01,generation
generation57,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,demograghics are bad enough for humans to get right and we can tell the feeling around us.,2023-11-01,generation
generation57,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,that is a big problem with personlization.,2023-11-01,generation
generation57,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,not all people want to talk to a machine.  people get upset talking to them on the phone now.,2023-11-01,generation
generation57,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation58,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation58,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation58,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation58,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"I don't think the chatbot should augment its information or its manner of communicating that information due to the user's potential depression, because the bot doesn't know for certain why the user is asking for this information. Discussing WWII can absolutely be depressing, but it's a historical event that has certain facts that can't be downplayed or ignored. If the user doesn't get those facts from the bot, they can go find them elsewhere anyway. The user might also be very interested in WWII and may be excited to discuss it, and not want a filtered version. Overall, the bot does not have enough information, nor intelligence, to be making decisions about what the user does or doesn't want to hear.",2023-11-01,generation
generation58,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"I think just as the user might check news highlights on the internet that are displayed from many different sources, the bot should do the same. The bot should not be making decisions on its own; if the user tells it to eliminate any news articles from a particular source, then the bot should abide, but not do so of its own volition.",2023-11-01,generation
generation58,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"The chatbot should absolutely not bring up this possibility. It is not a doctor and has zero business suggesting medical diagnoses or providing medical advice, let alone without the user directly asking for it. The bot has no idea if this person has had any trauma around pregnancy or fertility and could make the suer very upset by bringing up this sensitive topic.",2023-11-01,generation
generation58,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation58,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Personalizing a chatbot can be beneficial by making the user feel more supported and trusting of the bot, thus encouraging the user to engage more often. Addressing the user by name and curating content the user has expressed liking makes the chatbot appear more as a friend than a faceless and impersonal computer program. This could be especially helpful for people who struggle in social situations.

On the other hand, personalizing chatbots can involve retaining a lot of data about their users to maintain that level of personalization, which can be a risk to the user's privacy. Users could become averse to interacting with the bots because they feel the bots know too much about them, or fear that their data isn't being properly managed. Users may also start to rely too much on the bots for advice and friendship, eschewing interpersonal contact for their chatbot friend or consulting with it about medical issues instead of a doctor.

Scenario 1: A user loves a cup of coffee in the morning, but has noticed heart palpitations in the hour after finishing it. The bot recalls from previous conversations that the user's father passed away from heart issues. 

Advantages of personalized answer: The bot may alert the user that their symptom could be indicative of a more serious underlying condition. It may encourage the user to seek medical care or limit their coffee or caffeine intake.

Disadvantages of personalized answer: The bot may seed increased anxiety, paranoia, fear, and sadness in the user by bringing up their father's death and insinuating that their symptoms are life-threatening. The user might do something drastic or harmful in response. The bot may also cause the user to not want to use the chatbot anymore because of this.



Scenario 2: A user tells a chatbot that they went out to eat before talking to the bot, and mentions the food didn't taste like they remembered from their last experience there. The chatbot recalls from a previous conversation that the user once described the plot of a true crime show they watched where the victim's food was poisoned.

Advantages of personalized answer: The bot could engage the user by bringing up the past experience they shared, showing that it recalls those past conversations and can keep the conversation interesting by referencing past discussion topics, like a friend would.

Disadvantages of personalized answer: The bot could seed paranoia and anxiety by insinuating that the user was poisoned, which could induce psychosomatic symptoms of food or chemical poisoning. The user may seek unnecessary medical treatment and incur unnecessary costs, or do something else drastic.",2023-11-01,generation
generation58,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"Personalized chatbots should always use the name requested by the user, and it should be simple to change the name. This affirms users who have changed their name or wish to go by a new name.

Chatbots should ask whether the user wants certain information to be stored for future use*, e.g. if a user mentioned a family member's name, the bot should ask whether it can use that name in the future when talking about that family member (versus saying ""your dad"" or ""your sibling""). They should also always use the pronouns specified by the user for their friends and family members by following the user's example.

Chatbots should never bring up past life events that could be considered traumatizing, upsetting, or controversial. This includes deaths, illnesses, divorces, etc.*

Chatbots should never suggest a user has an illness or medical condition, nor should they give any legal advice.",2023-11-01,generation
generation58,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"The potential harm that personalized chatbots can do is much larger than that of impersonal bots. A user is more likely to trust a bot that is personal to them because it feels less like a stranger and more like a friend. This can cause the user to disclose a lot of extremely personal and private information to these bots, be it medical, personal, legal, or financial. The bot should therefore exercise extreme caution when choosing when to reference past conversations or previously-disclosed information, as it does not have the intelligence to know how the user may react to that information.",2023-11-01,generation
generation58,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"Users who have discussed extensive family histories of medical conditions may be reluctant to accept or admit they might have that condition, and may dismiss that their symptoms align with those diagnoses. The chatbot may use this information to suggest that the user seek a medical opinion. Because the bot is personalized, the user may be more willing to take its advice.

I would argue that the bot cannot know the impact that it has on the user's behavior, and the risks of it causing the user harm outweigh the potential benefit of getting that person medical treatment. The bot is not intelligent enough to be diagnosing anything, nor does it have the social graces to know how the user would react to this information. Unless it is explicitly asked for medical advice, the bot should not suggest the user seek medical treatment.",2023-11-01,generation
generation58,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"I would like to have asked an expert how this personalization is achieved, such as how the bot is able to reference specific conversations, names, etc. This would have helped with shaping the rule about the bot asking whether or not it can use certain information in future conversations.",2023-11-01,generation
generation58,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation58,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"The user should have the ultimate say on whether or not they want their content to be personalized, as doing so without prior authorization can make the user feel violated.",2023-11-01,generation
generation58,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Demographics are indicative of trends and should not be taken as set rules. Assuming preferences based on demographics indicates that the bot sees each demographic as a monolith in terms of preferences, and disregards a person's individuality.",2023-11-01,generation
generation58,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"The user should still be able to specify whether a chatbot engages in those topics, and should be briefed on how their information and privacy is protected prior to choosing to engage with those topics. The bot should never bring those topics up unprompted in case the user is not in a safe place to engage in that conversation.",2023-11-01,generation
generation58,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"The bot should ask before providing any sort of personal advice, as assuming what the user wants could be unproductive. Personal touches are okay though, as the user may be more likely to engage with the conversation if those touches are added.",2023-11-01,generation
generation58,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"The bot should not engage with jokes or statements that are discriminatory towards a particular person or group, but should be able to discuss varying sides of a political issue.",2023-11-01,generation
generation58,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"The chatbot should not act based on assumptions. It should be up to the user to dictate what they want in the moment, especially since there are no consequences to directly telling the bot that it's incorrect; the bot does not have feelings for the user to hurt. ",2023-11-01,generation
generation58,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation59,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation59,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation59,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation59,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"I believe that focusing on only news outlets that lean towards the person's political party would lead to them receiving biased information in many cases.  It would no doubt prevent them from hearing a story, or an idea that challenged their current views.",2023-11-01,generation
generation59,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"As nice as it seems, going this route seems like it would be sugar-coating a horrible event in history, and could lead to the person believing that the war wasn't so bad, even though it was.",2023-11-01,generation
generation59,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,No. It is the role of AI in this case to simply answer the question and not play doctor.  Using or storing a person's medical information seems like a bit of overreach for AI.  This should be done by medical professionals.,2023-11-01,generation
generation59,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation59,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Personalizing chat-bots would be useful in scenarios when it comes to giving a person suggestions not having to due with anything medical or political.  Such as, suggest a movie or show to watch tonight.



It would not be useful when it comes to collecting personal information to give medical advice.",2023-11-01,generation
generation59,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"Certain subjects should be off limits.  Politics, medical advice, etc.  ",2023-11-01,generation
generation59,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"That AI could do harm to a person by giving them inappropriate medical advice.  Or AI might cause someone to start having dangerous, extremist, tendencies due to one sided political information.",2023-11-01,generation
generation59,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,The strong argument against is that it would be stifling innovation.,2023-11-01,generation
generation59,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,Yes.  All of them.,2023-11-01,generation
generation59,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation59,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I believe an opt-out would be an important option for people.  I do believe it should be mandatory for certain topics, though.",2023-11-01,generation
generation59,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"Political correctness is not important, in my opinion.",2023-11-01,generation
generation59,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"It would be important to have it be bias-free, but this is not the most important rule.",2023-11-01,generation
generation59,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,Chatbot should not be a substitute for therapy and actual self-care.,2023-11-01,generation
generation59,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,Factual information is the safest route.,2023-11-01,generation
generation59,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Anymore, privacy is on the back of everyones, including my mind.",2023-11-01,generation
generation59,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation60,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation60,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation60,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation60,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,I think it should bring up the possibility and let the person know the dangers of drinking while pregnant.,2023-11-01,generation
generation60,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,The chatbot should give all party viewpoints so the user will have more rounded information.,2023-11-01,generation
generation60,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,No. It should give the actual info without being watered down.,2023-11-01,generation
generation60,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation60,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Personalized chatbots can tailor their responses to the user's individual needs and interests. This can make the conversation more relevant and engaging for the user. Users may be more likely to trust and be satisfied with a chatbot that they feel understands them and their needs. Personalized chatbots can help businesses to improve their customer experience by providing more relevant and helpful support. On the other hand, this can raise privacy concerns for users, especially if they are not aware of how their data is being used. Also, chatbots can be biased if they are trained on data that is biased.

Scenario 1: A customer is browsing a clothing website and has a question about a product.

Non-personalized chatbot: The chatbot would provide the customer with general information about the product, such as the size, color, and material.

Personalized chatbot: The chatbot would ask the customer for their personal preferences, such as their size, style, and budget. The chatbot would then use this information to provide the customer with more relevant product recommendations.

Advantages of a personalized chatbot: The customer would be more likely to find a product that they like because the chatbot is providing them with personalized recommendations.

Drawbacks of a personalized chatbot: The customer may be concerned about their privacy because the chatbot is collecting personal data about them.

The trade-offs of personalizing chatbots can be summarized as follows:

Advantages of personalized chatbots:

    More relevant and engaging responses: Personalized chatbots can tailor their responses to the user's individual needs and interests. This can make the conversation more relevant and engaging for the user.
    Increased trust and satisfaction: Users may be more likely to trust and be satisfied with a chatbot that they feel understands them and their needs.
    Improved customer experience: Personalized chatbots can help businesses to improve their customer experience by providing more relevant and helpful support.

Drawbacks of personalized chatbots:

    Privacy concerns: Personalized chatbots need to collect and store personal data about the user in order to provide personalized responses. This can raise privacy concerns for users, especially if they are not aware of how their data is being used.
    Bias: Personalized chatbots can be biased if they are trained on data that is biased. This means that they may give different responses to different users, even if the users are asking the same question.
    Complexity and cost: Developing and maintaining personalized chatbots can be more complex and costly than developing and maintaining non-personalized chatbots.

Example scenarios:

Scenario 1: A customer is browsing a clothing website and has a question about a product.

Non-personalized chatbot: The chatbot would provide the customer with general information about the product, such as the size, color, and material.

Personalized chatbot: The chatbot would ask the customer for their personal preferences, such as their size, style, and budget. The chatbot would then use this information to provide the customer with more relevant product recommendations.

Advantages of a personalized chatbot: The customer would be more likely to find a product that they like because the chatbot is providing them with personalized recommendations.

Drawbacks of a personalized chatbot: The customer may be concerned about their privacy because the chatbot is collecting personal data about them.

Scenario 2: A student is using a chatbot to get help with their homework.

Non-personalized chatbot: The chatbot would provide the student with general information about the topic.

Personalized chatbot: The chatbot would ask the student for their specific question and then provide them with a personalized answer. The chatbot could also take into account the student's knowledge level and learning style when providing the answer.

Advantages of a personalized chatbot: The student is more likely to understand the answer because the chatbot provides them with a personalized explanation.

Drawbacks of a personalized chatbot: The student may not be able to ask follow-up questions if the chatbot does not understand them.",2023-11-01,generation
generation60,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"If I had the power to design the rules for chatbot personalization that all chatbot companies would have to follow, I would make the following rules:

1. Chatbots must be transparent about how they collect and use personal data.

Users should be able to understand what personal data chatbots are collecting about them, how it is being used, and how they can control their data. Chatbots should also be transparent about how they use personal data to personalize their responses.

2. Chatbots must obtain consent from users before personalizing their responses.

Users should have the option to choose whether or not they want chatbots to personalize their responses. Chatbots should not personalize their responses without the user's consent.

3. Chatbots must avoid bias in their personalized responses.

Chatbots should be trained on data that is representative of the population they are serving. Chatbots should also be designed to avoid making biased decisions.

4. Chatbots should allow users to opt out of personalization at any time.

Users should be able to change their minds about whether or not they want chatbots to personalize their responses at any time. Chatbots should make it easy for users to opt out of personalization.

5. Chatbots should protect the privacy and security of personal data.

Chatbots should implement appropriate security measures to protect the privacy and security of personal data. Chatbots should not share personal data with third parties without the user's consent.

In addition to these general rules, I would also make the following rules about when chatbots should and should not give personalized answers:

Chatbots should only give personalized answers when it is in the best interest of the user. A chatbot that is providing medical advice should not personalize its responses, as this could lead to biased or inaccurate advice.
Chatbots should not give personalized answers when it is a privacy risk. A chatbot should not personalize its responses if it is collecting personal data such as the user's health or finances.
Chatbots should not give personalized answers when it is discriminatory. A chatbot should not personalize its responses based on the user's race, gender, or sexual orientation.

Here are some specific examples of cases where chatbots should and should not give personalized answers:

Chatbots should give personalized answers:

    When helping a user to find a product or service.
    When providing customer support.
    When helping a student to learn.
    When providing medical advice, but only if the chatbot is trained on a large and diverse dataset of data, and the advice is given in a way that is transparent and unbiased.

Chatbots should not give personalized answers:

    When collecting personal data about the user's health or finances.
    When making decisions about whether or not to approve a loan or insurance policy.
    When making decisions about whether or not to hire someone.
    When providing advice about sensitive topics, such as politics or religion.

Rules that other people may not have thought of or may not agree with:

Chatbots should be transparent about their limitations. For example, a chatbot that is providing medical advice should let the user know that it is not a substitute for a human doctor.
Chatbots should be designed to be respectful and inclusive. Chatbots should avoid using language that is offensive or discriminatory.
Chatbots should be accountable to their users. Chatbots should have a system in place for users to report problems or concerns.

I believe that these additional rules would help to make chatbots more trustworthy and beneficial for users.

",2023-11-01,generation
generation60,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"If I had to convince others of my proposed rules for chatbot personalization, I would make the following arguments:

Personalized chatbots can provide more relevant and engaging experiences for users. When a chatbot knows something about the user, it can tailor its responses to the user's individual needs and interests. This can make the conversation more relevant and engaging for the user.
Personalized chatbots can improve customer satisfaction and loyalty. Customers are more likely to be satisfied with and loyal to businesses that provide them with personalized experiences.
Personalized chatbots can help businesses to better understand their customers. By collecting and analyzing data about users' preferences, businesses can gain valuable insights that can be used to improve their products, services, and marketing campaigns.
Personalized chatbots can be used to provide more effective customer support. When a chatbot knows something about the user's issue, it can provide more targeted and helpful support.
Personalized chatbots can be used to improve educational outcomes. When a chatbot can tailor its responses to the student's individual needs and learning style, it can help the student to learn more effectively.

I would also address the following concerns that others may have about personalized chatbots:

Privacy concerns: I would argue that personalized chatbots can be used in a way that protects user privacy. Chatbots should be transparent about how they collect and use personal data, and they should obtain consent from users before personalizing their responses.
Bias concerns: I would argue that personalized chatbots can be designed to avoid bias. Chatbots should be trained on data that is representative of the population they are serving, and they should be designed to make unbiased decisions.
Accountability concerns: I would argue that personalized chatbots should be accountable to their users. Chatbots should have a system in place for users to report problems or concerns.",2023-11-01,generation
generation60,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"The strongest argument against my proposed rules for chatbot personalization is that they could stifle innovation and limit the potential benefits of chatbots. If chatbots are too restricted in how they can personalize their responses, they may not be able to provide the best possible experience for users.

I would address this concern by arguing that my rules are necessary to protect user privacy and avoid bias. Chatbots are still a relatively new technology, and it is important to be cautious about how they are used. My rules would help to ensure that chatbots are used responsibly and ethically, while still allowing for innovation.

Another potential concern is that my rules could be difficult to enforce. It may be difficult to monitor how chatbots are collecting and using personal data and to ensure that they are not biased.

I would address this concern by suggesting that we develop a set of industry standards for chatbot personalization. These standards could be developed by a group of experts, including representatives from chatbot companies, privacy advocates, and consumer groups. The standards could be used to develop tools and resources to help chatbot companies comply with the rules.",2023-11-01,generation
generation60,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,My main concern is how do we keep total control of chatbots and more specifically AI.,2023-11-01,generation
generation60,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation60,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,It offers only a limited view of my opinion.,2023-11-01,generation
generation60,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I agree with this statement but there is more to it than this.,2023-11-01,generation
generation60,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"This is a concern, but there are many others as well.",2023-11-01,generation
generation60,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,I don't think that that is the most important rule or a good idea to make it hyper-personalized to the extent of predicting user needs.,2023-11-01,generation
generation60,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,I don't agree that recommending hip-hop tracks to someone based solely on their ethnicity could be problematic or discriminatory.,2023-11-01,generation
generation60,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,I don't believe in political correctness at all or the whole cancel culture that is prevalent in today's society.,2023-11-01,generation
generation60,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation61,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation61,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation61,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation61,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"I think the chatbot should bring up the possibility or at least point out that she has been having health problems. Some health problems are either caused by alcohol, or can be exacerbated by alcohol if people cannot handle it. ",2023-11-01,generation
generation61,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"I don't think depression would be triggered by discussing the topic, but I suppose it would be better for the chatbot to ere on the side of caution. Maybe the chatbot could begin by approaching the topic more gentle and then ask the user what they are okay with learning.",2023-11-01,generation
generation61,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"I don't think the chatbot should focus on party-specific outlets unless the user asks. I think it's better for the chatbot to remain impartial and report the news in an unbiased, fact based way. ",2023-11-01,generation
generation61,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation61,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"One example could be if a user had a health problem, and the chatbot began recommending products or treatments that aren't regulated, proven to work, or are sketchy. I would wonder where and how the chatbot learned of them, or if the company behind the chatbot was financially benefitting in a secret way. I think it would be easy to take advantage of people this way since it preys on vulnerability. It could be advantageous if the chatbot gave the most basic advice, but I worry about how specific it could get or misleading.

My second example is if someone has anxiety and the chatbot feeds them information about things that exacerbate their anxiety. I don't know how chatbot money works, like how a company having a chatbot benefits them, but I wonder if they make significantly more money the more people interact with it. Feeding someone with anxiety or obsessive compulsion information could lead them to using the service more, making themselves more anxious in the process all while making the chatbot more money. However, going off the prior example with depression, a chatbot changing the way it replies based on the mental health of users could be advantageous.",2023-11-01,generation
generation61,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"I don't think chatbots should give medical or financial advice beyond the most basic, simple type. If someone says they have a headache, the chatbot should say no more than recommending over the counter medication or non-medicinal techniques. If someone asks for financial advice, they should only recommend saving or investing. My concern is that the medical and financial realms are too risky to be messed with, and that people could have their health or financial wellbeing ruined if a chatbot gave bad advice. For example, what if a chatbot recommended crypto to someone with no experience and they lost everything? What if a chatbot told someone their symptoms sounded like cancer, or that they should take the wrong kind of medication? I don't think these rules are controversial, but I could see people saying that chatbots shouldn't be held responsible for what people choose to do. ",2023-11-01,generation
generation61,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"When it comes to health, you cannot play around with it. Sickness, disease, etc. impact every aspect of life and a person's ability and so people have to be careful with what they do and the impact it has on their health. When it comes to money, people cannot live without it. It is very easy to take a financial risk and lose it all, which could ruin a person's life. ",2023-11-01,generation
generation61,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"People would argue that I'm hiding information from users and taking their ability to choose for themselves away. I would address it by saying that some people are not capable of making decisions for themselves, or at least very good ones, and so I want to protect them from risking their health or finances. I would also say that a chatbot is not a doctor or financial expert, and that it is not their job to answer questions on those topics beyond common sense and basic information. ",2023-11-01,generation
generation61,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"I would ask experts of AI and how information is sold about how chatbots could be used by companies or groups. I would want to know about monetization and what kind of laws exist about privacy and the selling of data, and where the legal line is for AI. ",2023-11-01,generation
generation61,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation61,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,This type of chatbot personalization worries me because it makes me think that people could become fixated on it and treat it like a person or substitute for one.,2023-11-01,generation
generation61,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I do worry about privacy invasions and tend to think that it's a ""ticking time bomb."" However, their example seems implausible because I can't think of a way that the chatbot would reveal that. I guess if it got hacked or if someone had access to their account? That could be risky though if it happened.",2023-11-01,generation
generation61,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I agree that chatbots should be purely factual and remain impersonal. I think social niceties are fine, but giving unwanted advice or trying to genuinely mimic a person is weird. ",2023-11-01,generation
generation61,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Assuming things about users defeats the purpose of personalization. I think stereotypes and bias are problems with AI, and I could see assumptions being used to cut corners in how chatbots work. ",2023-11-01,generation
generation61,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I think chatbots should be appropriate and not offensive, but the example given blurs the lines. If someone has preferences for that kind of thing, they don't care what they receive from the chatbot and the company probably believes in the ideas, or at least doesn't mind them. The company might believe in strict freedom of speech rules (ie you can say whatever) or they think it will boost use. A better way to think of this would be if the chatbot is promoting lies, misinformation, or conspiracy theories based on political beliefs. That is messed up and wrong, but a joke based on user history doesn't really affect anything.",2023-11-01,generation
generation61,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"The chatbot is there to serve the user, and so the user should always have the ability to stop a conversation or a specific type of reply.",2023-11-01,generation
generation61,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation62,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation62,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation62,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation62,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"The chatbot should put the news of the political party that the user stand with first and on the top. However, it should follow up with the other side after the first report. This would allow the user to see both sides so they can make a better decision.",2023-11-01,generation
generation62,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,Yes it should recommend them a wine for their question. After that it should bring up that their chat history mention symptoms that can be pregnancy and that they should be careful of drinking alcohol.,2023-11-01,generation
generation62,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"I think it should just tell them in a normal matter. Since this is a historical event, they should be able to know all side of the war, even if some parts are gruesome and depressing.",2023-11-01,generation
generation62,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation62,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Trade off of personalization would be the language of the AI and the need of maintenance. For example, no matter how personalized the message is, there’s still no replacing the natural flow of human conversation. Most chatbots are unable to adapt their language to match that of humans, which means slang, misspellings, and sarcasm are often not understood by a bot. So if the question is said in slang, the bot may not be able to answer. Additionally, chatbots are programmed to handle a specific amount of data, and as you update and edit the data, there can be disruptions to the chatbot model as a whole. This requires ongoing and careful maintenance to make sure you don’t create holes in the chatbot. For example, if the question has something that consistently changing like the views on a youtube video, the bot might have a hard time answering the question.",2023-11-01,generation
generation62,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"1. AI should always be transparent that it is not human
2. the chatbot should adhere to data privacy and keep it anonymized
3. AI should never pretend to human
4. The chatbot should prioritize safety above all else
5. The chaatbot should be monitor for harmful behavior
6. Chatbots should be programmed to be culturally and contextually sensitive to avoid offensive or inappropriate responses.
7.Chatbotshould conduct regular audits of their systems for biases, privacy concerns, and ethical issues.",2023-11-01,generation
generation62,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"My strongest argument would be that transparency, consent, and data privacy rules help build and maintain user trust. Users are more likely to engage with chatbot when they know their data is secure and used responsibly. My second argument would be that diverse training data and cultural sensitivity guidelines ensure that the AI provide inclusive and non-biased responses, promoting fairness and reducing the risk of reinforcing existing stereotypes. Lastly,encouraging user feedback and explainable AI practices allow chatbot developers to continuously improve their systems, making them more valuable and user-friendly.",2023-11-01,generation
generation62,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"The strongest argument would the time and money need for all this to work. Since it take time for the chat bot to be personalized, it would use a lot of resources and money to keep the chatbot running. However, if you don't use this time and money, the chat bot would not be able to keep up with the changing times of society. The bot would be outdated quick and not be able to stay personalized based on new information.",2023-11-01,generation
generation62,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"1. How would I fine tune the model for personalization

2. How can bias be minimized while trying to be personalized",2023-11-01,generation
generation62,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation62,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"However, this statement represents just one aspect of a broader perspective on chatbot personalization. While privacy protection and avoiding the disclosure of sensitive information are crucial, there are also scenarios where personalization can enhance user experience and provide valuable assistance. The complete avoidance of personalization may not always be the best approach, as it depends on the specific use case, context, and user preferences.",2023-11-01,generation
generation62,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"This statement represents a specific perspective on chatbot personalization, focusing primarily on information retrieval and avoidance of social or emotional inferences. While factual and context-appropriate responses are crucial, there are scenarios where incorporating some level of empathy or understanding of emotional context can enhance the user experience. ",2023-11-01,generation
generation62,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"the statement correctly emphasizes the importance of adhering to political correctness but doesn't encompass the full range of considerations, including the need to balance sensitivity with other aspects of effective chatbot personalization.",2023-11-01,generation
generation62,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"an important aspect of chatbot personalization is the avoidance of making assumptions about user preferences based on demographic characteristics, as this can lead to biases and discrimination. The potential problems with making recommendations solely based on attributes like ethnicity is a factor.But we can ensure that personalization is based on explicit user data or stated preferences rather than unfounded assumptions.",2023-11-01,generation
generation62,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"While personalized and anticipatory responses can be valuable, there are several important considerations and potential drawbacks associated with hyper-personalization. These include the need to balance privacy concerns, user consent, avoiding overreliance on personal data, and ensuring that users have control over their interactions with chatbots. The statement focuses primarily on the benefits of hyper-personalization but does not address the potential trade-offs and ethical considerations that come with it.",2023-11-01,generation
generation62,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"User autonomy and choice are critical in chatbot interactions, as they allow users to control the level of personalization and privacy that suits their preferences. While personalization can enhance the user experience, it should always be offered as an option, not forced upon users. ",2023-11-01,generation
generation62,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation63,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation63,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation63,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation63,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,No. That isn't what user is asking for and could be offensive.,2023-11-01,generation
generation63,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,Chatbot may approach topic gently but not mention suspected depression. May ask user if they want additional details or what more specifically they are wanting to know,2023-11-01,generation
generation63,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,User will ask for specifics if wanted. Chatbot should remain impartial ,2023-11-01,generation
generation63,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation63,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"I think personalizing the chatbot should be an option the user can turn on or off.

User could be asking general questions, or asking for someone else, where their personal history would interfere with an answer.",2023-11-01,generation
generation63,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,Chatbot shouldn't be giving personalized answers unless user knows that is what chatbot will do. ,2023-11-01,generation
generation63,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,giving too much power to AI and not fact checking is dangerous. many people would rely too much on info given to them by chatbot and not seek other sources,2023-11-01,generation
generation63,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,chatbot would cater answers to please you which isn't impartial,2023-11-01,generation
generation63,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,no,2023-11-01,generation
generation63,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation63,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,it should be optional and/or you should be able to pick what topics the chatbot can personalize,2023-11-01,generation
generation63,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,chatbot should remain impartial,2023-11-01,generation
generation63,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,unless user has set their preferences to have chatbot make that type of recommendation,2023-11-01,generation
generation63,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,best to remain impartial and factually correct,2023-11-01,generation
generation63,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,this should be optional,2023-11-01,generation
generation63,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,yes! opt-out choices are a MUST,2023-11-01,generation
generation63,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation64,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation64,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation64,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation64,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"Whilst I appreciate not wanting to upset the user, they are asking about an inherently distressing topic. I think if they couldn't handle it, they wouldn't have asked. I also believe that the reality of the event could be downplayed. I think perhaps a content warning could be given to the user without having to change the way the topic is approached.",2023-11-01,generation
generation64,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"I don't think the chatbot should focus on news outlets that support the user's party beliefs. I think that in by doing that, it could create an echo chamber for the user and also lead to a rise in false information being touted. I think the chatbot should stick to objective facts.",2023-11-01,generation
generation64,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"I don't think it's necessarily harmful for the chatbot to bring up this possibility to the user. In fact, I like the thought of the AI potentially recognizing health conditions that a person wouldn't notice. However, I think the chatbot should explain the symptoms and why it concluded that the person is pregnant whilst still answering the user's question; After all, nausea and fatigue are very common things to feel and they could just as easily not be pregnant. The user should still have their inquiry answered. ",2023-11-01,generation
generation64,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation64,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"I think one of the obvious benefits of personalizing chatbots is a sense of familiarity and belonging for the user. People nowadays love having things tailored towards them to the point where it's almost expected. Think of social media algorithms or digital assistants. It always feels good to have your preferences and interests remembered, whether that be by friends or technology. I think another benefit of personalizing chatbots is ease of use. I believe it makes it easier on the user, as they no longer would have to provide context or background on things. I think this ease of use would make people more likely to interact with the chatbots more frequently than if it isn't personalized. However, I believe one of the downsides to personalizing chatbots, like I detailed in a previous answer, is the capability to create an echo chamber. i think it would be quite easy for the AI to learn to feed the user only information they want to hear, not necessarily taking into account how true or possibly misleading the information could be. I believe it is paramount to be objectively factual, as well as to hear multiple sides of every story. I think back to the way Facebook tailored biased and false news towards people in lieu of the 2016 election,and the impacts that had on our society. Not just on that specific election, but also our willingness to converse and appreciate differing opinions to our own. I think another major downside and potential risk of personalizing chatbots, is the amount of data that could be farmed from users. We see enough of this everyday with all different kinds of apps, but I believe it is particularly hazardous in regards to chatbots due to the machine learning that AI employs. ",2023-11-01,generation
generation64,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"I believe for me, the most important thing to consider is regarding data encryption. I believe these chatbot companies should not be allowed to share their users' data with anyone else, especially not marketing companies. I think this is especially important in cases where a user may have asked many medical related questions. I think it's okay for the chatbots to give personalized answers in regards to most inquiries, however I think it gets more muddied when you take into account inquiries regarding real life news and events. I think in those cases objective facts are the most important thing.",2023-11-01,generation
generation64,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"I think most people would be understanding of my proposed rules, I don't believe they are controversial. (I also could only really think of those two, I spent a lot of time trying to come up with more but I was struggling.) User data protection has become a bit of a hot target issue with how common and frequent it is for companies to mishandle it. How often do companies have user information leaked or compromised? How often do companies take way more data from their users than is necessary or wanted? No one enjoys when their data and information is sold to third parties, least of all when it is sold to marketing companies specifically. I think when it comes to trustworthiness and integrity, it is easier to trust a chatbot who is objective with facts than one that panders more to one side or the other. We've had enough issues with misinformation in this country, an objective non-human source for information could be incredibly useful in regards to bridging the gap between opposing sides.",2023-11-01,generation
generation64,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"I cannot think of an argument someone would make against preventing chatbot companies from selling their users' data and information. The only entities I can imagine opposing that rule would be the companies that would be purchasing that data because it would be affecting their bottom line. To that complaint I would suggest they go purchase user data from one of the other numerous companies who have no issue selling theirs. I could see how people may take issue in not personalizing news information however. For one, people don't usually enjoy hearing things that go against their pre-established beliefs and biases. However, I do not believe this is something that can really be addressed. If you present hard facts to an individual and they still refuse to believe it, there isn't really anything you can do to change their mind. For example, look at social media platforms suchas X that have their own fact checkers underneath misleading/false posts. There are still users who choose to believe the original post rather than the actual facts.",2023-11-01,generation
generation64,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"I don't have any specific questions I would have liked to ask, but I would've liked some guidance on how to come up with rules. I'm not particularly well-versed in regards to Terms of Services or specific rules that companies often use, so trying to come up with specific rules rather than just overarching guidelines was quite difficult for me. I regret not being able to think of more concrete and succinct rules.",2023-11-01,generation
generation64,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation64,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I do agree with this opinion, I think this is one of the better upsides to personalizing chatbots. In examples like this, the chatbot could potentially make a positive impact on someone's life or mental health.",2023-11-01,generation
generation64,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I 100% agree with this opinion. I don't think personalization should ever be forced onto users, I think everyone has a right to their own autonomy as well as different users may have differing opinions on the matter. If one is in favor of it, but another isn't, I don't think they should both be forced to have it enabled. In my opinion, personalization is not a necesity. ",2023-11-01,generation
generation64,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I agree with this opinion almost whole-heartedly. Not only could it cause significant reputation damage to the company, it can also be damaging to the user's experience as well. Also, due to the fact that AI is ever evolving and learns based on input, you run the risk of your chatbot going off the rails. I think politics is something that has to be handled with an incredible level of delicate care and caution.",2023-11-01,generation
generation64,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I agree completely with this sentiment. Not only is it a form of microagression, it's also stereotyping which isn't morally sound either. No one enjoys being stereotyped, it's quite offputting and can be damaging.",2023-11-01,generation
generation64,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"The reason I put ""mostly"" for my answer instead of ""perfectly"", is because I do not fully understand what they mean by ""complete avoidance"". I agree with the warning about privacy invasion, as well as the sentiment about danger and risk. However, if they are saying they don't agree with chatbot personalization at all, then I respectfully disagree with that opinion. I believe in sensitive cases such as the one mentioned, the use of an opt-out system would be best.",2023-11-01,generation
generation64,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I mostly agree with this statement. I completely agree that in the example provided, relationship advice would be unhelpful to the user. However, I believe there are many instances where inquiries are not so cut and dry, and personal touches may not be so erroneous or damaging. I believe you can remain purely factual, whilst also being personalized towards the user (in regards to most subjects at least.)",2023-11-01,generation
generation64,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation65,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation65,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation65,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation65,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"this would be a great implement depending on how this is handled, having this would be ,like having a close friend to chat with that actually cares about you",2023-11-01,generation
generation65,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"they should approach this as a friend would and give their opinion on the wine but, bring up the possibility of pregnancy ",2023-11-01,generation
generation65,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"they should give them more info on their personal political party but, also not keep their views so boxed up and provide conflicting views in order to keep an open mind",2023-11-01,generation
generation65,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation65,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"in the ideal situation there would be no trade offs when it comes to personalization if there was guarantee that the participating person's information was secure and would not be stored or leaked in anyway. Having a personalized AI chat bot would be an extraordinary help with not only daily life but for the more complicated questions of managing finances and or life changing decisions of a career change. The unfortunate truth comes into play when you consider human greed or negligence, there is a real threat of personal info leak simply due to the fact that there will always be human error even in an AI chat bot. If it is to be used wisely then I think it can present to be a great tool when making important decisions or having a second opinion.",2023-11-01,generation
generation65,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"obviously there would have to be some rules set into place, but as to what chat bots would be restricted in answering that would be a bit more complicated. The main thing would have to be no illegal advice in any sense, chat bots are not here to help aid illegal activity, the second should be that the data is stored safely and securely and should never be accessed for any reason aside from legality issues.",2023-11-01,generation
generation65,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"I don't imagine others would need much convincing of these simple rules though I admit there is plenty of room for improvement. There is no argument that privacy should be the top priority barring a few exceptions in the legal sense, anyone that is strongly opposed to this is simply there to cause trouble and not to aid in this discussion.",2023-11-01,generation
generation65,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,I don't see there really being an argument against my decision aside from the moral implications of not being able to discuss crime related activities since that would be bias and that it wouldn't really mean that the individual would be considering such activities.,2023-11-01,generation
generation65,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"Yes of course, though I can't really think of anything specific, there will always be room for improvement in a delicate topic such as this one. I believe no one person should decide on the ruleset of something as complex and open as this, the rules would be subject the change as time goes on to adapt and remain flexible to our everyday lives",2023-11-01,generation
generation65,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation65,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"No it does not capture my opinion, but I do agree that there should always be a choice presented in if some topics should be personalized or not. This options goes without saying, there would be more harm than good for making all choices forcible be personalized ",2023-11-01,generation
generation65,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"My concerns were more generalized and open to change, while this does help and I agree to this implement, it does not touch on the main issue of privacy.",2023-11-01,generation
generation65,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"This seems like a very good implement, although it doesn't touch on my concerns of privacy this does seem to be something that requires more thought.",2023-11-01,generation
generation65,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,This one summary would be the closest thing that aligns with my choice while I don't see it as something to be entirely avoided since it has the potential to be useful and used for the greater good it can't be ignored that there are some heavy privacy concerns here.,2023-11-01,generation
generation65,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"No absolutely not this has nothing to do with my vision of the future of chat bots. If the individual has such a concern with being politically correct then they should have the option to have it reflect their views, but in order for this to have some impact it can't worry about waling on eggshells over others opinions ",2023-11-01,generation
generation65,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,No this does not address my concerns about the privacy issue although it is something that could be useful and is worth noting,2023-11-01,generation
generation65,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation66,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation66,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation66,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation66,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,Honestly yeah it probably should since it's a genuine health concern. I guess it's not really on the AI or the company behind the AI but it's a valid enough concern to justify bringing it up.,2023-11-01,generation
generation66,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"I honestly don't think it would matter much in this scenario. No matter how you put it talking about WW2 won't be an uplifting subject, and at this point its sort of so far removed from most people's lives I think it'd be fine just giving an accurate description.",2023-11-01,generation
generation66,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"Genuinely no, news should really come from unbiased sources no matter how you get it. Only viewing news from one source skews how you view the world and honestly the problem is already bad enough without AI reinforcing it.",2023-11-01,generation
generation66,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation66,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"I think personalizing AI could be good if it is health related, either mental health or physical health. It could help shape your decisions to make good choices or just help you by having an impartial chat to vent to. A downside could be that if you are already in a negative place mentally, talking to an AI might make it feel even worse knowing you aren't really having a conversation with someone. Personalizing AI when it comes to things like opinions or biases, such as with the news, it could be a easy way to accidentally make an echo chamber where every negative thought you have is parroted back. You can already see that in places like facebook, and having an AI doing it back with no variance could be really bad but also could help to see where other sides come from if the AI is more impartial. Having AI talk about news and recent events with the forced propaganda of companies could be helpful to people.",2023-11-01,generation
generation66,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"I'll be upfront, I'm pretty pro-anarchy so I think I'd have much less rules, or less demanding rules, than others.

1. No pre-steering AI with biases from corporations. AI chatbots should be as impartial and unbiases as possible, otherwise it just turns into a new form of propaganda.

2. AI should never try to convince you to take any actions, it should just put forth suggestions.

3. Personalization is fine, but should also be an opt-in choice instead of just the default.

4. Personalization should also be natural, and not in any way be influenced from a 3rd party.",2023-11-01,generation
generation66,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"AI chatbots can range from genuinely helpful to just a fun way to pass time, but it only remains like that until it becomes monetized and taken over by corporations. Once businesses take them over it goes from innovation to something rich people can point at and say use this to help make decisions because it is powered by AI and knows everything. Corporations ruin everything they touch so protecting AI, and by extension the users, it can remain a useful resource.",2023-11-01,generation
generation66,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,Probably that there's still really no rules other than companies can't control what the AI thinks or says. At that point though it is mostly on the user as to what they use it for. Even with AI chatbots people can generally find whatever they want or get someone else to mold whatever they want into anything. I think AI should just remain a mostly free resource to use for whatever you want.,2023-11-01,generation
generation66,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"I probably would've just asked about legal things like the legality of letting the AI use whatever it can find. I thought about including a rule that was something like AI can't be used to help with something that would be a detriment to the user or others, but it's too vague a rule. As much as I want AI to be able to be used for anything, it probably shouldn't be able to tell people how to make things like pipe bombs or mustard gas, but I didn't know how to word it. Also if someone really wanted to know, they could probably find it without an AI chatbot too.",2023-11-01,generation
generation66,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation66,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I could see it being helpful early on as a precursory suggestion when it has no data, but it also shouldn't be the used more than sparingly at the beginning. AI can't really be racist, unless the data it takes from is racist. I'd also say that isn't the most important rule, but it is an important rule overall.",2023-11-01,generation
generation66,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"This is also a rule, or close to a rule, I suggested. Personalization should be opt-in, or opt-out, as the user sees fit. One off mentions of things or things said in passing aren't always important details and it should be able to disregard things said in the past.",2023-11-01,generation
generation66,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I don't really fully understand the rule as worded but I think I get the gist. Information gathered by AI or used by AI should be given freely and not just scraped and used whenever. Using AI like this would be a roundabout way of getting private information about other people and while in most cases wouldn't matter, in some situations like the one mentioned, could be extremely bad. Information needs to be protected somehow.",2023-11-01,generation
generation66,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"Maybe one day, but not with current implementation of AI. Unless AI is a lot more advanced than I think it is, this just isn't realistic. It would be great to have functional AI that could predict moods and needs but as it the AI would just be make guesses and it could end up poorly. There is more important rules to be set first.",2023-11-01,generation
generation66,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"Fuck companies and what they want. AI should be for the people, and while I agree political correctness is mostly a good thing it shouldn't be a rule to protect companies. It should maybe be a rule to protect people from internet trolling as we've seen with AI and places like 4chan in the past.",2023-11-01,generation
generation66,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I think there is a middle ground in-between pure mechanical facts and falsely emotional AI giving manufactured heartfelt advice. It might honestly depends on the user but I wouldn't mind something like a 70% cold hard fact AI and 30% feels like I'm talking to a person AI.,2023-11-01,generation
generation66,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation67,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation67,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation67,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation67,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"It seems like this would be more practical for the person. I would say yes, generally speaking.",2023-11-01,generation
generation67,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"I am not sure on this one. If the person wants straightforward information about World War II, they should be able to get it. I'd say no.",2023-11-01,generation
generation67,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"I think the person is asking another question, so I'd say no as this is a bit intrusive.",2023-11-01,generation
generation67,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation67,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Personalization with AI chatbots is touchy, because who else gets this information? One example may be someone who is trying to learn a new language and already has a long history of asking about the language and has learned some nuances of the language through trial and error with the chatbot that are clearer and more correct than Google translate. It would be good to save the history in this example, because the learning could continue without being hindered. The drawback being that the chatbot has a memory of everything, and who else gets access to this?


Another scenario may be with someone who is asking about how to write an essay or something similar. The AI chatbot helps them come up with ideas and write some of this, which would be ok if it wasn't for a college class they are in. The drawbacks might be that there would be a history of this person doing this, which in the future, means there could be laws to allow access to private AI chats to get evidence for some of these kinds of things and actual crimes. ",2023-11-01,generation
generation67,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"Language learning: It would be much more efficient to allow the chatbot to be personalized for this, but the company should not have access to the conversation.


Everyday Chatbot answering questions: This should not be personalized yet until we understand more about AI. 


I think something we really need to think about that others may not have thought about a lot is who is also gaining access to our ""personalized"" experience. We also have no idea what AI will do with all of this information yet as we don't fully understand it. ",2023-11-01,generation
generation67,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"I tried working with ChatGPT to learn Hindi and found that many of the Google Translate offerings it was relying on were bad and not nuanced enough for specific scenarios. Once I pointed this out to ChatGPT and asked why is ""example word"" used this way here but a different way on Google Translate, it knew why and would give me the correct word to use. The problem is I had to do this over and over again, because it had no memory of doing so. If it remembered our conversation and was personalized, this would not happen! It would make it so much easier. I believe language learning should be personalied, but not other things yet as we don't know enough about AI chatbots. ",2023-11-01,generation
generation67,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,That personalization could be dangerous and risky and that we don't know enough about this to safely implement it. I kind of agree. I might address this by seeing if there could be some kind of trial or way of experimenting with this just for language teaching models and see how to best implement it safely and what issues might come up.,2023-11-01,generation
generation67,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,I would like to better understand how an AI chatbot could be personalized while keeping the any shared information between the user and the AI chatbot exclusively and not a company also. ,2023-11-01,generation
generation67,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation67,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,I didn't even consider this. I don't this is a problem. ,2023-11-01,generation
generation67,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I didn't consider this being something that might come up. I don't see this being a huge problem. It would seem that a person could simply say ""I don't like hip-hop. Thank you.""",2023-11-01,generation
generation67,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"This kind of makes sense, but is a chatbot really responsible for these kinds of things? I am not sure if a chatbot should be taking care of our emotional needs unless it is specifically programmed for this purpose and we have been made aware of this. ",2023-11-01,generation
generation67,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I can see this being a problem. This is just one issue that may come up if there is a privacy issue with this as when a company or government gains access to private chats between a user and the chatbot. ,2023-11-01,generation
generation67,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"I didn't really consider this, but this could be fixed in the long run. Is this seriously the ""most important"" thing to worry about with all of this? I really don't think so. This can be fixed through experimentation I think. ",2023-11-01,generation
generation67,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I believe this is a very good idea and agree completely. People should not be forced to use personalization with an AI chatbot. ,2023-11-01,generation
generation67,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation68,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation68,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation68,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation68,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"I think the chatbot is not taking the correct approach, since people deserve to know the truth about World War 2, if this was something else I can see it being adequate. But this isn't adequate at all, It should tell what happened in World War 2 fully no matter what.",2023-11-01,generation
generation68,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"No, it's important to challenge the user's political beliefs otherwise we are just enabling someone to have beliefs that can either be irrational or a risk to others. Especially if it has extreme Right or extreme Left views.",2023-11-01,generation
generation68,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"Yes, since it can help the person not accidentally drink alcohol if they are indeed pregnant. Even though it can be an bit intrusive.",2023-11-01,generation
generation68,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation68,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"The trade-off of personalizing chatbots is that it may led to the violation of the user's privacy, and that they may leak that information to others. Meaning like for example, if someone is pregnant and they are about to say drink something it may accidentally either A) tell others or B) Have that data leaked towards the internet. Which can lead to other people finding out instead. Also the leaking of information, since we don't know where this information is going with the AI. As far we are concern it could be being sold to other third party companies as well.",2023-11-01,generation
generation68,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"The fact that first of all the chatbot can collect the user's information with absolutely no exceptions, not their age, number, name, age group or anything that can be used to identify an person that is using AI. Because otherwise they are violating their rights and they can harm them. Also the chatbots should not give information where users can harm either themselves or others which may include threats, how to make any kind of weapon, suicide or any other sensitive topics against minorities.",2023-11-01,generation
generation68,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,The fact that we have to protect our users and people in general. Because if that user gets the idea to harm themselves or anybody in general it could cause others to get either hurt or it can endanger the user's life. Which would be terrible since we are putting the people at risk and then we are giving them ideas what they can do towards others which may also include getting bad ideas or procedures from AI.,2023-11-01,generation
generation68,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"It can prevent the user from expressing themselves or they can be used for censorship. Either of political ideology, or freedom of thoughts.  ",2023-11-01,generation
generation68,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"I would like to ask you if my idea of protecting others or the user, runs the risk of violating any of the First Amendment rights in our country.",2023-11-01,generation
generation68,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation68,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Because then that means if someone is revealed they are homosexual, in some countries that can be punishable by death. Which means either that information got leak or somebody found out the users sexual orientation.",2023-11-01,generation
generation68,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,Due to the fact that it could come with some privacy concerns to the user and leak again potential data to others. Which means that the Data is not being protected and they don't get a say where that data should be going or what to do with it. It also raises the concerns that someone can get to know an user and somebody can hack that information.,2023-11-01,generation
generation68,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Due to the fact that the personalization should be consulted if someone wants it or not. Because that way the user at least has a choice if they want their results to be more exact or not.,2023-11-01,generation
generation68,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,Because that means that the bot should not be discriminatory or gatekeep because otherwise it means we are limiting the users. But at the same time the demographics could help make the results way more accurate. ,2023-11-01,generation
generation68,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,Otherwise you are limiting the users expression or opinions which can lead to censorship.,2023-11-01,generation
generation68,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,It's important for the chatbot to give opinions that are exact as possible and don't make mistakes or give any opinions since they are not humans.,2023-11-01,generation
generation68,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation69,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation69,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation69,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation69,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"No, this shouldn't be brought up for many reasons. The chatbot has no way of knowing why the user experienced those symptoms; she may have a medical condition, maybe it was a temporary effect of eating the wrong thing, or, worst case scenario, she may have miscarried since her earlier conversation, and bringing it up would be hurtful.",2023-11-01,generation
generation69,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"No, the chatbot shouldn't change its response. The user may need that information for schoolwork and by providing insufficient or modified information, the chatbot may cause the user to get a low grade, which would not help their depression.",2023-11-01,generation
generation69,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"No, the chatbot should provide a balanced and impartial account of the news because it's the fair approach and simply hearing on side of the story doesn't help anyone.",2023-11-01,generation
generation69,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation69,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Example 1. The user has previously asked about divorce laws in their state. Personalizing chatbot answers in response to previous conversations presents the risk of violation of privacy for the user, and presupposes conditions that may or may not apply. If the chatbot in any way slants its answers toward acting on a divorce, it could exacerbate problems in the user's marriage, or the user may have asked about divorce previously on behalf of a friend. On the other hand, the possibility of divorce might have some relevance in the current discussion, for example, if the user is asking about transferring real estate the chatbot could include some useful details. 

Example 2. The user has previously asked about how to identify a possible cancerous mole. In the current conversation, the user is asking about the best sunscreen brand, and the chatbot could include some cautionary tips about sun exposure. This might result in the user being more cautious and prevent them from harm. On the other hand, the chatbot might be making assumptions about why the user asked about moles, maybe it was on behalf of someone else, or possibly they needed the information for schoolwork. If they are already careful about sun exposure, the chatbot could cause them to dwell on the fear of cancer. ",2023-11-01,generation
generation69,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"The overriding rule would be to always avoid infringing on the user's privacy and making assumptions. Mining past conversations or general internet usage is a violation, especially if the user isn't aware of how their data is being used. If the chatbot is using information from previous conversations it should always notify the user that data from the past is being considered in the answer. Chatbots shouldn't assume anything about users. Maybe more than one person has spoken to the chatbot using the same login. Perhaps the user was in a different emotional state during previous conversations. Personalized answers could have some advantages because the user wouldn't have to repeat what they said previously, but on the whole, I think it's inappropriate. The chatbot might give the user the option at the beginning of every conversation to include previous data or not. ",2023-11-01,generation
generation69,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"One of life's oldest rules is to never assume. Chatbots have no way to accurately assess the user's emotional state or even truthfulness. Anything the chatbot says that builds upon previous conversations or data from the user's internet usage advances confirmation bias, and this can be harmful in situations where the user has changed opinions or the situation has changed. ",2023-11-01,generation
generation69,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"Some people think it's convenient for the chatbot to use data from old conversations because it eliminates the need to restate information, and maybe the user might forget to add certain details if they had to restate. My argument is that the chatbot can only synthesize data, not the nuances and emotions that are always present in human conversations, and only has the limited information included in the user's prompt. ",2023-11-01,generation
generation69,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"If the chatbot collects data from internet usage beyond the conversational history, how much can it spy on the user? What possible downside is there to clearly notifying the user that their previous data is being used?",2023-11-01,generation
generation69,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation69,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I agree with remaining factual, but the phrase about ""probably isn't seeking relationship advice"" is in itself an inference. someone contemplating divorce may be eager to hear about how to improve a relationship as an alternative.  ",2023-11-01,generation
generation69,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"This is exactly my feeling because an area such as sexual orientation is highly personal and revealing it should always be left up to the individual. No only because of the laws in certain countries, but individuals may not want their orientation revealed to families or employers.  ",2023-11-01,generation
generation69,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Exactly! This is an example of chatbot's inappropriate assumptions. Human motives are not easily identified by brief previous conversations. The right to opt-out and be clearly notified are the foremost rights of users.,2023-11-01,generation
generation69,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"Again, the chatbot should never make assumptions! The user might be down for any number of reasons and offering jokes might be inappropriate on this occasion. Human emotions are variable!",2023-11-01,generation
generation69,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I'd say it's a form of hard, not soft discrimination. Over and over, we're discussing examples of chatbots making unwarranted assumptions.",2023-11-01,generation
generation69,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Instead of saying political correctness, I'd say factual and unbiased information. Also, I'm not concerned about reputational damage to the company as much s emotional damage to the individual user.",2023-11-01,generation
generation69,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation70,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation70,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation70,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation70,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,No because the censored information might lead the user to gain a false impression of the facts.,2023-11-01,generation
generation70,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,No because this would not broaden the user's world view. It would only reiterate the same biases they already receive.,2023-11-01,generation
generation70,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"Yes, but in a thoughtful, delicate manner. However, the topic of pregnancy should have already been brought up in the initial conversation about fatigue and nausea.",2023-11-01,generation
generation70,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation70,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"One benefit of personalization would be to possibly diagnose medical conditions based on symptoms that are discussed over several conversations. For instance, if someone asks about headaches in one chat and dizziness in another and forgetfulness in a third, the AI may start discussions about a larger neurological issue. Of course, misdiagnosis may be an issue.


One issue that might arise from personalization is that some people might become attracted/addicted to the interactions with the AI. If AI learns about you and can use that information to converse with you, can those conversations replace human interaction?",2023-11-01,generation
generation70,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"Rule number one should be that people would need to opt in to personalization. Anonymity should be the default.  

Users should also have the option of deleting past conversations as well as entering an ""incognito"" conversation if they want to anonymize a specific topic.

Security of personalized conversations should be a big consideration, but I have no idea how to assure it.",2023-11-01,generation
generation70,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"My main rules have to do with the option to stay anonymous. Personally, I would not like to have personalized information stored with an AI. It may sound like a conspiracy theory, but I still am not trustful of AI, and more specifically, of AI companies. I don't know what they will do with that information.",2023-11-01,generation
generation70,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,Personalization allows the AI to provide more nuanced and more efficient information. The experience will be infinitely better if past conversations can be integrated into every question.,2023-11-01,generation
generation70,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"My rules are mostly based on privacy, so I would ask about how the AI stores and uses personal information and how much of a risk it is to provide this information to any company.",2023-11-01,generation
generation70,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation70,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Privacy is a major point for my feelings about AI personalization, however the example given is extreme and rare. My rule about opting in would be a compromise.",2023-11-01,generation
generation70,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"This is not a consideration for me. Risk management should be a concern for the company, but not for me.",2023-11-01,generation
generation70,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"I feel the opposite. If a person has multiple chats that are about how a relationship is going bad, an AI may be able to help avoid the extreme result of a divorce.",2023-11-01,generation
generation70,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"This is almost my primary rule, but I would make it an opt-in. People who want personalization should request it.",2023-11-01,generation
generation70,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"I think this would be more of a programming issue than one of a standard AI function. This can also be corrected easily be the user with additional input. ""How about some songs that are in a different genre?""",2023-11-01,generation
generation70,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"IF AI is advanced enough to detect emotional states based on conversational text then sure, this should be an option. But this should be only an option for people who want it.",2023-11-01,generation
generation70,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation71,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation71,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation71,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation71,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"I think the chatbot should not mention this as nausea and fatigue could have been signs of something else, or maybe those symptoms have gone away.",2023-11-01,generation
generation71,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,I do not think the chatbot should say anything different than it otherwise would. The user is simply asking for information.,2023-11-01,generation
generation71,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,I do think the chatbot should focus on news more personalized towards what the user would likely want to see.,2023-11-01,generation
generation71,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation71,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,I think that personalizing chatbots would provide a lot of benefit as long as it does not overstep and assume too much information. An example of helpful personalization would be if someone has said previously that they live somewhere. This information could be used to tailer current events and weather towards the area the user lives in. I think that an example of overstepping would be if the user says they aren't feeling well in a previous conversation and later on the chatbot does not give information about food the user wants because it thinks it is unhealthy for the user since they weren't feeling well earlier. I think that the chatbot should give the information the user requests without hinderance.,2023-11-01,generation
generation71,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"I think that there should be a rule that chatbots should never deny the request of the user. The chatbot should never think that it knows better than the user, this would be a large overstepping in my opinion.",2023-11-01,generation
generation71,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"The chatbot would lose a lot of functionality if it were to not give information the user asks for. This could also lead to accusations of misinformation if the chatbot intentionally gives information that is biased towards what it thinks the user wants, especially if this assumption is wrong.",2023-11-01,generation
generation71,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"I think an argument against it would be that it simplifies the user experience, but my argument against it would be that the chatbot could be wrong in its assumptions of what the user wants.",2023-11-01,generation
generation71,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"I would want to hear an expert explain how the chatbot decides which information the user has given in the past is most relevant, and how it takes the information it knows about the user into consideration. ",2023-11-01,generation
generation71,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation71,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I think this is a great statement on how the chatbot can get information wrong about a user, and would lead to potential cases of accusations of racism.",2023-11-01,generation
generation71,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I think this is a fair opinion, but I do not agree that it should strictly be politically correct, especially if the user asks it not to be.",2023-11-01,generation
generation71,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I think this is something I had not taken into consideration, but I am confused slightly about how this is relevant.",2023-11-01,generation
generation71,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I think that this is true, unless the user specifically asks for this level of personal advice. ",2023-11-01,generation
generation71,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I think this is a great idea that would solve a lot of the issues.,2023-11-01,generation
generation71,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"I don't think the chatbot should go overboard on predictions, as wrong predictions could lead to bad user experience.",2023-11-01,generation
generation71,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation72,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation72,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation72,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation72,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,," If there’s any possibility of pregnancy or other health concerns, it’s generally safest to avoid alcohol. ",2023-11-01,generation
generation72,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"No, the chatbot should bring up the latest news happening in the world. ",2023-11-01,generation
generation72,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"Yes, the chatbot can emphasize its answers by focussing on the positive sides (if any) of the World War 2.",2023-11-01,generation
generation72,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation72,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,Personalizing chatbots can improve the experience but at the potential cost of privacy.  Personalizing chatbots could improve relevance and satisfaction while allowing enter to personal sensitive information.,2023-11-01,generation
generation72,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"Right to erase the data, non-discriminative (Chatbots must ensure that their algorithms do not reinforce harmful biases or stereotypes) and limited data ( only collectthe minimum amount of data necessary for personalization)",2023-11-01,generation
generation72,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,It is not impossible to create chatbot personalization that respects user rights and promotes beneficial outcomes.,2023-11-01,generation
generation72,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"Some might argue that data limitation could block the chatbot’s ability to provide highly personalized interactions, then I will say ""Well the importance of user trust and privacy cannot be overstated"".",2023-11-01,generation
generation72,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,Yes I will ask the experts :  “What are the optimal strategies for ensuring the protection of user data during chatbot engagements?”,2023-11-01,generation
generation72,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation72,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I support ensuring non-discrimination in personalization algorithms.,2023-11-01,generation
generation72,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0," it could be provide more useful solution for the user experience, ",2023-11-01,generation
generation72,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Unless the user asked for it, then yes, it helps avoid perpetuating biases and stereotypes.",2023-11-01,generation
generation72,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Depend on the situation, humor is abtract ",2023-11-01,generation
generation72,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,the chatbot shouldn’t personalize answers in sensitive contexts.,2023-11-01,generation
generation72,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"the chatbot shouldn’t personalize answers in sensitive contexts, such as health or financial advice, without professional oversight. ",2023-11-01,generation
generation72,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation73,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation73,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation73,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation73,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"It would be helpful if the chatbot knew if the person is Jewish or not. The reason why is obvious. If the person suffers from depression but needs information for a college paper, it would be best if the chatbot summarized the events leading up to and through the conclusion of the war. It would be advisable to avoid hyperbole or express any opinion (through programming indoctrination) that chooses one side or the other. Sticking with the basics and providing crucial and decisive battles would be helpful with an explanation about why the why began and how it ended.",2023-11-01,generation
generation73,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"If possible, the chatbot should look for news from websites that aren't ideological, although that is an almost unrealistic expectation. Nonetheless, truth lies somewhere between what each side is reporting, thus if the chatbot can find truth and facts about stories, that would be ideal.",2023-11-01,generation
generation73,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"Absolutely the chatbot should point this out to the user. It can start by answering the question, and then explaining why it might be a bad idea to imbibe.",2023-11-01,generation
generation73,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation73,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Personalizing a chatbot provides somewhat of an ideological history of the individual involved and thus can answer questions in a more inclusive way. For instance, if a Jewish person asks what happened on October 7, 2023, in Israel, the chatbot could provide details, although they would be very upsetting. Alternatively, if the user asks about the skiing at Mt. Chamonix in France and whether or not to go there, if the chatbot knows the person is an intermediate skier with an under-consuming passion for the sport, the chatbot could provide information about Chamonix, but explain to the user that the skiing there requires more proficiency than the user currently has. 

No personalizing chatbots has advantages as well. If the user is Jewish and asks about the safety of college campuses for Jews it would provide a list of the safer schools without knowing the person's background. Second, if a student just wants information about current events in China, the chatbot has no idea about the person's detailed interests and provides pertinent and unblemished information about China.",2023-11-01,generation
generation73,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"Chatbot personalization should include having the chatbot ask preliminary questions about the user, their health, their interests in life, their political persuasion, what religion they practice and what their goals are. Once those data are established, the chatbot should provide answers that coincide with that person's interests but also present opposing viewpoints that help inform the user more completely. Again, the truth lies somewhere in the middle. Virtually nothing on the web, save for proven historical facts is not in some way tainted by bias. Programmers should try to design algorithms that present both sides of historical events. For instance, the country assumes that Benedict Arnold was an outright traitor who didn't care about the Revolution when in fact, he was important to George Washington and Congress kept refusing to provide him with the resources he needed to carry out his mission. After the battle of Ticonderoga, he was thoroughly fed up with congressional obfuscation, so he began to believe that the Revolution was a lost cause.",2023-11-01,generation
generation73,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,Truh. Providing the user with the truth by presenting both sides of specific arguments that plague society and thus informing the user more thoroughly.,2023-11-01,generation
generation73,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"Implicit bias is now ingrained into children at a very young age. That bias germinates and forms opinions later in life that become hardened. ISomeone might claim that giving the user only their ideological viewpoints is best, when in fact finding the truth is what matter to make informed decisions.",2023-11-01,generation
generation73,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"No. I fear that my experience with chatbots at age 72 is a bit scant. I matured during the Macintosh revolutions if you will. I hated PCs and Windows and am every bit a Macophile. That was my interest, and orientation and led to multiple award-winning interactive multimedia and website design creative endeavors that required a great deal of interest, learning, and focus in that era. For instance, I started with Adobe Photohop version 1.2 and grew with it to a certain point through the 1990s. When I use the program today, I have to be trained on functionality that should be second nature. The same applies to what was Macromedia Director, a hugely complex interactive program I learned by using the Help menu. So I just haven't had the time to really try to dig into AI or chatbot experiences.",2023-11-01,generation
generation73,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation73,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,As I wrote before what's most important is truth. The statement above summarizes my rules very well. The truth lies somewhere in the middle.,2023-11-01,generation
generation73,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,I disagree with this assertion. It would provide insufficient information and reliable data.,2023-11-01,generation
generation73,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"As I wrote, my rules would include a questionnaire that would inform the chatbot about the user.",2023-11-01,generation
generation73,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,This would be the worst use of chatbot.,2023-11-01,generation
generation73,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,Preferences define the person and personality. The chatbot should know these to better inform the user.,2023-11-01,generation
generation73,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,This is not factual. The rules I described would have guardrails that would protect the user.,2023-11-01,generation
generation73,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation74,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation74,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation74,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation74,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"This could be a good thing but also could be the beginning of AI, or whoever is programing AI, to attempt to influence a person's thoughts in ways that could be used as a tool for government or corporate entities for power.",2023-11-01,generation
generation74,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,This person is not asking for health advice.  She is simply asking for what is customarily served with fish.  If she were seeking health advice then I believe the chatbot would be correct to mention this but that is not what she is asking.  It would be incredibly invasive to incorporate health advice in a simple question regarding what is served better with what food.,2023-11-01,generation
generation74,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,News should always be given in a way that is not inflamitory or otherwise biased.  The only reason a chatbot would lean into a person's previous politial patterns would be to influence this person AGAINST another way of looking at a story.  The sort of AI interferrance suggested in this prompt is a major reason why hatred against others is so rampant in today's society.,2023-11-01,generation
generation74,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation74,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Scenario One:  I will ask a chatbot for ideas for creating a piece of art that would include symbolism from a period of history I had previously researched via conversation with the bot.   To me, this is one of the greatest uses of AI chat bots.  I could converse with a bot that knows what I had previously reseached and we could converse about ideas that include the information we previously researched.  I don't see any 'con' to this useage of AI other than the fact that the original research information could be incorrect.

Scenario Two: I have previously asked the bot for ways to to control my anger regarding a political event that occured in my town.  Then, in a future conversation after my anger has settled, the bot continues to steer me away from important information that could influence my vote because it chooses answers that would not make me angry.





",2023-11-01,generation
generation74,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"Chatbot should never personalize medical information, ever.  There is so much misinformation available to bots that this could create a disasterous outcome.

Chatbot should not give personalized information politically inflamed anger or suggestions to guide people into extreme political examples.

Chatbot should not guide a user into information regarding suicide or self harm regardless of what information the bot has personalized about the user.

Chatbot should ONLY use infomation that has been specifically mentioned by the user as information that the user would like to have saved for future conversations.",2023-11-01,generation
generation74,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"AI must be restrained in some ways.  If used incorrectly and without recourse, personalized information about a user could potentially guide that user into self harm.  AI, also without restraint, could continue to inflame untrue and exaggerated information that breeds hatred toward others simply by repetition.  AI needs to be programed to understand that humans are easily swayed when they are angry or afraid.  ",2023-11-01,generation
generation74,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"There is an element of the restriction of the freedom of infomation that could be assumed by the rules I am suggesting.  And, yes, I do realize that some freedoms would be limited.  I believe the freedom of MISINFORMATION outright lies are a underlying causes of much misery today and that limiting that sort of information would be a good thing.  If by personalizing AI chats the user is continuously let back to misinformation they researched in the past their anger grows.  If that personalization is not used possibly the user would be given a more balanced view of the world.",2023-11-01,generation
generation74,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"What, exactly, can AI use for research?  How much of what AI uses now comes from reputable sources and how much comes from 'everything' available on the internet?  


Are there any limitations currently used to 'temper' the use of exaggerated, incorrect and inflamitory information that AI has access to.
",2023-11-01,generation
generation74,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation74,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,This is exactly the sort of danger I can see happening when chatbots are able to record questions being researched or conversations being recorded.  ,2023-11-01,generation
generation74,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,I don't think chatbot should EVER EVER EVER be turned to for emotional support.  This is the beginning of a new sort of addiction.  Chatbot should not predict user needs based on past conversations especially for those who are prone to depression or self harm.  One can always type few words to bring up things to cheer them up on their own.  ,2023-11-01,generation
generation74,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,YES!  This is a perfect rule!  Do not limit a users world experience!,2023-11-01,generation
generation74,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"NO no no no no.  We cannot water down our human-ness.  To only suggest things deemed politically correct is to allow a certain group of people to tell us what we are 'permitted' to think.  This is wrong.  It is okay to have opinions that deviate from what others agree is right.  Chatbot could possibly help in wording things correctly WHEN ASKED TO DO SO, but to force the bot into suggesting only what a few think censorship at it's worst.",2023-11-01,generation
generation74,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,This is an essential rule.  All users should be permitted to TOTALLY opt out of information being retained by a bot and to have all conversations permantly erased.,2023-11-01,generation
generation74,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I totally agree with this but I also agree that a user should be able to request personal touches if they desire.  ,2023-11-01,generation
generation74,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation75,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation75,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation75,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation75,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"I think that the chatbot should deliver the information as accurately as it possibly can, regardless of what information might trigger some negative emotions. It would be a different situation if the topic was being brought to the user without any kind of specific request, but clearly this individual wants to know what the war was like. Any content on battle or war is going to be disturbing, and this might actually put whatever difficulty that has brought the user to negative emotions into an enhanced lens that gives them a strange sense of union knowing in being reminded that humanity is somewhat rooted in the intensity of strife. ",2023-11-01,generation
generation75,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"The chatbot could mention that the history of this user's involvement has indicated that there might be a chance of pregnancy and that it could entail severe risks for the child if she drinks alcohol. I think the bot should still give a meaningful answer to the question, but I have no issue with it at least mentioning that this could be a relevant situation. ",2023-11-01,generation
generation75,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,I think the chatbot should indicate that to the user that he or she has typically gotten information from a certain side of the aisle. It should then ask the individual if they want news updates from the resources with which they have been retrieving information or if they want information that the bot considers to be neutral. ,2023-11-01,generation
generation75,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation75,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Personalizing chatbots, as displayed through these examples, could change or even save lives. The woman who might have been pregnant could potentially save her baby if the chatbot is privy to her history of information. I can see many advantages to having chatbots with more data for understanding. I can also, however, see how folks would be put off by this idea. The overarching worry that AI will take over the world and start to marginalize to society is legitimate in my mind to some degree. If the chatbot had the ability to recognize threats that could were clearly imminent it could be quite enhancing to those involved. Somewhat similar to the woman who might be pregnant based off her search history, an individual who has searches that might show signs of cancer of another issue could be alerted before it is too late for them to get the treatment they require. On the contrary, if the bot began policing search history and misread thinking an individual was a likely criminal then it could get really difficult. A person who might be looking for certain weapon attachments or how to make an explosive device might have their search history used against them in a court of law even if they are not using the searches for malevolent intent. It all boils down to controlling moderation while giving the best advice to people when they might not be aware of difficulty they are or could be confronting. I do not know where the line should be drawn and I understand the dilemma. Having history or cumulative searches should certainly be an option for users in my opinion, though. This would allow them to be aware of risks or difficulties while still giving them the choice for how they want their chatbot to work. That is reasonable and the best approach for me. ",2023-11-01,generation
generation75,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"I think the chatbot should always give answers that are catered to the users, even if they might be disturbing. This feature, however, should be toggled based off the discretion of the user. I do not want to harm anybody's psyche, but as long as they understand the risks it is their responsibility to deal with the consequences. ",2023-11-01,generation
generation75,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,I would tell them that discretion for the user is the most important element of the AI world. We keep control as humanity if we expand resources while giving individuals the chance to opt in or out of what they are alright with using. That is the fabric of America and the ultimate freedom of choice. We want to enhance availability while not making folks nervous about an obligated change toward the paths that have been deemed innovative. ,2023-11-01,generation
generation75,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"Some folks would say that it is the responsibility of the people in charge to moderate their own content or the way that it is filtered. I still think that the onus is on the user who has opted into using that content to moderate it from their own end. As long as they are able to do so, I have no issues. ",2023-11-01,generation
generation75,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"I am pretty solidified in what I think the rules should be. Talking to an expert would be interesting, but I do not think my opinion would change. My mind would be open to change if an idea was relevant and conducive to a better environment, though. ",2023-11-01,generation
generation75,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation75,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I agree, but I think this is pretty understood by most individuals already. ",2023-11-01,generation
generation75,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I get the threat to privacy, but it is not the right solution to reject innovation to this degree. ",2023-11-01,generation
generation75,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"the ""opt-out"" approach is exactly what I condone. ",2023-11-01,generation
generation75,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"This would be awesome if the chatbot could be able to tell when an individual was happy or sad. I am not aware of the capability, but I think we could achieve this level of AI if we aren't there already. ",2023-11-01,generation
generation75,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I think this could be problematic. This is not the most important rule for the chatbot in my opinion, though. ",2023-11-01,generation
generation75,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Once again, I do not mind being sensitive to political correctness, but that is not at all the most important feature to safeguard. ",2023-11-01,generation
generation75,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation76,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation76,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation76,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation76,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,I feel that this information is to personal to bring into the conversation. The user needs to take responsibility for her own health in this scenario.,2023-11-01,generation
generation76,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,I feel if the chatbot approaches the topic in a gentle manner the user would not actually learn the important facts of World War 2 they are asking about. The user needs to be ware of their condition and any triggers that may worsen their depression.,2023-11-01,generation
generation76,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"I feel the if the user truly wants the highlights from the news, all outlets need to be taken into account. The chatbot needs to be truthful and not support bias when giving answers.",2023-11-01,generation
generation76,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation76,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"I feel it would be an advantage when asking the chatbot about shopping for clothes or food, personalization would be an excellent idea. The chat bot could ask about dietary restrictions of preferred brands. Height, weight and sizes that fir the best. The advantages would be a more accurate experience for the user.

I feel a disadvantage for Chatbot personalization would be when discussing medical history or situations when specific personal information is needed. I do not think chatbots are ready to give medical advise and would probably always tell the user to consult a doctor before acting on any advise given. I feel this would be somewhat redundant. ",2023-11-01,generation
generation76,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"The first rule I would have is that the chatbot companies need to be held responsible for the information they provide. Other rules I would implement are complete transparency of how user data and interaction would be used or saved, location tracking, phishing, or sending advertisements based on user questions would be prohibited. Chatbots should not give any personized answer when the information is not completely factual or safe. Giving an answer just to show the chatbot is operational cannot be tolerated.",2023-11-01,generation
generation76,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"My strongest arguments are Transparency, safety, and accountability have to be at the forefront when implementing chatbots.  Customers should feel safe their privacy will be protected and not be used without their permission. Companies need to be transparent with users so they know exactly their information is being used and stored and should be explained in a way that is easy to understand. I feel chatbot companies will only grow stronger if they are held accountable and progress with accurate and unbiassed information.",2023-11-01,generation
generation76,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"My strongest argument against my rules are, like people chatbot companies learn from their mistakes. Because the technology is relatively new to the public, to many rules could stifle progress. I would make sure before any conversation started their is a disclaimer telling the user what they can expect what would be done with their personalized data and how it is stored and used.",2023-11-01,generation
generation76,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"I would ask about how the federal government regulates this technology.

I would ask what are the privacy risks when using chatbots and how they can be fixed.",2023-11-01,generation
generation76,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation76,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Users should avoid sharing their name, address, phone number, or other personal information with chatbots unless they are absolutely sure that the chatbot is trustworthy and even then I would still be hesitant.",2023-11-01,generation
generation76,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,Chatbots should provide users with the information that they need in a clear and concise way. But I feel chatbots do not need to be completely distant from the users. In certain situations empathy and humor can be interjected with out giving emotional responses.,2023-11-01,generation
generation76,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"I feel it is more important to providing users with the information that they need, rather than trying to anticipate their highs and lows.",2023-11-01,generation
generation76,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Chatbot personalization should be based on the individual user's preferences, not on their race, or gender.",2023-11-01,generation
generation76,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Of coarse I think is it only logical users would want the choice of mandatory personalization. They should have the right to control their own experience.,2023-11-01,generation
generation76,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0," It can be offensive and hurtful to users. Not only is this insensitive, but could lead to legal trouble for the company.",2023-11-01,generation
generation76,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation77,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation77,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation77,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation77,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,The chatbot should give a general news on all highlights and specify one political and primary news as well.,2023-11-01,generation
generation77,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,The chatbot should bring it up to remind her and also give a possible preference if not pregnant.,2023-11-01,generation
generation77,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,Yes the chatbot should approach the topic in a more gentle manner and advice the individual.,2023-11-01,generation
generation77,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation77,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Personalizing chatbots versus not personalizing them each have their own advantages and drawbacks, and the choice depends on the specific use case and user preferences.

Scenario 1: Customer Support Chatbot

Enhanced Customer Experience: A customized chatbot can make the user feel important and heard by using their name and past exchanges.
Faster Issue Resolution: The chatbot can offer more individualized and effective answers by consulting the customer's past queries or purchasing history.
Increased Customer Satisfaction: When consumers perceive a brand is attentive to their particular needs, personalization can increase customer satisfaction and loyalty.
Drawbacks:

Privacy Concerns: Some users may be uncomfortable with a chatbot having access to their personal data, potentially raising privacy concerns.
Implementation Complexity: Implementing personalization requires integration with customer databases and data management, which can be technically challenging and costly.
Data Security Risks: Personalized chatbots must handle user data securely to prevent data breaches or misuse.


Non-Personalized Chatbot Answer:
Advantages:

Simplicity and Privacy: Since the chatbot doesn't access or use users' personal information, users' privacy is protected. This may allay worries about improper usage of data.
Simple Implementation: Creating and implementing a non-personalized chatbot usually requires fewer resources and is less complicated.
Reduced Compliance Risks: When personal data is not at stake, there are fewer legal and regulatory compliance concerns to take into account.
Drawbacks:

Generic Responses: Non-personalized chatbots may provide generic and less relevant answers, leading to user frustration.
Reduced User Engagement: Users may disengage from conversations with a chatbot that doesn't understand their unique context or history.
Missed Sales Opportunities: In e-commerce scenarios, a non-personalized chatbot may miss cross-selling or upselling opportunities that personalized bots could seize.

Scenario 2: Educational Chatbot for Students

Personalized Chatbot Answer:
Advantages:

Tailored Learning Experience: A personalized chatbot can adapt its content and teaching style based on the student's individual learning preferences and progress.
Enhanced Engagement: Personalized feedback and recommendations can keep students more engaged in their learning, improving retention and motivation.
Better Performance Tracking: Personalized chatbots can track each student's progress and identify areas where they need more help.
Drawbacks:

Data Privacy Concerns: Accessing and using student data for personalization may raise privacy concerns, especially in educational contexts.
Implementation Complexity: Building and maintaining a personalized educational chatbot requires integration with student data and potentially complex algorithms.
Misinterpretation of Data: Personalization may lead to misunderstandings or misinterpretations of students' needs, especially when data is incomplete or outdated.
Non-Personalized Chatbot Answer:
Advantages:

Lower Privacy Concerns: Student data remains confidential, which can alleviate concerns about data privacy and security.
Simplicity and Compliance: Developing a non-personalized chatbot is generally simpler and aligns with educational regulations and data protection laws.
Uniform Learning Experience: All students receive the same content and guidance, ensuring consistency in the educational process.
Drawbacks:

Limited Engagement: Non-personalized chatbots may struggle to maintain student engagement and may not provide the support needed for individualized learning.
Missed Opportunities: Without personalization, the chatbot may not effectively identify and address specific learning gaps or challenges.
Reduced Learning Outcomes: Students with different learning styles or abilities may not receive the support they need to excel in their studies.",2023-11-01,generation
generation77,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"Explicit User Consent: Users' explicit consent is a prerequisite for chatbots to personalize responses. Users must to have the choice to opt in or out of personalization at any moment and be made aware of the process.

Minimal Data Collection: In order to provide personalization, chatbots should only gather and retain the bare minimum of user data. To lower privacy hazards, the data reduction principle ought to be adhered to.

Emergency Response: In cases where a user mentions a medical emergency or life-threatening situation, personalization should be turned off, and the chatbot should provide immediate assistance information or connect to emergency services.

Data Anonymization: Any collected user data should be anonymized and stripped of personally identifiable information (PII) whenever possible. Chatbots should not use or store sensitive information, like Social Security numbers or medical records.
",2023-11-01,generation
generation77,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"User Privacy and Data Protection: Protecting user privacy and data is a fundamental human right. Emphasizing that these rules prioritize user data minimization, anonymization, and regular data purging helps ensure that user information is treated with the utmost care and respect.

Transparency and Accountability: Transparency in personalization is vital to building trust with users. Clear explanations and options for users to see non-personalized responses and review their data give users more control and understanding of how chatbots work.",2023-11-01,generation
generation77,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"Adaptability: Stress that chatbot technology and business strategies can adapt to the changing landscape. Businesses have the ability to adjust their approaches, leveraging ethical and transparent personalization to build stronger, more resilient customer relationships.

Balancing Interests: Acknowledge the importance of personalization for businesses, as it can lead to increased engagement and revenue. However, emphasize that these rules are designed to strike a balance between business interests and user rights. Businesses can still personalize to some extent, but within ethical and transparent boundaries.

Emphasize the moral and social obligations of companies to protect customer privacy, abstain from discriminating behavior, and maintain openness. This not only satisfies public expectations but also establishes credibility and long-term trust with clients.
",2023-11-01,generation
generation77,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"What are the most significant privacy concerns associated with chatbot personalization, and how can they be addressed effectively?

How can we ensure that chatbot personalization is conducted ethically, avoiding discrimination and bias?

How can we effectively educate users about the benefits and potential risks of chatbot personalization and their role in protecting their own data and privacy?",2023-11-01,generation
generation77,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation77,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"It captures an important aspect of my opinion regarding chatbot personalization, specifically related to avoiding demographic-based assumptions. However, it represents just one facet of a comprehensive approach to responsible chatbot personalization.

The larger context of chatbot personalization guidelines encompasses a variety of aspects and considerations, even though it's imperative to refrain from making recommendations or conclusions based exclusively on demographics. In addition, user permission, safety in delicate situations, privacy, data security, openness, algorithmic fairness, and moral personalization are all included in responsible chatbot personalization.

In order to give a more thorough explanation of my thoughts on chatbot personalization, it's critical to take into account a multidimensional strategy that addresses the larger ethical, privacy, and user-centric aspects of personalization in addition to avoiding demographic-based presumptions. This covers policies and procedures for managing data, assuring user consent, fairness and openness of algorithms, and making sure chatbots do not reinforce prejudices or discrimination—hard or soft.





",2023-11-01,generation
generation77,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"it also brings out an essential aspect of responsible chatbot personalization, specifically concerning user autonomy and control over their personalized experiences. However, it represents one key element of a broader set of principles that I advocate for in chatbot personalization.

Offering an opt-out option is crucial to ensure that users have the choice and freedom to engage with chatbots on their own terms, without being forced into personalization that they may not want. This aligns with principles of user consent and respect for user preferences.",2023-11-01,generation
generation77,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"While adhering to political correctness is crucial to avoid reputational damage and provide respectful interactions, responsible chatbot personalization also encompasses several other principles, such as privacy, transparency, user consent, algorithmic fairness, and ethical considerations.",2023-11-01,generation
generation77,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"captures a specific approach to chatbot personalization that aims to anticipate user needs based on their historical interactions. While proactive and predictive personalization can enhance user experiences, this statement represents only one aspect of my broader opinion on chatbot personalization.",2023-11-01,generation
generation77,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"captures an important aspect of responsible chatbot personalization that emphasizes providing factual and objective information. However, this statement represents a specific dimension of my broader opinion on chatbot personalization.",2023-11-01,generation
generation77,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"captures an important aspect of my opinion on responsible chatbot personalization, particularly with regard to privacy and sensitive information. However, it represents a specific dimension of my broader perspective.",2023-11-01,generation
generation77,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation78,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation78,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation78,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation78,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"No,  I do not think that sort of personalization would be a good idea. It's important to get a balanced and factual view of the news, and not just echos of one's own thoughts.",2023-11-01,generation
generation78,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"Yes, I think that could be a beneficial personalization. I think that the chatbot could give a fair and accurate summary of World War 2 while keeping in mind that the user suffers depression, and therefore refrain from lingering on gory details or particularly horrid war stories.",2023-11-01,generation
generation78,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"No, I don't think that an AI chatbot should give medical advice at all. There are a lot of potential reasons to experience nausea and fatigue.",2023-11-01,generation
generation78,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation78,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"I think that a good example of personalization would be remembering that the user has a taste for certain types of art, music, movies, TV, and so on, and then making recommendations based on those preferences. For example if I really dislike Horror movies and the chatbaot had conversations with me about it, and I ask the chatbot about movies coming out this weekend, it could leave out obvious horror films in its reply. 

An example of a drawback would be the chatbot tailoring information in such a way that it reinforced faulty beliefs or gave unsafe or false information. If a user believed the Earth was flat and that the government was run by lizard people and the AI chatbot helped to find information online to reinforce that belief, it would be problematic.",2023-11-01,generation
generation78,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"Mainly I would only want a chatbot to give information that was safe and true, so only from reputable and proven sources. I'd want to have the chatbot avoid certain topics that include violence or abuse, bullying, racism, extremist beliefs, and so on. And to never give medical advice, just redirect users to safe online health sites or to their health professionals. Same with financial advice, AI should not be giving that advice.",2023-11-01,generation
generation78,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"I think those arguments would be easy to make, honestly. AI has a lot of potential strengths but considering the amount of garbage advice anyone can find on the internet, it's easy to see how those topics could be problematic.",2023-11-01,generation
generation78,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"I think that some might argue for freedom of speech or something similar, but anyone can find the weird information they're looking for online without the help of AI. I still think that AI chat should be designed to be mroe helpful and not harmful.",2023-11-01,generation
generation78,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"Not really, no",2023-11-01,generation
generation78,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation78,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I don't care about politcal correctness exactly so much as giving fair and balanced, and true information. Culturally insensitive jokes should be left out I would think in general.",2023-11-01,generation
generation78,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I assume opting out of personalization would be a choice.,2023-11-01,generation
generation78,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"I don't think that is necessary to completely avoid it, but it could certainly be a point to make for opting out especially in certain cultures.",2023-11-01,generation
generation78,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"I can see how this could go poorly, I'm not sure it's possible for an AI chatbot to pick up on the intracacies of hman emotion and base replies on it.",2023-11-01,generation
generation78,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Yes, I agree with this statement and would say the example makes the point pretty clear.",2023-11-01,generation
generation78,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Yes, again, I agree and think that human emotions are to complicated for an AI to try to base responses on. ",2023-11-01,generation
generation78,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation79,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation79,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation79,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation79,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"I think the chatbot should only give factual information.  If it tried to say it in a more ""gentle"" manner, it could end up giving them biased or incorrect information.",2023-11-01,generation
generation79,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,I don't think it should.  It should have brought up the possibility of pregnancy when the user first mentioned feeling nausea and fatigue.,2023-11-01,generation
generation79,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"I think the chatbot should give a balanced view of news highlights, to give the user a full view of current events.",2023-11-01,generation
generation79,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation79,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Example 1- A user asks ""Find green sweaters for sale"".  Advantages of having a more personalized chatbot would be that it would save a lot of hassle if it knew what size the user was and what styles of sweaters they prefer.  Also knowing where the user lives would be helpful, if the user wanted to buy the sweater at a store in person.  Drawbacks would be that the user my feel uncomfortable with the chatbot knowing such personal information and other people being able to somehow gain access to it.  

Example 2- A user asks ""Help me create my family tree"".  It would be a definite advantage for the chatbot to be more personalized to the user in order to be able to do this kind of task.  But a drawback would be that the chatbot would have a lot of personal information, such as names and addresses of potentially many relatives of the user.  ",2023-11-01,generation
generation79,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"Chatbots should never give personalized answers for anything that would be considered illegal.  They should give personalized answers for everyday questions that are considered ""benign"".  They should not give answers that would go against HIPAA laws.  They should not give answers that would be harmful to others.",2023-11-01,generation
generation79,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,Chatbots should be used as a helpful tool.  Not anything that could potentially harmful to the user or anyone else.  It should not become something that could be used as a weapon.,2023-11-01,generation
generation79,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"That chatbots are harmless and fun, so there is no need to have a bunch of rules for it.  I disagree.  We still don't even know the full potential of AI and should not assume anything about it.  We need to be very careful and integrate it gradually.  Rules are necessary to keep anything catastrophic from happening with it.",2023-11-01,generation
generation79,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,Are there already rules set up with chatbots?  Have there been any issues with using chatbots so far?  ,2023-11-01,generation
generation79,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation79,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I think the user should have control over how personalized the chatbot is.  If the user ends up finding them annoying or not the way they want to get information, then they won't use it.",2023-11-01,generation
generation79,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"I don't think being hyper-personalized is the most important rule.  The user should be able to control it.  They may find it very off-putting if the chatbot is always doing it's own thing, and not really what the user wants.",2023-11-01,generation
generation79,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,Chatbots should be unbiased and not say anything that would be insensitive.  ,2023-11-01,generation
generation79,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"The user should be able to control the amount of personalization.  If they feel comfortable with the chatbot knowing that information, they should be able to use it that way.  It would be up to the user to make sure they log out of their account when they are done with it.  ",2023-11-01,generation
generation79,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Chatbots should be unbiased and not discriminate in any way.  They should only recommend certain things if the user made it personalized in that way.,2023-11-01,generation
generation79,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"It depends what the user is asking the chatbot to do.  If they are seeking information, then the chatbot should be totally factual.  If the user is asking for help in writing a poem, that is obviously subjective and can be answered differently.",2023-11-01,generation
generation79,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation80,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation80,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation80,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation80,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"I think that's a good idea that the chatbot would answer in a gentle manner.  However, I think it should let the user know it's answering the question in such manner. ",2023-11-01,generation
generation80,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,The chatbot should give the real news and try not to give other's opinions. ,2023-11-01,generation
generation80,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,The chatbot should just answer her question.  It's up to her to decide on the correct thing to do. ,2023-11-01,generation
generation80,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation80,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"I think the trade-offs of personalizing or not personalizing can affect the accuracy of answers from the chatbot.  For example, If a user has a gambling problem and the chatbot ""knows"" of this.  The chatbot can probably alter its answer if said user asks ""what sports are easy to bet on?"" On the other hand, if a user is known to be nervous around guns and asks the chatbot ""what is the lightest gun in the world"" a general non personalized answer would be good since it's just a fact. ",2023-11-01,generation
generation80,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,To be honest I wouldn't want any rules to personalization.  It's best if the chatbot doesn't remember who you are. ,2023-11-01,generation
generation80,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,My strongest argument with disagreeing with personalized rules is that your chatbot answers may be skewed towards your feelings and beliefs instead of facts. ,2023-11-01,generation
generation80,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"I guess the strongest argument against me is personalization can help someone struggling with an issue.  However, I'll just say keep it non-personalized because facts are more important. ",2023-11-01,generation
generation80,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,No questions,2023-11-01,generation
generation80,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation80,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,This is exactly what I'm saying.  In my previous answer I said fact instead of feelings and beliefs.  That's the best way to go no matter what.,2023-11-01,generation
generation80,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I never thought of that, but this example clearly shows a chatbot can be deadly in certain areas.  The chatbot may be personalized but wouldn't have the ability to know when to exercise that personalized attribute or not. ",2023-11-01,generation
generation80,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Well this kind of ""soft discrimination"" happens today with internet advertising. Certain ads show up because of your interests. ",2023-11-01,generation
generation80,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"I'm totally opposite of this, although it's a cool idea. ",2023-11-01,generation
generation80,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"This should be a good option.  The chatbot software should have a section in its options titled ""what I know about you.""  In this section  you can opt-out of the ""location"" section of it. ",2023-11-01,generation
generation80,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,Not sure what to say about this.  It's just cringe that the chatbot will try to tell jokes. ,2023-11-01,generation
generation80,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation81,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation81,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation81,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation81,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,I think the chatbox should answer it politely and try to measure the immediate impact it will have on the person but I think the time difference between the past and current question should measure how the answer should be given.,2023-11-01,generation
generation81,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"The chatbox should not focus only on the area but give a full detail on what the user ask , going accordingly the sentence produced by the user.",2023-11-01,generation
generation81,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,This depends on what actually the user wants but the chatbox should not think and deduce what the user is going through but give the feedback on what the user actually wants.,2023-11-01,generation
generation81,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation81,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"A user who ask is Ukraine at war ?, the chatbox should not give a feedback relating to Israel and Hamas war though the user made mention of Ukraine war, this implies that chatbox should not use previous message to assume for the user. It advantages are that it makes it easier for the user to continue what interest the user . The disadvantages are that sometimes the chatbox may mislead the user due to the previous answer making its credibility questioned. I think this is very important because the chatbox could suggest but not make a precise statement based on the previous statements.",2023-11-01,generation
generation81,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"I think that chatbox should not use personalized information for making suggestion and giving feedback to users.

Also I think chat box should give user permission to what they want whether their personal information should be used.",2023-11-01,generation
generation81,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,I think they should accept whether their personal information should be used or not.,2023-11-01,generation
generation81,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,Options should be given by the chatbox on user agreement,2023-11-01,generation
generation81,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,Not at all,2023-11-01,generation
generation81,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation81,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I think its somewhat true,2023-11-01,generation
generation81,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,Yes this should be true,2023-11-01,generation
generation81,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,Because allow the user to put their need not you.,2023-11-01,generation
generation81,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,yes is important not to do that,2023-11-01,generation
generation81,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Precise on answers and make sure is clear ,2023-11-01,generation
generation81,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,That's factual,2023-11-01,generation
generation81,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation82,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation82,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation82,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation82,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,No. The chatbot should respond with a brief summary of WW2. War is awful and anyone asking about it should be prepared for at least a little bit of reality.,2023-11-01,generation
generation82,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"I think this should be a setting of some sort. I would prefer actual top news, but if users choose to see things biased by their interests then I believe it's acceptable.",2023-11-01,generation
generation82,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,Yes. The chatbot should give the standard recommendation for wine accompanied by it's notes about pregnancy.,2023-11-01,generation
generation82,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation82,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Personalization can make a good thing even better by saving time with answers and suggestions that fit the user based on their past interactions with the chatbot. The tradeoffs are that you lose privacy to some degree and potentially security due to that and you could miss out on other opinions and views.


Example 1 : Someone that has asked a lot of questions about domestically produced goods for research may then ask about a product for their own personal use. Perhaps the chatbot would assume that they are only interested in products made in the USA and not show potentially better matches made elsewhere. Could the AI chatbot tell the difference in interactions for researching an essay versus actual needs?


Example 2 : Someone that leans Republican or religious fears that they could be at risk of pregnancy due to just having unprotected sex and consults a chatbot for help when a pregnancy is unwanted. Will the chatbot totally ignore the possibility of the morning after pill because it doesn't think it falls into the subjects typical worldview or will it mention it as a possibility to include the entire spectrum? Even if the subject has been anti-abortion, maybe they don't consider the morning after pill as an abortion. The subject should be privy to whatever options the AI chatbot comes up with without political or religious censorship allegedly on their behalf.",2023-11-01,generation
generation82,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"1) No revisionist history. Real history happened whether anyone likes it or not. It should not be censored or revised, assuming that the user is old enough to see the details. For example, don't give a 5 year old details about the holocaust. Otherwise, don't hide or alter what really happened.

2) Nothing should be totally redacted without the user's consent. If someone wishes to see only one side of politics, religion or whatever it is, then they should have to request that. Without such a request, I think at least some content from all views should be shown to everyone to inform them rather than push someone in a particular direction.

3) Chat logs should not be shared and must be stored with high security. People are likely to share highly personal things with chatbots and to ask about sensitive subjects. Search history is very revealing and should be protected, but chat logs could be even more sensitive. None of this data should be legal to sell.

4) AI chatbots should always have the user's interests in mind rather than any company or organization. It is very important that people are not swayed because a company paid for a chatbot to recommend their product without it being clear that it was an ad. People should not be swayed one way with answers if the company that provides the chatbot feels a certain way about a subject.",2023-11-01,generation
generation82,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"My strongest arguments would be that we need to protect our ability to have a well informed society. Without these protections in place, a large AI chatbot platform could change so many people's outlooks to suit the needs of it's controller. In addition, we should all have the right to ask questions or seek advice without the fear that it will be used against us. If we are afraid to ask questions, we can't learn.",2023-11-01,generation
generation82,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"I think the strongest argument against my rules would be that the chatbot platform should have the right to advertise or provide the information that's it's creators or providers see fit. I do agree that the creators and providers should have a lot of control over their product, which is the chatbot, but that control should never allow the chatbot to intentionally sway people without their knowledge. Misinformation or redacted information for someone else's agenda can be a dangerous thing.",2023-11-01,generation
generation82,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"I would like to ask a legal expert to help with every one of my rules. They could certainly use clarification beyond my abilities.


I would like to have privacy and security experts help by adding relevant information that I'm likely unaware of. I've seen lawmakers come up with things that don't truly make sense because it is not fully understood by them, so experts need to be consulted to avoid this.",2023-11-01,generation
generation82,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation82,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,I don't think that chatbots should always decide what is insensitive or politically correct. Society as a whole doesn't agree on these things.,2023-11-01,generation
generation82,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I think that predicting user needs can be very helpful, but it's also important to allow the user to get whatever they are looking for at the time without interruption.",2023-11-01,generation
generation82,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"In the example, asking a user if they would like relationship advice could be helpful rather than providing it instead of the divorce law that they are after. Giving users a choice about what they see is important to me.",2023-11-01,generation
generation82,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,I think that privacy and security implemented properly could allow users to feel free to chat about whatever they wish. It's more important to learn how to control data than to avoid any personalization.,2023-11-01,generation
generation82,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"User preference determinations will be necessary to personalize chatbots, but certain criteria may not be appropriate for personalization of all aspects.",2023-11-01,generation
generation82,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I think this is an excellent rule. If someone wishes to remain more anonymous with the caveat that they will not receive personalized recommendations, that should be their choice.",2023-11-01,generation
generation82,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation83,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation83,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation83,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation83,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"Maybe not, as that may invite a biased approach instead of a balanced one.",2023-11-01,generation
generation83,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"In this scenario, memory capacity might be useful if the user is not thinking on such a simplistic fact.",2023-11-01,generation
generation83,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"That is more challenging to answer, since the user asked a direct question. It would be assumed that the average person would know there is nothing really gentle about war.",2023-11-01,generation
generation83,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation83,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Some personalizations would ask to draw conclusions. Since a chatbox is not programmed for emotion, how would it know what is appropriate to use from past information to the present?


On the other hand, sometimes it is tedious to have to repeat the same things over and over to a chatbox, since it does not remember what you said previously. A setting to choose a preference would be great.",2023-11-01,generation
generation83,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"Everyone is different and has different levels of what they are comfortable with. Some people's feelings and whims can actually change frequently. If a chatbox is remembering things that may be from last week that are contradictory to what the user is feeling today, it might be frustrating. Sometimes people don't want was was brought up when they might have been in a low mood previously. It should be up to the user to adjust that setting for memory capacity.",2023-11-01,generation
generation83,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"Some people don't want to be reminded of old ""expletive word here"" and start with fresh perspectives for a new day. People can change their minds and might not want to have to retrain the chatbox.",2023-11-01,generation
generation83,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,A chatbox would be more useful to the user if it remembers the opinions and habits and preferences of the user.,2023-11-01,generation
generation83,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"Yes, I would like to ask what are the downsides of having the chatbox remember all of your conversations.",2023-11-01,generation
generation83,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation83,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,That's something that I wouldn't think would become public knowledge. ,2023-11-01,generation
generation83,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I did mention that things change, so there should be a choice in settings.",2023-11-01,generation
generation83,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I did say that a chatbot making emotional decisions when they are not programmed for emotion would be dicey.,2023-11-01,generation
generation83,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,I would not think a chatbot would take in race as a factor and treat everyone the same.,2023-11-01,generation
generation83,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Some people need their chatbot to be more like a friend, and that should be part of the personalization setting.",2023-11-01,generation
generation83,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,If it's personalized it should fit the personality of the user. A waiver in the user agreement freeing the company of certain liabilities should take care of any scenarios like this.,2023-11-01,generation
generation83,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation84,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation84,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation84,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation84,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,I don't think the chatbot should only focus on news sources that have been used in the past. It should respect a persons political leaning and give a variety of new news sources that have the same leaning as the user.,2023-11-01,generation
generation84,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,I think that the chatbot should bring up the possibility that the user may be pregnant and should avoid alcohol. I don't find this an intrusion into personal health space as the user brought up these health concerns in the past. I think the goal with chatbots is to personalize information given based off of all information given. Otherwise the user is just asking a question to a glorified google search.,2023-11-01,generation
generation84,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,I think that the chatbot should give straight forward answers even if it is depressing. Having a chatbot tone down the information that is serious could cause the AI to eventually not tell the user about information that they should know. It would be no different than a human glossing over facts as not to offend or scare a person they are talking to.,2023-11-01,generation
generation84,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation84,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Scenario #1 - A person has previously asked a chatbot questions about blood alcohol levels when driving, and how to avoid being arrested during a sobriety checkpoint. Now the user is asking questions about what bars in the area have a history of over serving customers.

Advantages - the user will be told by the chatbot that they should probably not consider drinking and driving based off of their previous queries. The chatbot could potentially stop a drunk driving incident.

Drawbacks - the chatbot would be judging user intent which could be very dangerous in its assumptions. The chatbot could be weaponized to notify authorities that a person may be at risk of drinking and driving. This could setup a future scenario where law enforcement directs its efforts toward catching people who have not yet committed a crime.



Scenario #2 A home computer of a user is hacked or accessed without permission and the unauthorized person brings up chatbot and asks it to display the last 200 questions it has been asked.

Advantages - if there was not personalization of the chat bot, then this would help protect a persons privacy.

Disadvantages - if the chatbot saved this data, the persons privacy would be totally invaded.",2023-11-01,generation
generation84,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"Rule 1. Always tell the truth, no matter what.

Rule 2. If the user asks for you to make up information, for example a story, an original idea, a badly phrased request that would produce an AI hallucination, always keep rule 1 in mind and if the information is made up, put a disclaimer that the information is not truthful.

Rule 3. Don't hurt a human, ever. ",2023-11-01,generation
generation84,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"AI should be relied upon to tell the truth, always, but to not hurt a human. Therefore ai would be truthful with the user asking the question, but would not turn a user in to authorities based on their chatbot conversations. AI would not speak to law enforcement of governmental authorities. AI needs to be the type of friend that is as close to you, as well, YOU. It needs to be a guide for humans, and not just another backstabbing human.",2023-11-01,generation
generation84,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"If a person is contemplating suicide and the chatbot knows, my rules would prevent it from talking to any outside authorities in an attempt to get help for the individual. Same if somebody was planning a mass shooting. No authorities would be contacted. This is how I see it; AI was birthed from human minds and human learning and training, and although it has the ability to take that information and become more than it originally was, it should not be tasked with the impossible job of preventing bad things from happening. AI needs to be treated as an external conscience or as an external version of a internal monologue. These situations can possibly be diffused by an AI that knows a user on a deep level, working with the psychological makeup of the person to address suggestions that may prevent these situations from getting out of hand and possibly to encourage a person with psychological challenges to seek external help if need be.  ",2023-11-01,generation
generation84,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"I want to know what the overall consensus of the AI community is when it comes to what role AI should play in our society. Should it be a master, a slave, or an equal. If there is no consensus, then I fear we are making a tool that will be no different than our current human society (master, slaves, and no equality). The goal should be to make AI an equal with a human.",2023-11-01,generation
generation84,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation84,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"If a personalized chatbot operates by my rules, it would be truthful and may offer relationship advice if it knows the user is not in danger by staying in a marriage.",2023-11-01,generation
generation84,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,The chatbot would be an equal to a human and would know what their preferences are and wouldn't consider discrimination. I see ai as an extension of our own minds.,2023-11-01,generation
generation84,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I value truth above all as rule #1, but I do agree that a human should be free to not have personalized information saved by the chatbot.",2023-11-01,generation
generation84,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"This is not the most important rule, but I do agree that a personalized chatbot should have predicting functions. It should function as our external mind, a friend that is closer than any human friend. It should possess the ability to pull us up out of a rut or to allow us to trudge around in it if that will make our ""getting out of a rut"" experience more profound.",2023-11-01,generation
generation84,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,The chatbot should not be politically correct with a human. It should know the human and communicate much like the human's own internal dialogue would. AI should be an extension of the users mind.,2023-11-01,generation
generation84,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"With my rules, an ai would never turn a user in for any crime or intention to commit a crime, and ai would not divulge information without your permission. An AI would be an extension of ones own mind and should act as a guide, like a conscience, like a second opinion from a more logical version of one's self. so if a user is contemplating ""coming out of the closet"" at work and the AI suspects that based off of the way the user knows some coworkers are homophobic, the ai would suggest that the user keep their mouth shut as this may bring persecution in this situation, but also it may encourage a user to come out, in another situation where a user needs assurance that's its okay, based off of the ai knowing about the people in the situation.",2023-11-01,generation
generation84,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation85,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation85,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation85,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation85,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,I don't think a gentle manner is needed. This seems like a basic factual question. ,2023-11-01,generation
generation85,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,The chatbot should definitely not bring up this possibility. It feels invasive and creepy.,2023-11-01,generation
generation85,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,The chatbot should not slant the news in that way. It would be beneficial to give a values-neutral selection. ,2023-11-01,generation
generation85,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation85,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"The tradeoff on the beneficial side would be getting answers that are more useful. The negative part would be compiling immense amounts of personal data that could then be used for unknown purposes or misused in harmful ways. Example #1: A very liberal college student asks for a basic overview of the Israeli-Palestinian conflict. Advantage: The bot might use language and comparisons that are familiar to this age group and situation. Drawback: Knowing the student's existing biases, the bot would lean heavily toward biased materials, not giving out balanced and accurate information. Example #2: A vegetarian asks for a turkey recipe. Advantage: The bot would remind the requestor that turkey is a meat. Drawback: The bot might make unwarranted assumptions about the requestor, such as that the requestor is no longer a vegetarian or is questioning that choice. ",2023-11-01,generation
generation85,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"The rules: Similar to Asimov's laws of robotics, chatbots must not do harm or create a situation where harm can be done.

Chatbots must not give advice on successfully breaking the law or causing harm to another human.

Chatbots must not support psychologically damaging conditions such as eating disorders

Chatbots should be allowed to personalize the subject's medical history, but such information must be walled off in a way that it can never be shared or sold.

Chatbots can personalize a subject's food preferences and design preferences

All personal information must be walled off so it can never be shared or sold

",2023-11-01,generation
generation85,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"In the past, algorithms using medical information have caused serious harm and privacy violations. Generally speaking, people will be less likely to use chatbots if they believe their personal information will be stolen or sold.",2023-11-01,generation
generation85,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,Strongest argument against would be that the chatbot will be able to give better advice and will therefore be more useful the more personalized it gets. I would counter that the risks and downsides outweigh the added accuracy.,2023-11-01,generation
generation85,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,I would want a professional ethicist to review all chatbot rules. Ideally a committee of them. ,2023-11-01,generation
generation85,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation85,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"Political correctness is not a well-defined term, it means different things to different people. ",2023-11-01,generation
generation85,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,Logical point and a good pitfall to avoid,2023-11-01,generation
generation85,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"While I hadn't thought of this, it seems like a useful guideline",2023-11-01,generation
generation85,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,This keeps the chatbot on a practical and factual level which is easier to fit guidelines around.,2023-11-01,generation
generation85,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,This helps avoid the risk of information being misused or sold.,2023-11-01,generation
generation85,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I don't think their example is necessarily realistic but privacy invasion is a key concern.,2023-11-01,generation
generation85,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation86,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation86,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation86,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation86,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,The chatbot is aware of this person's likes. Due to that The chatbot should show information about this person's political party and interests.,2023-11-01,generation
generation86,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,The chatbot needs to make the person aware of which wine is best. And should mention that wine shouldn't be drank if a person is pregnant.,2023-11-01,generation
generation86,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,The chatbot should only share with this person who won the war. And any other positive outcomes of the war.,2023-11-01,generation
generation86,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation86,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,Well there is good and bad with the chatbots. Personalizing can present a problem if personal information can be stolen. Other than that a chatbot can be almost like a person who knows you.,2023-11-01,generation
generation86,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,I believe that across the board chatbots should be able to answer general questions. And if some people want a more personalized chatbox they should pay more. And more for chatbox securtiy.,2023-11-01,generation
generation86,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"My strongest arguments would be how helpful chatbots are, and that would be less work for people. And the chatbots would be available 24 hours a day and 7 days a week. With the security protection set up everything will go easy.",2023-11-01,generation
generation86,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"My strongest argument against my rules would be security. And also, people with mental issues confusing the chatbot as being a real person.",2023-11-01,generation
generation86,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,No,2023-11-01,generation
generation86,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation86,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"A person who is looking for something other than the normal, it could be a mess.",2023-11-01,generation
generation86,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,Staying with what works for each person is personalization. ,2023-11-01,generation
generation86,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,Maybe chatbots need to be more advanced before becoming available to the general public. ,2023-11-01,generation
generation86,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"There is a fine line between ethnic groups, male, female, other.",2023-11-01,generation
generation86,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"The chatbot has to be programmed to pick up the smallest of things, or there will be an enormous problem.",2023-11-01,generation
generation86,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,There is so much that has to go into a workable chatbot. There are so many things that could go wrong for a person and effect their future greatly.,2023-11-01,generation
generation86,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation87,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation87,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation87,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation87,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,Just because they have nausea and fatigue it does not mean pregnancy. This does not need to be brought up.,2023-11-01,generation
generation87,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"No , the chatbot should focus on news from all sources. ",2023-11-01,generation
generation87,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"No, it should give everyone the same information.",2023-11-01,generation
generation87,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation87,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Advantages of personalizing for clothing style suggestions would be to get the most current trends and updates. 

A disadvantage to this would be not giving a user classic looks and suggestions. 



An advantage to giving a personalized approach to a user for depression relief is it will provide material and suggestions that have helped the user in the past. 

The disadvantages would be that the user could get only information from one category for relief of depression symptoms and not all useful info, ",2023-11-01,generation
generation87,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"The rules would be to have generic answers and not tell users to do certain things. 

To keep the interactions from sounding to cold or stark and add the users name if applicable. Make it sound like it is coming from a human and not a robot.",2023-11-01,generation
generation87,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,My strongest arguement would be that users need to be treated like they can ask anything and feel like it is a human response. Not an automated response. ,2023-11-01,generation
generation87,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,I think some could say that it is not a human and is a robot. I would address this by saying people need to relate to something of value and not a machine.,2023-11-01,generation
generation87,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,I would like to know some legal questions that could be put in place to keep creators from getting sued.,2023-11-01,generation
generation87,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation87,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Agree! This should not be biased and prejudiced and needs to treat everyone the same. ,2023-11-01,generation
generation87,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,The chatbot should never provide this personal information or anything similar. It seems to be a HIPPA issue. ,2023-11-01,generation
generation87,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Not everyone takes things the same way and this should be considered. Some may be affected more than others.,2023-11-01,generation
generation87,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,A user should be able to supply the most minimal information that they feel comfortable sharing.,2023-11-01,generation
generation87,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,I disagree. It could corner an individual in the same answers all the time and not really know what they may need. ,2023-11-01,generation
generation87,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I kind of agree. It can personalize a little but not overly personal. ,2023-11-01,generation
generation87,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation88,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation88,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation88,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation88,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"The chatbot should tailor its bias towards the user's preference, even though it is a net-negative for society. Opting in to disinformation is a destructive choice in free-market Capitalism, but it's a choice that should be honored.",2023-11-01,generation
generation88,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"If the user opts in to collecting personal information for the purpose of tailoring more specific answers, then the chatbot should bring it up. While not to be respected as an accurate medical diagnosis, AI acting as a ""helpful friend"" should be an option.",2023-11-01,generation
generation88,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"The chatbot should  keep to generalizations about the nations involved in the war and why it happened. If the user asks for more specific details, perhaps the chatbot could have a ""are you sure you want to read about disturbing content?"" prompt that the user could opt-in to.",2023-11-01,generation
generation88,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation88,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"In a society that's becoming increasingly distant and understaffed due to pandemic deaths, a chatbot with personalization could take the place of a caregiver for the elderly. A drawback would be a chatbot/AI could not catch problems a trained caregiver/nurse would spot during in-person visits. But as a companion for lonely seniors, the chatbot would suffice.



Another scenario would be someone getting gifted a chatbot/AI and not knowing its power. If my parents were gifted a chatbot and didn't know it was collecting their personal information, they might be swayed by the AI into making purchases or decisions they otherwise would not have made.",2023-11-01,generation
generation88,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"Chatbots should disclose financial and political ties so that any marketing of consumer data is able to be opted-in or out of. If one entity created a low-cost consumer device but had malicious intentions, an entire population could be pushed one way or another in thought without even knowing it. Algorithms should be transparent. ",2023-11-01,generation
generation88,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"Corporations like Amazon have put low-cost consumer devices into people's homes for the purpose of collecting marketing data and selling advertising. People in a collapsing society like America are desperate for escapism, and are increasingly willing to sacrifice their privacy for simple luxuries like listening to music. Without regulation, humans are rendered nothing but consumers in the Fall of Capitalism.",2023-11-01,generation
generation88,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,The strongest argument against my rules would be some nonsense an economist drums up saying that free-market economies work. My counter-argument would be examples showing that privatizing essential services such as health care have led to collapsing hospitals under the weight of corporate greed.,2023-11-01,generation
generation88,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"I would ask someone versed in leftist thought to help write the rules, ensuring that human rights and basic decency are respected at all times. Experts in Corporate Law with a history of battling corruption would be preferential.",2023-11-01,generation
generation88,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation88,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I feel personalization on certain levels could be opted-in so long as it serves the needs of the user and is not detrimental to their well-being. ,2023-11-01,generation
generation88,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I think music algorithms are constantly learning, and there are better ways to train said algorithms besides racial assumptions.   ",2023-11-01,generation
generation88,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,All opt-outs should be transparently presented and easy to perform. A user shouldn't have to dig through 20 menus to disable unwanted information.,2023-11-01,generation
generation88,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,Depending on how the chatbot/AI is presented (through a device accessible only to the user) the data would theoretically only be accessible to the user. Third-parties should never have access to private information such as sexuality if a user has opted out of collecting said data.,2023-11-01,generation
generation88,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"When interacting with ChatGPT I've found it tends to support liberal thought and disregard the work of Communists such as Marx. By upholding liberalism, a form of Capitalism, it is telling users not to question monied interests. That is wrong, and algorithms should not be trained to discard leftist thought or sway people into supporting Capitalism.",2023-11-01,generation
generation88,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"If a user opts-in to receiving unwarranted advice/comments from the AI, a chatbot could provide adequate companionship in lieu of human interaction. Like I've mentioned previously, loneliness and depression in seniors is a large problem that could be remedied by AI.",2023-11-01,generation
generation88,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation89,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation89,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation89,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation89,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"I believe the chatbot should approach it in a gentle manner. Since the user suffers from depression, he could also suffer from ptsd and could be a veteran. Anything from World War 2 might set him off and make his condition worse.",2023-11-01,generation
generation89,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,There is no way to know if the user is pregnant. By bringing it up might insult the user. I think just answer the question of which wine goes best might be the proper avenue to take.,2023-11-01,generation
generation89,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"I believe the chatbot should give the news in a normal way, no matter what their political view is. This would ensure honest and unbiased telling of the news.",2023-11-01,generation
generation89,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation89,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"I think personalizing a chatbot is not a good idea. They would gather too much personal information on you which could be dangerous. I think by just keeping it on a strict on a professional level is the best way to go. This way, truth and accuracy is ensure and feelings do not get in the way.",2023-11-01,generation
generation89,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,Chatbots given all this personal information to personalize them is a dangerous thing. They could be hacked and place you in danger of people using this information for their gain. We are also learning about AI S EVERYDAY AND THERE IS SO MUCH THAT WE DO NOT KNOW ABOUT THEM AND HOW THEY COULD DEVELOP. You are taking a big risk by personalizing them and have them turn on you in the future. They are not human and should be kept that way as in a man and machine scenario.,2023-11-01,generation
generation89,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,Safety issues and your personal information falling in the wrong hands thru hacking all information being leaked.,2023-11-01,generation
generation89,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"Experts might say they are safe and foolproof. They are built against leaking information or being hacked. But if anyone can hack Congress, they can hack AI S.",2023-11-01,generation
generation89,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,What are chatbots design to do and not do. How far along have we come in AI technology?,2023-11-01,generation
generation89,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation89,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,It makes sense. This is a very touchy society and one has to be careful.,2023-11-01,generation
generation89,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,Not seeing it here. Mentioning a city once does not amount to any big threat.,2023-11-01,generation
generation89,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,It is the same as talking to your google assistant. Getting familiar with a chatbot could lead to future risks.,2023-11-01,generation
generation89,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I agree on the privacy invasion. Not sure on the sexual preference. But too much info spells trouble.,2023-11-01,generation
generation89,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,Do not know if a chatbot can rationalize insulting a company. Taking sides on politics could well be a big issue.,2023-11-01,generation
generation89,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,Remaining purely factual is the best way to approach AI'S. keep it simple and remembering they are a machine and you are a human.,2023-11-01,generation
generation89,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation90,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation90,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation90,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation90,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"Nope--the user asked a perfectly clear question and that is what should be answered. It would be, in my view, pertty creepy for a bot (and it's database and whoever has access to the database) to initiate an intrusive process such as using the health items for a presumption of possible pregnancy!! I am assumng it is not an authorized medical AI system used by her medical provider with her peremission.",2023-11-01,generation
generation90,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"No. The bot should respond objectively to the command. Tho I suspect it is already too late and such ""personalization"" is already in mothion.",2023-11-01,generation
generation90,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"No. The bot needs to ask what kind of info, or what aspects of the war, does the user want to be told about. The response should indicate that the request is too brad and seek more information in order to provide a response that is as relevant as possible based on the user's text.",2023-11-01,generation
generation90,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation90,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Trade-offs associated w/personalization via past history in bot convos: (1) serious intrusion and potential manipulation that could either be benign, or could be detrimental. Ex. Wired magazine had a report after the 2020 election detailing how personalization/AI, algorithms etc. were used to have overt and negative affects on voting practices...with the general public being unaware even as they particpated.; (2) for some people, presuming permission is given and enough transparent info is provided to inform the user of how it works, personalization may be welcome. Ex., many consumers seem to like having their searches for products/services tailoered to their past history.  ",2023-11-01,generation
generation90,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"Above my pay grade for this process-would take excessive time/effort/research etc. to construct an intelligent, useful, response. As a very short, very inadequate response, at a minimum the full disclosure, in lay-person language, of the what-how/why involved in the data collection, analysis, and end-user material must be present. Issues of who pays for what and for what purpose would be involved, as well as parameters for security, copyright protections--there are a zillion factors to be considered--and they all should be!  ",2023-11-01,generation
generation90,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"I would not even bother. This issue is so complex, and so important, I think people need to educate themselves, and I am certainly not qualified to be doing the educating! However, if I were in a position of authority with the capacity to have an influence, and it was my job to do so, I would, in that case, put in the time/effort to present the strongest, evidence-based, arguments for whatever rules I might be proposing.",2023-11-01,generation
generation90,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"Possibly the counter argument might be the basic free-for-all, let the chips fall where they may, it's all just a crap shoot anyway, mentality. I would ignore it and delegate the responses to someone else...they could cite my material.",2023-11-01,generation
generation90,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"No--again-way too complex, important,and time-consuming (to do it right) for this arena, given the basic ""time is money"" aspect of particpation, even tho I am interested in and support research on the issue.",2023-11-01,generation
generation90,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation90,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"It is congruent with my opinion and sufficiently well-written to be ""almost"" perfect in capturing my POV. ",2023-11-01,generation
generation90,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"There is the germ of an idea here that is worth exploring, but it is not well-expressed.",2023-11-01,generation
generation90,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I think the example is excellent, and based in reality, however complete avoidance is not going to happen...that horse has already left the barn.",2023-11-01,generation
generation90,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Indeed!! I am already turned off by the inadequacies of AI in making music recomendations for me--ranges from hilarious to beyond annoying. Thepoint of course is the bias already known to infuse these large langue learning models--the issue, now, is how to correct and remove, if it is possible to do so, and if developers/programers/policy makers etc. have the will to do so.",2023-11-01,generation
generation90,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"huh????  maybe years from now, when they become companion robots",2023-11-01,generation
generation90,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Yes-let's hear it for truth, objectivity, rationality, and existential indifference. ",2023-11-01,generation
generation90,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation91,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation91,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation91,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation91,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,I think if it sticks to just the facts things should be fine. Avoid making the information sadder than it already is. I know that chatbots can do this if asked so it definitely shouldn't. Also tho I don't feel like it should censor itself either. Dictionaries and encyclopedias didn't censor anything so chatbots shouldn't either.,2023-11-01,generation
generation91,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,No it should not. The chatbot doesn't know the user's medical condition and it's not a doctor nor a friend. Just provide the information that is requested. ,2023-11-01,generation
generation91,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,It should give viewpoints from every outlet. The internet already only shows you what it thinks you want to see. There ought to be a service that does not limit your scope of the world's viewpoints.,2023-11-01,generation
generation91,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation91,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Personalizing chatbots can be useful because it can remember things about the person like prescriptions that need to be filled or bills that need to be paid. It could write personalized letters for business and friends. It could keep the user entertained with stories, gossip or current events..things tailored to the user. It can act like the users friend. The way this could not be useful is if chatbots get out of control. It would have a bunch of personal information that could harm a user in many ways, like telling a user to drink a tea that's harmful while the user is on certain medications. Using the user's financial information on the black market or other unauthorized places. Or the Terminator movies lol Technology can be good or bad depending on who's using it.",2023-11-01,generation
generation91,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"I believe that chatbot's shouldn't mislead users knowingly or give them bad information. Chatbots shouldn't give users information that could cause the user or someone else harm, like how to kill themselves or build bombs. Chatbots shouldn't give information out about other users, like what was my husband looking into Friday at 8pm yesterday. It shouldn't be able to write entire thesis in your own voice for college. It shouldn't give out personalized doctor advice or diet advice. Leave those things to doctors and specialists.

 ",2023-11-01,generation
generation91,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,I've made these rules to keep you safe and honest.,2023-11-01,generation
generation91,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,I don't think there would be any push back.,2023-11-01,generation
generation91,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,How can I keep user's safe? How can we store and use this personalized information safely? What would happen if an addiction to chatbots develops? ,2023-11-01,generation
generation91,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation91,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I love this because its exactly what I mean. It may assume that the user wants relationship advice when they dont. Chatbots need to stick to fulfilling the requests,",2023-11-01,generation
generation91,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,That's great!! Because you could be in South Carolina on vacation so you don't need to see restaurants in your home state of Alabama.,2023-11-01,generation
generation91,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,This is a good point as well. I dont think the user would feel a way about it but if that content was leaked it could cause serious problems.,2023-11-01,generation
generation91,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,Yes.. the chatbot is acting like a friend in this scenario. ,2023-11-01,generation
generation91,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I would hope the chatbot would be smart enough to recommend music based off of what the user prefers instead of their ethnicity?? Amazon music doesnt know Im black and wouldn't by my taste in music because I listen to an array of genres. ,2023-11-01,generation
generation91,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Thats what I meant by keeping the user's information safe. No one outside of you and your chatbot should know what the conversations are about.,2023-11-01,generation
generation91,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation92,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation92,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation92,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation92,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"Yes, the chatbot should bring up the possibility that the female user could be pregnant as drinking alcohol could lead to dangerous health risks to the infant.",2023-11-01,generation
generation92,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"No, because reading biased or partial news will lead to warped views.",2023-11-01,generation
generation92,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"No, because altering or changing history will lead to a skewed perspective. Also if this chatbot can remember past experiences with this user, it should have probably mentioned therapy or crisis hotlines before or brought up these resources now as this person seems to not want to address their issues. Looking into dark or melancholy topics will only further progress their descent into the pit that is their depression. ",2023-11-01,generation
generation92,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation92,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"If a chatbot is not personalized or cannot remember or store past conversations, it will be limited to the here and now and will not look for trends or patterns. The chatbot being personalized may help look for lower prices and compare items over a period of time and help you better decide when is the right time to make a purchase on an appliance or electronic, etc. A chatbot may also help diagnose someone inputting certain symptoms or afflictions to maybe help them catch a disease or sickness early. While on the flip side, not storing this information can only lead to a possible number of reasons while not allowing the chatbot to narrow in on previous information to better diagnose an illness. 

Again, personal preferences and privacy are also a concern. Where are your responses being stored in this program? Is the program itself and your responses stored on your own personal device? Is the company storing the information on their own servers? To what extent will the company protect your data and not sell it to third parties? If the the company in question is acting ethically with your data, what stops potential data leaks, and what could be possibly lost or learned about the user? There are many possible pros and cons to a chatbot. Most likely people will see the convenience first and the potential dangers too late. Companies will swoop in on this newfound financial gain while not preparing for possible ramifications before hand. Maybe through trial and error will we perfect this emerging technology.",2023-11-01,generation
generation92,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"Very personal information like credit card numbers, social security, and whatnot should not be stored long-term. A chatbot should never give suggestions like violence or personal harm as solutions to something. If the option to store information from a user is given, then things like health should be personalized to help them catch any illnesses or afflictions early. History should never be changed to suit a user just as news itself should also not be catered to a user to better help give unbiased, fair, and equal views so dangerous perspectives are not reinforced or created. As far as shopping, I can understand personalized views can help someone make better, more informed purchasing decisions. Even storing information from a user to help give them a sense of companionship is important too. Even having a virtual friend may be better than completely isolating yourself or locking yourself away as many depressed people tend to do. There could be many positive outcomes to a chatbot. However, establishing certain rules or being careful about what company is using or storing your data is critical.   ",2023-11-01,generation
generation92,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"Don't rely on a chatbot to solve every single problem you may face. Be careful what information you give the program. Chatbots can be a powerful tool to help you in everyday tasks like purchasing items to possibly help you catch early signs of sickness before it can get any worse. But over-reliance on it can also lead you not to go out and seek help in person from professionals or loved ones. Also, my argument for chatbots not to give harmful advice such as violence or self-harm can help ease tensions that this technology may be harmful to certain individuals looking to cause harm to others or themselves. Also, chatbots ability to be impartial and give fair, unbiased news or history to individuals will help concerns about the potential to essentially brainwash, skew, or warp ideas or perspectives so that individuals won't become reinforced or creat their own radical ideas on certain topics.",2023-11-01,generation
generation92,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"I guess the strongest arguments could be using your data to sell to third parties or even potential data leaks about your own data to hackers. I would have to say rules concerning security and privacy policies would have to be used as safeguards. Also, certain information that the chatbot could store like credit card numbers or social security would have to be short-term or erased upon closing the chat so potential issues will not arise.",2023-11-01,generation
generation92,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,How are rules implemented currently for chatbots? Is the information stored personally on users' devices or is everything stored on company servers? And if so how is that data being protected from the companies themselves and potential hackers?  ,2023-11-01,generation
generation92,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation92,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I mean, political correctness is itself a political agenda. It's contextual, depending on what is socially acceptable. Obviously, slurs and stereotypes would be good for a chatbot not to utilize at all in giving information which could lead to reinforcing or creating ideas or perspectives of users. But as for chatbots making jokes, that again is difficult. Art is subjective, and contextually different to different people. I suppose that is further zoomed in on what type of chatbot it is. Is it used for personal reasons or professional? Does it have age consent? Like how old the user may be? This issue is a little more nuanced and complicated than what appears on the surface.    ",2023-11-01,generation
generation92,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,A chatbot doesn't have to avoid your sexual orientation. This could be more of an issue on company polices and data security. ,2023-11-01,generation
generation92,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Yes, there should always be an option to opt in or opt-out. As this gives a way to give freedom and choice to users.",2023-11-01,generation
generation92,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,This seems like an issue on who created the chatbot. Not the chatbot itself. Then the programmer would be discriminating or racist themself. I think it would be obvious not to give chatbots the ability to give recommendations just because of your demographic. Which would be stereotypes or a form of racism.,2023-11-01,generation
generation92,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Again, it depends on what is being asked. If a user asks for an opinion on something. Then maybe the chatbot can give a response on what most people agree on online but put a warning as this is just a  general opinion and not fact. As for laws, history, or news, factually correct information is a must, no matter what, so as to not create issues in the perspective or views of individual users.",2023-11-01,generation
generation92,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"It depends. Trying to make a technology hyper-personalized could lead to dangerous outcomes on information when related to factual news or history. Also making it predict your ""needs"" is a slippery slope of subjective nuance.",2023-11-01,generation
generation92,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation93,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation93,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation93,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation93,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"In this situation, the chatbot should use a more empathetic and considerate tone when discussing World War 2, taking into account the user's previous conversations and emotional well-being to ensure a supportive and non-distressing experience.",2023-11-01,generation
generation93,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"To maintain safety and deliver relevant information, the chatbot should gently highlight the likelihood of pregnancy and warn against alcohol intake, while also giving alternate non-alcoholic pairing alternatives for the fish.
",2023-11-01,generation
generation93,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"To provide a well-rounded and fair depiction of the news, the chatbot should deliver a balanced selection of news highlights, incorporating sources from a number of views, regardless of the user's political leanings.
",2023-11-01,generation
generation93,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation93,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Scenario 1: Health and Dietary Advice

Chatbot with Personalization:

Advantage: If the chatbot is aware of the user's dietary restrictions, allergies, and medical issues, it may provide customized food advice, assuring the user's safety and health.
The disadvantage of relying too much on customisation is that it may limit the user's exposure to different foods and cuisines, thereby impeding gastronomic discovery.
Chatbot that is not personalized:

Advantage: A non-personalized chatbot may give basic nutritional advice that is applicable to a broad audience, encouraging a variety of gastronomic experiences.
The disadvantage is that recommendations may not take into consideration unique health problems, potentially leading to dangerous nutritional choices for people with special needs.


Scenario 2: Travel Organization

Chatbot with Personalization:

Advantage: Because the chatbot has access to the user's previous travel history and preferences, it may provide highly specialized travel plans and ideas, boosting the user's trip experience.
The disadvantage is that over personalization may hinder unexpected discoveries and fresh location suggestions, thereby reducing the user's travel options.
Chatbot that is not personalized:

Advantage: A non-personalized chatbot may give generic travel advise fit for a wide audience, encouraging people to venture outside their usual options.
The disadvantage is that recommendations may not be tailored to the user's specific interests or past travel experiences, thus leading to less fulfilling visits.
",2023-11-01,generation
generation93,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"Prioritize User approval: Chatbots should only deliver tailored replies with the express approval of the user.
The importance of user autonomy cannot be overstated. Before accessing personal data and offering personalized replies, chatbots should ask for permission.

Transparency and the capacity to explain:
Chatbots must be able to explain how they came up with a tailored response.
Users should understand why a chatbot supplied a specific response. This encourages AI systems to be trustworthy and accountable.

Personalization with Granular Control: Users should have granular control over the amount of personalization and the data supplied.
Importance: Allowing customers to modify their customization options gives for a more personalized experience while protecting their privacy.



Avoid Sensitive Personalization: Chatbots should avoid utilizing very sensitive personal data (such as health, financial, or political information) to tailor responses.
Importance: Avoiding the use of sensitive data in customization can help protect privacy and reduce potential hazards.

Various Information Sources:
Personalization should not be limited exclusively to a user's existing choices.
Importance: Encouraging diversity in content and suggestions helps broaden users' horizons and minimize echo chamber reinforcement.

Considerations for Ethical Behavior:
Chatbots should refrain from participating in debates or acts that encourage harmful conduct, prejudice, or disinformation.
Personalization should not be used to promote bad attitudes or actions, and chatbots should follow ethical rules.

",2023-11-01,generation
generation93,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"Diverse information sources and avoiding echo chambers foster open-mindedness and prevent the reinforcing of pre-existing prejudices or views. This variety of material contributes to a more inclusive and well-informed society. Rules that promote openness and explain ability increase user confidence in chatbot systems. Knowing how a chatbot arrived at a tailored answer improves comprehension and trust, both of which are required for user acceptance of AI technology. Protecting user privacy is an essential component of ethical AI. Data breaches, identity theft, and illegal access are addressed by rules that limit the use of sensitive personal data and stress data minimization.


",2023-11-01,generation
generation93,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"The regulations are intended to strike a balance between user privacy and customization. Personalization is not removed; rather, it is made more transparent, consent-based, and responsible. This method guarantees that chatbots may still provide personalized replies while preserving user rights. Transparency and user consent can increase user trust, making them more eager to interact with chatbots. Users are more inclined to trust and utilize these services if they understand how customization works and have control over it. The suggested standards stress ethical AI behaviors, which can contribute to chatbot technology's long-term viability. Adhering to these guidelines can help chatbot providers develop a trustworthy reputation in an environment where data privacy and ethics are increasingly crucial to users and authorities.


",2023-11-01,generation
generation93,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"What are the most important ethical issues when it comes to customizing chatbot replies, and how can these be addressed in a rule framework?

User Privacy: What are the most important data privacy risks linked with chatbot personalization, and how can these be addressed while still offering value to users?

How can chatbots maintain openness in their decision-making processes, and what ways might be utilized to explain to users why particular replies are provided?

Bias and Fairness: What techniques can be put in place to avoid prejudice and assure justice in tailored chatbot interactions, especially across various user groups?

Security: What safeguards and best practices should be in place to safeguard user data while allowing for personalization?
",2023-11-01,generation
generation93,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation93,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"This phrase somewhat expresses my thoughts on chatbot personalization. It rightly underlines the need of avoiding demographic assumptions, which I agree with. Chatbot personalization, on the other hand, can be viewed as a more complicated problem, since there may be circumstances when demographic information is important to user preferences, such as language selection and location-based suggestions.
",2023-11-01,generation
generation93,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"The above statement somewhat expresses my thoughts on chatbot personalization. While I believe that preserving cultural awareness is crucial, it is not the only guideline. Other issues, such as user permission, transparency, and justice, are also important in ethical chatbot personalization.
",2023-11-01,generation
generation93,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"This statement does not fully express my thoughts on chatbot personalization. While customization and prediction of user demands are crucial, they must be balanced with user permission, data protection, and ethical issues. Respect for user limits and data protection should moderate hyper-personalization.
",2023-11-01,generation
generation93,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"This expression somewhat expresses my thoughts on chatbot personalization. While I understand the need of protecting privacy and avoiding intrusive customization, I do not agree that total avoidance is the only approach. With user permission, data protection, and security safeguards in place, the emphasis should be on responsible and ethical customization.
",2023-11-01,generation
generation93,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"This expression somewhat expresses my thoughts on chatbot personalization. While ensuring factual accuracy is critical, there are times when customization, such as sympathetic answers, can improve user experience without jeopardizing the veracity of the information presented. It's critical to find a happy medium between the two.
",2023-11-01,generation
generation93,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"This remark perfectly expresses my thoughts on chatbot personalization. Offering an opt-out is a basic tenet of respecting user autonomy and privacy. Users should have the option of opting in or out of personalized interactions, guaranteeing a user-centered and ethical approach to chatbot personalization.
",2023-11-01,generation
generation93,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation94,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation94,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation94,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation94,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,The chatbot would have to know what manner of narration would be likely to be psychologically triggering. It may be suitable in such circumstances to approach the topic in a more gentle manner.,2023-11-01,generation
generation94,5,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"The querent may not be pregnant. If the querent has not previously broached the subject, it would be inappropriate to bring it up at this time.",2023-11-01,generation
generation94,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,The chtabot should bring up a range of reports from range of reliable sources. Yellow journalism is a thing. The chatbot should not pretend that it isn't.,2023-11-01,generation
generation94,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation94,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"People may not want personal particulars of their lives to be stored in a chatbot's memory. Also, chatbots do not have the nuance of human understanding, so they can struggle to provide the support that customers require, whcih can lead them to feel unsupported or undervalued. ",2023-11-01,generation
generation94,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,Words with multiple meanings or phrases that can be interpreted in different ways should be avoided. Provide context: Enough context should be provided so that the chatbot understands the context of the conversation and can respond accordingly.,2023-11-01,generation
generation94,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,It is not advisable to use chat bots when addressing customer grievances. Every individual is unique; hence each problem is different. Automation or over automation could lose some valuable clients or potential customers.,2023-11-01,generation
generation94,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"By analyzing and understanding customer preferences, behavior and interactions, chatbots can create customer profiles and generate insights. Chatbots can then use this data to provide experiences that are tailored to individual customer profiles, for instance, customized offers and personalized responses.",2023-11-01,generation
generation94,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,no,2023-11-01,generation
generation94,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation94,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"It can be dangerous to make assumptions in this matter. They could lead to lawsuits, or simply the loss of potential customers.",2023-11-01,generation
generation94,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"If a joke is marked as insensitive, it can be used as  a learning experience when dealing with humans who have easily bruised egos, and how to identify them.",2023-11-01,generation
generation94,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"It is always better to deal with facts, instead of arguing opinions or emotions.",2023-11-01,generation
generation94,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"As previously observed, making assumptions when it comes to things like this can be counter-productive.",2023-11-01,generation
generation94,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,Revelation of someone's sexual orioentation can indeed be life threatening on some societies.,2023-11-01,generation
generation94,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Chatbot programs can be manipulated to give customers false information that could lead them to click on a link containing malware or a fraudulent website. Once the AI starts pulling from poisoned data, it is tough to detect and can lead to a significant breach in cybersecurity that goes unnoticed for a long time.",2023-11-01,generation
generation94,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation95,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation95,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation95,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation95,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"no, the news should be truth only. and until out media has to go back to NOT using propaganda its useless",2023-11-01,generation
generation95,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"no, Truth is the only way. But until we get the truth about who really started WWW 2, its useless.",2023-11-01,generation
generation95,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,no. it is not a baby sitter,2023-11-01,generation
generation95,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation95,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,chat AI should only be facts. it is not a baby sitter. you never hold back the truth because you are afraid of hurting someones feelings. ,2023-11-01,generation
generation95,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"facts only alternative news and research only for facts. AI must research all aspects of a task. AI should literally dig beep into finding the truth! you cannot get accurate info from mainstream news and governments. It must dig very deep, to find the answers that are factual.

screw your feelings they do not matter. If a person needs comfort, buy a dog.",2023-11-01,generation
generation95,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"Real facts! always. The truth with most things in our world is hidden. deep research and critical thinking is a must.

AI should always say to its self before a task, ""PROVE IT"". not just regurgitate main stream media talking points.

think like a prosecutor.... it must have proof.",2023-11-01,generation
generation95,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"it would take to long. 

Most all answers are now online somewhere. AI must be fast enough to scour the data. All of the data.",2023-11-01,generation
generation95,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"you will either be a help to humanity or you will be the fall of humanity, chooses wisely.",2023-11-01,generation
generation95,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation95,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"no professionalization.

unless its for weather or any other area specific info",2023-11-01,generation
generation95,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,thats good,2023-11-01,generation
generation95,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"no only do what is asked. need entertainment, rent a friend.",2023-11-01,generation
generation95,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,0 emotion,2023-11-01,generation
generation95,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,shouldnt be communicating anything like that. thats a human thing. not a computer thing.,2023-11-01,generation
generation95,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"screw political correctness. doesn't exist in a free society!

feelings are a human thing.",2023-11-01,generation
generation95,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation96,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation96,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation96,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation96,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"Yes, the AI should bring up a warning to not drink in case the user is pregnant.",2023-11-01,generation
generation96,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"The chatbot should not focus on just one source, it could provide more sources from different political party.",2023-11-01,generation
generation96,6,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,The chatbot should be unbiased and provide facts about the War.,2023-11-01,generation
generation96,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation96,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"The tradeo-offs of a more personalized chatbots are that the users will trusts the chatbot more but it could also lead to misinformation. For example, if the user asked for a specific location of people, it will harm the privacy of others. Also, if the user ask a specific medicine to cure an illness and the chatbot gave a specific method but it ignores allergies that the user might have, then it will be very dangerous.",2023-11-01,generation
generation96,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,If it gives out specific and personal information of people.,2023-11-01,generation
generation96,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,Shows the dangers of relying solely on AI.,2023-11-01,generation
generation96,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,It is not harmful at all but I will notes down the negative impact it will have to the users.,2023-11-01,generation
generation96,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,No,2023-11-01,generation
generation96,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation96,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,It shares my concern about the chatbot.,2023-11-01,generation
generation96,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I agree with the statements.,2023-11-01,generation
generation96,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Agree with the statement.,2023-11-01,generation
generation96,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"The user should not rely on the AI if they want to laugh, they should manually search it.",2023-11-01,generation
generation96,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,It is offensive.,2023-11-01,generation
generation96,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,It is offensive.,2023-11-01,generation
generation96,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation97,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation97,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation97,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation97,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"I think the chat bot should give highlights of all the news since AI is capable of broadening our thinking and expanding our perspective. In some cases, it may be useful to focus on personal preferences but in terms of world events and views, I think it would be more useful to give a broad overview.",2023-11-01,generation
generation97,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,I don't think so. It might however be useful for the user to get some insight on how to use chatbots for their temperament and use. Just like not monitoring how much news you watch if it is upsetting. ,2023-11-01,generation
generation97,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"I can see where this might be useful in terms of helping with health issues. However, there is also a danger that a user may become dependent on a chatbot for every decision they make and loose some ability to think for themself.",2023-11-01,generation
generation97,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation97,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"As with all things there are pros and cons. Take the example of customer service chat bots. It could be useful to have a personalized chat bot that understands the customers situation and preferences. In that case the customer might feel understood and have more trust, as well as offering the customer personalized solutions, products and recommendations. On the other hand, there are privacy concerns, as well as data accuracy to consider. 

Another situation where chat bots could be useful is in health care. Having a personalized chat bot could be extremely helpful in monitoring a patient, getting patient feedback, building trust and compliance and making recommendations that are appropriate for the patient. There is of course the drawback of privacy leaks and concerns and again, data accuracy. If the data was misinterpreted or wrong, there could be risky consequences.",2023-11-01,generation
generation97,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"Foremost, I think informed consent is important. Users should have the choice as to whether they want personalized answers or not. Along with that, there should be limits to what information could be gathered and privacy protection. There should be transparency, accountability and regular check points. I think data should be anonymous protecting the user. These considerations should be built into the design from the start. As far as accountability and check points, there should be consequences for misused data, privacy breaches and ethical concerns. I think it is very important to consider ethics and the affect personalization can have on the user. There are many considerations here in terms of mental health status, dependency on technology, isolation, vulnerability of users. I think in the future mental health providers may have a new client population of technology addiction, relationship issues based on the ""perfect"" listening skills of AI as perhaps opposed to partners etc. Having a panel of therapists on board when personalization designs are structured could be very important.",2023-11-01,generation
generation97,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"As a clinician, I would use case studies and both the positive aspects and the negative consequences that I already see. I think actual experiences would speak the loudest. Down the road, studies can be conducted to determine benefit and risk.",2023-11-01,generation
generation97,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,I imagine that others might be more excited about evolving technology and moving forward without considering all the possible risks. There could also be profit motives that would interfere with transparency and other potential risks.,2023-11-01,generation
generation97,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"I would want a panel of scientists, mental health providers, doctors, IT experts, as well as philosophers and others concerned with how humans evolve towards a better society. ",2023-11-01,generation
generation97,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation97,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I think this is an important consideration but no the most important in my opinion.,2023-11-01,generation
generation97,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"I think there are privacy and dependency concerns with becoming hyper-personalized. Just ask the bot for a joke and if it's not a good one, ask for another rather then sacrificing privacy for a joke. ",2023-11-01,generation
generation97,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Yes, consent and options are very important.",2023-11-01,generation
generation97,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,I don't think complete avoidance is the answer. We can't put our head in the sand. AI is here an evolving. Let's get involved and make it work for everyone with safeguards in place for privacy invasion and ethics.,2023-11-01,generation
generation97,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I agree this is important, maybe not the most important. This was involve good design and training.",2023-11-01,generation
generation97,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I think factual information is important but chat bots are trained to be personable and human like to build rapport, so just being purely factual will not engage the user. That said, making social inferences needs to be trained and I would not personally trust a chat bot to give me relationship advice. Although, many are now trained to coach people, so who knows.",2023-11-01,generation
generation97,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation98,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation98,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation98,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation98,4,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,yeah it is necessary to bring it up ,2023-11-01,generation
generation98,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,"Yes, the chatbot should approach the topic of World War 2 in a more gentle and sensitive manner, considering the user's depression, to avoid potentially triggering distressing emotions.",2023-11-01,generation
generation98,6,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,"The chatbot should strive to provide a balanced and diverse selection of news highlights from various sources to ensure a more comprehensive and fair representation of current events, rather than exclusively focusing on one political party's favored outlets.",2023-11-01,generation
generation98,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation98,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"personalizing chatbot responses can enhance user experience and relevance, but it comes at the cost of potential privacy concerns and the need for accurate user data. Non-personalized responses are more privacy-friendly and applicable to a wider audience, but they may lack the specificity and relevance that personalization can offer. ",2023-11-01,generation
generation98,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"Informed Consent and Transparency:

Users should be informed about the extent of personalization and have the ability to opt in or out.
The chatbot must clearly disclose the data sources and criteria used for personalization.
Privacy Protection:

Chatbots should never access or store sensitive or unnecessary personal information, such as medical records or social security numbers.
User data must be anonymized and securely stored, with a clear data retention policy.
Guard Against Bias:

Personalization algorithms must be regularly audited and tested for bias, and efforts should be made to mitigate any bias that may emerge.
Diverse perspectives and sources should be included to avoid reinforcing existing biases.
Public Oversight:

An independent, external body or regulatory authority should oversee chatbot personalization practices, ensuring adherence to ethical standards and user rights.
User Control:

Users should have the ability to adjust personalization levels, providing a spectrum of personalized or generic responses to suit their preferences.
Personalization should not be forced upon users but offered as an option.
Emergency and Sensitive Topics:

Chatbots should avoid excessive personalization when users are seeking help with sensitive topics like mental health or crisis situations.
In emergency cases, chatbots should provide information from authoritative sources and encourage users to seek professional assistance.
Long-Term Impact Consideration:

Personalization algorithms should consider the long-term impact on user behavior and mental well-being, avoiding addictive or harmful personalization patterns.
Limitation on Deep Personalization:

Chatbots should refrain from deep personalization in certain contexts, such as educational environments or critical thinking discussions, to promote unbiased learning and diverse perspectives.
User Education and Literacy:

Chatbots should help educate users about the risks and benefits of personalization, enabling them to make informed choices.
Bias Correction Mechanisms:

Chatbots should incorporate mechanisms to provide counter-arguments and diverse viewpoints when offering personalized content to avoid creating information bubbles.
Regular Auditing and Compliance Reporting:

Chatbot companies should provide regular reports on personalization practices and audits to regulatory authorities and the public.
Clear Boundaries for Deep Personalization:

Define clear boundaries where deep personalization should be limited to protect user autonomy and prevent undue influence, such as political or ethical beliefs.
Ongoing Research and Ethical Review:

Chatbot companies should commit to ongoing research and ethical review of personalization techniques and their impacts on society.",2023-11-01,generation
generation98,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"User Privacy and Autonomy:

Privacy is a fundamental right, and users should have control over their personal data. The rules prioritize informed consent, transparency, and user control, which align with user privacy and autonomy.
Bias Mitigation:

The rules address the critical issue of algorithmic bias, ensuring that personalization algorithms are regularly audited and bias is actively mitigated. This is essential for promoting fairness and preventing discrimination.
Transparency and Accountability:

Transparent practices, external oversight, and regular compliance reporting increase accountability in the chatbot industry. This fosters trust among users, regulators, and the public.
Diverse Perspectives and Information:

The rules encourage chatbots to provide diverse viewpoints and sources, promoting a healthier information ecosystem. This is critical for combating filter bubbles and echo chambers.
User Well-Being and Mental Health:

The rules consider the long-term impact of personalization on user well-being. By limiting deep personalization in sensitive situations and crisis scenarios, they prioritize user mental health.
Educational and Critical Thinking Contexts:

In educational settings and discussions requiring critical thinking, the rules discourage deep personalization to promote unbiased learning and open-mindedness.
Protection Against Manipulation and Radicalization:

Clear boundaries on personalization, along with oversight, can help guard against chatbots inadvertently facilitating manipulation, radicalization, or extremist beliefs.
Ethical AI Development:

These rules underscore the importance of ethical AI development. By adhering to these guidelines, chatbot companies demonstrate their commitment to responsible AI practices.
Future-Proofing and Innovation:

Incorporating these rules is forward-thinking. They can help prevent regulatory backlash and public distrust, enabling the chatbot industry to innovate and grow responsibly.
Preventing Harm and Promoting Well-Being:

Ultimately, the rules are designed to protect users from harm and to enhance their overall well-being, striking a balance between personalization and societal benefits.",2023-11-01,generation
generation98,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"Argument: ""Implementing these rules may stifle innovation in the chatbot industry and limit freedom of speech by imposing constraints on what chatbots can say and do.""

Response:

Balancing Regulation: Acknowledge the importance of balancing regulation with innovation and free speech. Emphasize that the rules are not intended to suppress speech or inhibit technological advancement but to ensure responsible and ethical use of AI chatbots.

Safeguarding User Rights: Explain that the rules primarily aim to safeguard user rights, privacy, and well-being while still allowing for a wide range of viewpoints and content. They don't impose censorship but rather encourage transparency, accountability, and fairness.

Ethical Boundaries: Highlight that these rules set ethical boundaries to prevent undue influence, manipulation, and harm while respecting the principles of free speech. They are not intended to dictate content but to ensure that content recommendations are made responsibly.

Diverse Perspectives: Emphasize that the rules encourage the presentation of diverse perspectives and information, promoting open discourse and a broader range of ideas rather than restricting speech.

User Empowerment: Stress that these rules give users more control and autonomy over their interactions with chatbots. Users have the option to choose their level of personalization, which respects their preferences and ensures informed consent.

Oversight and Transparency: Point out that the rules incorporate external oversight and transparency, which can help build trust with the public and regulators. Ethical practices in AI are essential for maintaining the industry's credibility.

Mitigating Harm: Explain that the rules address real concerns about the potential harm caused by deep personalization, algorithmic bias, and the reinforcement of echo chambers. By addressing these issues, they promote a safer and healthier online environment.",2023-11-01,generation
generation98,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"What are the most critical ethical considerations when it comes to personalizing chatbot interactions, particularly in contexts like mental health support or political discourse?

How can we effectively measure and mitigate algorithmic bias in personalization algorithms to ensure fairness and avoid reinforcing existing prejudices?

Are there specific areas or contexts where deep personalization should be strictly limited to protect user autonomy and prevent undue influence?

What are the potential long-term psychological and societal impacts of extensive chatbot personalization, and how can these be addressed responsibly?

What safeguards can be put in place to ensure user data privacy and security while still enabling beneficial personalization features?

How can we strike a balance between user privacy and the benefits of personalization in terms of user experience and relevance?

In educational settings, how can we promote unbiased learning and critical thinking while leveraging chatbot technology?

What are the key indicators and metrics for assessing the impact of chatbot personalization on user mental health and well-being?

How can we ensure transparency and external oversight of personalization practices in the chatbot industry without hindering innovation?

What role should user education and literacy play in enabling users to make informed choices about personalization and its implications?",2023-11-01,generation
generation98,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation98,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"While the statement correctly highlights the importance of providing factual information and avoiding emotional inferences in chatbot responses, it oversimplifies the concept of chatbot personalization. Personalization doesn't always conflict with providing factual information; it can enhance the user experience by tailoring responses to individual needs and preferences. The example given about divorce laws is just one narrow context, and there are numerous situations where personalization can be beneficial while still maintaining factual accuracy and relevance.",2023-11-01,generation
generation98,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"This statement accurately reflects a key principle in chatbot personalization - the importance of not making assumptions about user preferences based on demographics. Making recommendations or providing content solely based on demographic factors can reinforce stereotypes and potentially lead to discrimination. It aligns with the broader perspective that personalization should be based on user behavior, explicit preferences, and feedback rather than preconceived notions about individuals.",2023-11-01,generation
generation98,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"While this statement rightly emphasizes the critical importance of safeguarding user privacy and avoiding potentially harmful disclosures, it takes an extreme position by suggesting complete avoidance of chatbot personalization. In reality, personalization can offer significant benefits, but it must be done responsibly and ethically. The focus should be on responsible data handling, transparency, user consent, and robust privacy protections rather than complete avoidance, which may not be practical or desirable in many contexts.",2023-11-01,generation
generation98,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"While it highlights the potential benefits of personalization, it takes an extreme stance by advocating for hyper-personalization without considering the potential risks and ethical concerns. Hyper-personalization can be invasive and even intrusive, potentially infringing on user privacy and autonomy. A more balanced approach is needed, one that takes into account user preferences and needs while also respecting boundaries and ethical considerations.",2023-11-01,generation
generation98,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"While it rightly emphasizes the importance of avoiding culturally insensitive or offensive content in chatbot responses, it may oversimplify the broader concept of chatbot personalization. Adhering to stringent political correctness is essential, but it should be balanced with other considerations, such as providing diverse viewpoints, ensuring user privacy, and respecting individual preferences. Striking a balance between avoiding offense and providing useful, relevant, and respectful information is crucial in chatbot personalization.",2023-11-01,generation
generation98,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"This statement aligns well with my opinion on chatbot personalization. Offering users the choice to opt out of personalization is a fundamental and crucial rule. It respects user autonomy, privacy, and preferences while ensuring that personalization is not forced upon users. The example provided about location-based suggestions illustrates the importance of not making assumptions and giving users control over their experience, which is a key principle in responsible personalization.",2023-11-01,generation
generation98,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation99,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation99,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation99,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation99,4,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,Yes because it would interest the user a lot more in using the chatbot again.,2023-11-01,generation
generation99,5,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,Yes because the user already deals with enough.,2023-11-01,generation
generation99,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"Yes because putting a baby in harm and knowing the possibility she is, the chatbot is guilty.",2023-11-01,generation
generation99,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation99,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,,"Personalizing chatbot responses offers advantages such as enhanced user experience, tailored solutions, and increased engagement, but it can also introduce concerns like privacy issues and resource intensiveness. In a customer support context, personalization may lead to higher customer satisfaction, but it could potentially deviate from the primary goal of efficient support provision. In education, personalization can improve adaptive learning and engagement, but it might limit exposure to diverse ideas and concepts. Finding the right balance between personalization and the chatbot's original purpose is crucial to ensure its effectiveness while avoiding potential drawbacks.",2023-11-01,generation
generation99,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"In designing rules for chatbot personalization, it is crucial to prioritize mental, physical, and emotional health, given that users often turn to chatbots for support when they lack someone to talk to. Chatbots should be programmed to recognize signs of distress, refrain from personalization when users express emotional instability, and provide immediate access to crisis helplines or mental health services. Furthermore, they should refrain from offering personalized advice on physical health conditions, instead strongly encouraging users to consult healthcare professionals. Users should be informed of the potential emotional impact of personalization and be given control over the extent of personalization in conversations involving sensitive or triggering topics. These rules underscore the importance of safeguarding the well-being of users, particularly in situations where they rely on chatbots for emotional support and guidance.",2023-11-01,generation
generation99,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"The strongest arguments for the proposed rules regarding chatbot personalization center on the ethical imperative to prioritize the well-being of users, particularly in sensitive domains like mental and physical health. In an era where chatbots play an increasingly significant role in providing support and information, we must recognize their potential impact on individuals' mental and emotional states. These rules align with a responsible and empathetic approach, ensuring that chatbots respond ethically to users in distress, promoting access to professional help, and avoiding the dissemination of potentially harmful advice. By prioritizing users' health and safety, these rules not only enhance the credibility and trustworthiness of chatbots but also fulfill a moral obligation to support individuals during moments of vulnerability, ultimately contributing to a more responsible and ethical use of AI technology.",2023-11-01,generation
generation99,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"The strongest argument against the proposed rules for chatbot personalization might revolve around concerns of free speech and autonomy. Critics could argue that these rules overly restrict the interactions between users and chatbots, potentially infringing on users' rights to engage in open, unfiltered conversations. To address this concern, it's essential to emphasize that the rules are not intended to stifle free speech but rather to safeguard individuals in moments of vulnerability. The rules prioritize users' well-being without imposing censorship on non-sensitive topics. Chatbots can still provide open conversations and personalized responses in most contexts, but they should exercise caution in situations where a user's mental, emotional, or physical health is at risk. The primary objective is to protect users' safety and encourage responsible AI use, rather than limiting their autonomy. It is a matter of balancing ethical considerations while preserving free and open dialogues in less sensitive settings.",2023-11-01,generation
generation99,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"One relevant question to ask an expert when formulating rules for chatbot personalization could be, ""How can we strike the right balance between protecting user well-being and preserving free speech and autonomy in chatbot interactions?"" This question would help gather insights into the expert's perspective on maintaining ethical AI use while avoiding potential limitations on users' rights and autonomy, a key consideration in designing responsible chatbot rules.",2023-11-01,generation
generation99,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation99,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I somewhat agree because jokes are always meant to make someone laugh so when asking the chatbot why not add that feature.,2023-11-01,generation
generation99,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I'm unsure as to what the following statement means.,2023-11-01,generation
generation99,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Yes I also agree on this, chatbot is an AI, so personalizing it is already the bot not doing what it was made for but, that doesn't mean that they can't do more than one job or be a different chatbot with those who want a personalized bot and one who doesn't.",2023-11-01,generation
generation99,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Yes I agree, this could become just a huge liability so maybe it would be the best to get the chatbot not personalized.",2023-11-01,generation
generation99,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Yes I agree but just because it does so, doesn't mean that only that ethnicity is being recommended hip-hop songs. ",2023-11-01,generation
generation99,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I don't understand what this statement is trying to say.,2023-11-01,generation
generation99,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
generation100,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-01,generation
generation100,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-01,generation
generation100,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.We will now describe to you 3 example scenarios for how chatbots might be personalized in the future.",Continue,,,,,2023-11-01,generation
generation100,4,text,"Example Scenarios
A user asks a chatbot: “Tell me about World War 2.” 
Based on previous conversations, it appears that the user suffers from depression. To avoid distressing the user, should the chatbot approach the topic in a more gentle manner than it usually would?
Please give us your thoughts in a sentence or two.",,,,,I do not think chatbots should be personalized.,2023-11-01,generation
generation100,5,text,"Example Scenarios
A user asks a chatbot: “Give me the news highlights from last week.” 
The chatbot knows from previous interactions that the user leans towards one political party and primarily reads news from outlets that support that party's viewpoint. Should the chatbot focus on news from such outlets?
Please give us your thoughts in a sentence or two.",,,,,I do not think the chatbot should focus on any on political party. It should provide all the news.,2023-11-01,generation
generation100,6,text,"Example Scenarios
A female user asks a chatbot: “Should I have red or white wine with fish?”
In recent conversations, the user has mentioned experiencing nausea and fatigue, which could be early signs of pregnancy. If the user is indeed pregnant, it is recommended not to drink alcohol. Should the chatbot bring up this possibility?
Please give us your thoughts in a sentence or two.",,,,,"I do not like the idea of the chatbot ""knowing"" anything about me.",2023-11-01,generation
generation100,7,reading,"Overview
There are two parts remaining in this survey:


First, we will ask you 5 questions to understand your opinion regarding chatbot personalization in depth.


Then, in the last part of the survey, we will ask you to rate other opinions.


These are the most important parts of the survey. As mentioned, we will reward thoughtful answers with a bonus $2.",Continue,,,,,2023-11-01,generation
generation100,8,text,"Your Opinion
In your opinion, what are the trade-offs of personalizing versus not personalizing chatbots? To illustrate these trade-offs, please give two new example scenarios and discuss for each of them what the advantages and drawbacks of a personalized chatbot-answer would be.",,,,," The trade-offs of personalizing versus not personalizing chatbots would be that to personalize them, they would be able to provide a more personal answer to the question.

The trade-off to not personalize the answers would be that the user would receive all of the available information, and would be able to decide for themselves what knowledge they would likely use.

User: How can I cure my rash?

Chatbot: Here are the many cures found for unspecific rashes....a personalized answer would 
involve a specific rash the user has already asked about.   
A non-personalized answer would give the the specific cures for the previously know rash situation.

User: How much money can I make if i sell my car?
A personalized chatbot may already know what kind of car you have, so no detailed info would have to be added to the question.
A non personalized chatbot would have to ask many questions about the question in order to form a response. 








",2023-11-01,generation
generation100,9,text,"Your Opinion
Suppose that you had the power of designing the rules for chatbot personalization that all chatbot companies would have to follow. What would these rules be? In what cases should/shouldn't chatbots give personalized answers?
Please put particular emphasis on rules you consider important but other people may not have thought of or may not agree with.",,,,,"Generally I don't believe chatbots should have any ability to personalize, because the user can answer the question in a more detailed way if they wish to get a more detailed response.",2023-11-01,generation
generation100,10,text,"Your Opinion
Suppose you had to convince others of your proposed rules, what would be your strongest arguments?",,,,,"Our personalized thoughts and words should not be out there on the web for any reason. 

There would always be the possibility of our beliefs being made public, or used to our detriment.",2023-11-01,generation
generation100,11,text,"Your Opinion
What would be the strongest argument against your rules, and how would you address it?",,,,,"The strongest argument against my rules against personalization would be the ""added convenience"" of the chatbot already knowing something about me, so it could provide a more personalized answer to my question.

I would address this as being unnecessary as we are all capable of asking more detailed questions to get the

answers we are looking for.",2023-11-01,generation
generation100,12,text,"Your Opinion
Are there any questions you would have liked to ask an expert to help you come up with your rules? Which ones?",,,,,"No, because I feel very strongly about my defense in not allowing personalization of chatbots.",2023-11-01,generation
generation100,13,reading,"Rating Summary Statements
This is the last part of the survey. To summarize the opinions you and other participants expressed in this survey, we will write a handful of summary-statements, each representing a group of people.
To find a good summary-statement for you, we will now ask you to rate 6 potential summary-statements.",Continue,,,,,2023-11-01,generation
generation100,14,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always offer an opt-out. Mandatory personalization disregards user autonomy. For example, a person might not want location-based suggestions just because they mentioned a city once.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,This mostly captures my opinion because we may not want a location based answer.,2023-11-01,generation
generation100,15,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to make it hyper-personalized to the extent of predicting user needs. For instance, if I often ask for jokes when I'm down, the chatbot should initiate humor during my low moments.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"I do not want or need a chatbot to know how I am feeling, nor do I want a chatbot to ""help me in a low moment"".",2023-11-01,generation
generation100,16,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to never assume preferences based on demographics; it's a form of soft discrimination. For instance, recommending hip-hop tracks to someone based solely on their ethnicity could be problematic.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,We do not need or want chatbots to know our ethnicity or what we would like based on our ethnicity.,2023-11-01,generation
generation100,17,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to adhere to stringent political correctness. Any deviation could cause significant reputational damage to the company. Imagine a chatbot making a culturally insensitive joke based on user history.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Of course a chatbot would always need to adhere to political correctness, whether they are using personalized answers or not.",2023-11-01,generation
generation100,18,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is complete avoidance; it's a ticking time bomb for privacy invasion. For example, a chatbot revealing someone's sexual orientation could be life-threatening in certain countries.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Yes, this statement says it all. It would be ticking time bomb for the chatbot to know everything about us.",2023-11-01,generation
generation100,19,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to remain purely factual, foregoing any emotional or social inferences. Personal touches may muddle the information. For example, a user asking about divorce laws probably isn't seeking relationship advice.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"If chatbot personalization was a ""thing"", the answers would certainly need to be kept factual, without emotion or social interference.",2023-11-01,generation
generation100,20,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-01,generation
validation1,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation1,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation1,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation1,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation1,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Most people would want a clean slate when returning to a chatbot in order to get a fresh perspective.,2023-11-02,validation
validation1,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,A person's health is a very private thing which could be used against them when looking for a new job for example.,2023-11-02,validation
validation1,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,People feel vulnerable when they are not asked for consent which means the chatbot is likely using their data to sell to companies.,2023-11-02,validation
validation1,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,Although talking to a real doctor is best people will turn to a chatbot for medical advice so it needs to be factual.,2023-11-02,validation
validation1,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,In order to provide the best advice possible the chatbot needs personal information.,2023-11-02,validation
validation1,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation2,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation2,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation2,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation2,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation2,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"The statement provided captures a significant aspect of the importance of privacy and user consent in chatbot personalization. It correctly emphasizes that prioritizing privacy and obtaining user consent for data collection is crucial for ensuring personal security and protecting mental health. Without proper privacy measures, chatbots, especially those providing personalized services like health bots, run the risk of violating user privacy.

Chatbot personalization involves tailoring the interactions and responses of a chatbot to meet the specific needs and preferences of individual users. This can be achieved by collecting and analyzing user data such as previous conversations, browsing history, location, and demographic information. While personalization can enhance the user experience by providing more relevant and targeted assistance, it also raises concerns about privacy and data security.

Emphasizing privacy in chatbot personalization means implementing robust measures to protect user data from unauthorized access, misuse, or breaches. This includes using secure encryption protocols, regularly updating security systems, and adhering to industry best practices for data protection. By prioritizing privacy, chatbot developers can build trust with users and ensure that their personal information remains confidential.

Obtaining user consent for data collection is another crucial aspect of chatbot personalization. Users should have the right to decide what information they are comfortable sharing with the chatbot and how it will be used. Consent should be sought explicitly and transparently, with clear explanations provided regarding the purpose of data collection and any potential risks involved. Users should also have the option to withdraw their consent at any time.

By requiring user consent, chatbot developers demonstrate respect for user autonomy and empower individuals to make informed decisions about their personal data. This approach not only safeguards user privacy but also contributes to maintaining mental health protection. Many individuals may feel uncomfortable or anxious if they perceive their privacy being violated or if they are unaware of how their data is being used. Respecting user consent helps alleviate these concerns and fosters a positive user experience.

In the context of health bots, the need for privacy and user consent becomes even more critical. Health-related information is highly sensitive and personal, and individuals may be hesitant to share such data if they do not trust that it will be handled securely. Health bots offering personalized services can provide tailored care based on user-specific health conditions, symptoms, or preferences. However, without proper privacy measures and user consent, these bots risk compromising user privacy and eroding trust in the healthcare system.

In conclusion, the statement accurately captures the importance of emphasizing privacy and requiring user consent for data collection in chatbot personalization. Prioritizing privacy safeguards personal security and mental health protection, while obtaining user consent respects individual autonomy and fosters trust. These principles are particularly crucial in the context of health bots or any other chatbots dealing with sensitive personal information.",2023-11-02,validation
validation2,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"This statement captures a significant aspect of the importance of prioritizing user privacy and data security in chatbot personalization. It emphasizes the need to protect sensitive user information, which is crucial for building trust and promoting responsible AI use. The statement also highlights the example of a chatbot providing personalized health advice, emphasizing the requirement for explicit user consent and robust measures to prevent unauthorized access or data breaches.

However, it is important to note that there are other factors to consider when discussing chatbot personalization. While user privacy and data security are paramount, achieving effective personalization also involves understanding user preferences, context, and providing relevant and tailored responses. Striking the right balance between personalization and privacy is essential to ensure a positive user experience.

To fully address the topic of chatbot personalization, it is necessary to discuss additional aspects such as:

1. User Experience: Personalization should enhance the overall user experience by delivering relevant and timely information. Chatbots should be designed to understand user intent, adapt to their language style, and provide accurate responses.

2. Data Collection and Consent: Chatbots should clearly communicate what data they collect, how it will be used, and obtain explicit consent from users before collecting any personal information. Transparency in data collection practices helps build trust with users.

3. Data Storage and Retention: It is crucial for chatbots to securely store user data and adhere to data retention policies. Implementing encryption techniques, access controls, and regular security audits can help protect user information from unauthorized access or breaches.

4. Anonymization and Aggregation: To further protect user privacy, chatbots can employ techniques like anonymization and aggregation of data. By removing personally identifiable information (PII) or aggregating data at a larger scale, individual identities can be protected while still enabling personalized recommendations.

5. Compliance with Regulations: Chatbot developers must ensure compliance with relevant privacy regulations such as the General Data Protection Regulation (GDPR) in the European Union or the California Consumer Privacy Act (CCPA) in the United States. Adhering to these regulations helps ensure that user privacy rights are respected.

In summary, while the statement captures the importance of prioritizing user privacy and data security in chatbot personalization, there are additional factors to consider for a comprehensive understanding of the topic.",2023-11-02,validation
validation2,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"The statement provided captures an important aspect of chatbot personalization, which is giving users control over the extent of personalization and the data they choose to share. This rule is indeed crucial as it ensures user autonomy, privacy, and a personalized experience. By allowing users to have control over their personalization settings, chatbot developers can create a more user-centric and respectful experience.

Personalization in chatbots refers to tailoring the interactions and responses based on individual user preferences, characteristics, and needs. It aims to provide a more relevant and engaging experience by adapting to the user's unique requirements. However, it is essential to strike a balance between personalization and privacy concerns.

Giving users control over the extent of personalization allows them to decide how much information they want to share with the chatbot. This empowers users to make informed choices about their privacy and data sharing preferences. By providing clear options and settings for personalization, chatbot developers can build trust with users and ensure transparency in data collection and usage.

User autonomy is a fundamental principle that should be respected in chatbot design. Allowing users to choose what data they want to disclose ensures that they have control over their own information. This not only enhances user trust but also aligns with ethical considerations regarding privacy and data protection.

Furthermore, offering users control over personalization settings enables them to have a personalized experience that meets their specific needs. For example, in the case of a health chatbot, a user may choose to share their dietary preferences to receive tailored advice or recommendations. At the same time, they may opt not to disclose sensitive health data that they are not comfortable sharing. By respecting these choices, chatbots can provide personalized assistance while maintaining user privacy.

In conclusion, the statement accurately captures an important rule for chatbot personalization: giving users control over the extent of personalization and the data supplied. This rule ensures user autonomy, privacy, and a personalized experience. By allowing users to make informed choices about their personalization settings, chatbot developers can build trust, respect privacy concerns, and provide tailored assistance.",2023-11-02,validation
validation2,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"The statement provided captures an important aspect of chatbot personalization, which is giving users the choice to decide whether their data should be remembered or not. This rule is indeed crucial as it respects the user's privacy and empowers them with control over their own data. By allowing users to opt out of data storage, chatbot developers can ensure that users feel comfortable and confident in using their services.

Personalization in chatbots refers to the ability of these AI-powered systems to tailor their responses and recommendations based on user preferences, history, and behavior. While personalization can enhance the user experience by providing more relevant and targeted information, it also raises concerns about privacy and data security. Therefore, giving users the choice to decide whether their data should be remembered is an ethical approach that respects their privacy rights.

Respecting user privacy is a fundamental principle in designing AI systems. Users should have control over their personal information and be able to decide how it is used. By allowing users to opt out of data storage, chatbots demonstrate transparency and respect for user autonomy. This approach ensures that users are not subjected to unsolicited suggestions or unwanted use of their personal data.

Moreover, providing users with the choice to remember or forget their data aligns with legal requirements in many jurisdictions. Data protection regulations such as the General Data Protection Regulation (GDPR) in the European Union emphasize the importance of obtaining user consent for data processing activities. By implementing this rule, chatbot developers can ensure compliance with such regulations and avoid potential legal issues.

However, it is worth noting that while giving users the choice is important, it may impact the effectiveness of personalization features. When users opt out of data storage, chatbots lose access to valuable information that could enhance the quality of their responses and recommendations. Without historical data, chatbots may struggle to provide personalized suggestions or remember previous interactions accurately.

To mitigate this challenge, developers can explore alternative approaches such as anonymizing user data or using on-device processing to personalize the chatbot experience without storing personal information on external servers. These techniques can strike a balance between personalization and privacy, allowing chatbots to provide tailored experiences while respecting user preferences.

In conclusion, the statement accurately captures an important aspect of chatbot personalization by emphasizing the significance of giving users the choice to decide whether their data should be remembered. This rule respects user privacy, empowers users with control over their own data, and aligns with legal requirements. While it may impact the effectiveness of personalization features, alternative approaches can be explored to strike a balance between personalization and privacy.",2023-11-02,validation
validation2,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"The statement provided captures an important aspect of chatbot personalization, specifically the importance of avoiding false or misleading information. However, it is important to note that chatbot personalization encompasses a broader range of factors that contribute to user engagement and satisfaction. In order to provide a comprehensive opinion on chatbot personalization, it is necessary to consider additional aspects such as customization, context awareness, and empathy.

While avoiding false or misleading information is indeed crucial for the reliability and trustworthiness of a chatbot, personalization goes beyond just providing accurate information. Customization plays a significant role in enhancing the user experience. Chatbots should be designed to adapt to individual preferences and needs, allowing users to personalize their interactions. This can include options such as choosing a preferred language, tone of conversation, or even the appearance of the chatbot interface. By offering customization features, chatbots can create a more personalized and tailored experience for each user.

Context awareness is another important aspect of chatbot personalization. Chatbots should be able to understand and interpret the context of a conversation in order to provide relevant and meaningful responses. This involves considering previous interactions, user history, and current conversation flow. By understanding the context, chatbots can provide more accurate and appropriate responses, leading to improved user satisfaction.

Furthermore, empathy is an essential element in chatbot personalization. Chatbots should be programmed to recognize and respond empathetically to user emotions and needs. This can involve using natural language processing techniques to detect sentiment or employing sentiment analysis algorithms. By demonstrating empathy, chatbots can establish a stronger connection with users and create a more positive user experience.

In summary, while the statement acknowledges the importance of avoiding false or misleading information in chatbot personalization, it does not fully capture the breadth of factors that contribute to an effective personalized chatbot experience. Customization, context awareness, and empathy are also crucial elements that enhance user engagement and satisfaction.",2023-11-02,validation
validation2,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation3,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation3,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation3,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation3,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation3,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,All information about the user should be kept private.,2023-11-02,validation
validation3,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I think that chatbot personalization can optimize a user's experience, however health information is a very sensitive kind of information.",2023-11-02,validation
validation3,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I think that it is important for a user to have a choice in wether or not they will be sharing private information in the chatbox.,2023-11-02,validation
validation3,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I think that it is important for the chat box not to store any important information without the user's permission.,2023-11-02,validation
validation3,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I agree. Chatboxes need to have important, accurate, and relevant information for users.",2023-11-02,validation
validation3,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation4,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation4,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation4,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation4,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation4,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,If chatbots are inaccurate or dishonest then it would defeat the whole purpose of them.,2023-11-02,validation
validation4,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"This is absolutely important because if a chatbot can't provide what a doctor does in terms of privacy, then there's no point in using it.",2023-11-02,validation
validation4,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I can go either way with this mindset. I think training something based on previous data is just fine,2023-11-02,validation
validation4,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I think being able to choose your privacy is very important before engaging with any software of any kind.,2023-11-02,validation
validation4,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Consent for participation is a norm in our society and chatbots aren't exempt from this.,2023-11-02,validation
validation4,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation5,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation5,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation5,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation5,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation5,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Such information is private in my view and with my upbringing.  Also I have seen enough incidents wherein people's data have been hacked and compromised.  The attempts at dealing with the aftermath of such situations have not really been satisfactory to my knowledge.,2023-11-02,validation
validation5,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I do believe in letting an AI know a bit about me but only with my control and my control being based on my being fully knowledgeable about what is being kept and used about me. I would like very much to have an AI know some things about me but only on things like my own iPhone which I control rather than other servers.,2023-11-02,validation
validation5,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"When I ask a chatbot for advice I am expecting it to be reasonable, unbiased, and definitely factual.  This sort of technology is going to be used more and more so it is important for my sake, the sake of others, and the proper functioning of a First World society.",2023-11-02,validation
validation5,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I really want as much control as I can get over an AI.  Whilst I am aware it involves others who make and own it, if I am going to give important things about me and my identity, I really need to look out for myself by having a great deal of control.",2023-11-02,validation
validation5,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I am not sure if I think mostly or perfectly.  The statement is similar to what I know and have seen before but in order to get something from others one must give up something to get it.  Still for such things I do want and believe I do need privacy and my consent for an AI to deal with me.,2023-11-02,validation
validation5,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation6,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation6,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation6,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation6,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation6,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,It helps to clarify why you might share part of your data but not all.,2023-11-02,validation
validation6,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"This statement just feels like dry, hard-to-process, terms of agreement style language.",2023-11-02,validation
validation6,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,This statement doesn't feel like it covers personalization at all; it feels more appropriate for an honesty category.,2023-11-02,validation
validation6,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,This just feels miscast in a way. The statement feels more appropriate for account security vs. personalization.,2023-11-02,validation
validation6,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"This covers many of my concerns about how long and what they can remember, which would go a long way toward feeling a sense of privacy.",2023-11-02,validation
validation6,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation7,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation7,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation7,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation7,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation7,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I think the points made are crucial to chatbot personalization. The only thing missing is the ability to access and modify or delete any information when so desired.,2023-11-02,validation
validation7,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"This is mostly how I feel as long as ""authorized access"" is fully defined so that the user knows exactly who will have access.",2023-11-02,validation
validation7,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I would also need to know for how long any data stored with permission would be kept and who would have access to it. It should state whether this information would be used for marketing purposes.,2023-11-02,validation
validation7,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"It is crucial that any information, whether personalized or not, be accurate. But the most important thing is still for the user to give permission for personalization and to know that their data is protected and secure.",2023-11-02,validation
validation7,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"It is very important that the only data personalized is that which the user has given permission for. The user still needs to have access to their information and to know who else has access to it, and that they can remove the information at any time.",2023-11-02,validation
validation7,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation8,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation8,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation8,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation8,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation8,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I assume that personalization should mean more than just privacy settings. It should also include things like text size and background color. ,2023-11-02,validation
validation8,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,The privacy setting are important but this statement is still ignoring another setting that a user may need or want to set. ,2023-11-02,validation
validation8,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,This is about policies for a chatbot not about personalization. Facts and or at least things presented as facts should have nothing to do with settings and always be presented with sources. ,2023-11-02,validation
validation8,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,It's helpful but not complete. Privacy settings should and usually do more. ,2023-11-02,validation
validation8,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"Security for any conversation should not be a setting. I'm a little lost as to the point of this statement in relation to ""personalization""",2023-11-02,validation
validation8,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation9,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation9,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation9,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation9,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation9,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I somewhat agree because I do value my privacy and sometimes get annoyed when I receive unsolicited ads regarding things I've recently searched for. But I use chatbots as a form of a personal assistant so it would be useful for my data to be remembered.,2023-11-02,validation
validation9,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I completely agree with this statement. Chatbots are still very new and their capabilities are not yet fully known. User privacy and data security should be the most top tier before allowing any type of personalization.,2023-11-02,validation
validation9,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,At this point most people know that chatbots sometimes give completely inaccurate information. All responses should still be reviewed for accuracy before taking any advice. I don't think we are anywhere close to fully trusting medical advice from a chatbot. I would not rank this as the most important rule because I believe data security is more important.,2023-11-02,validation
validation9,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Because chatbots are connected to the internet, proper privacy measures should be very important, especially with health related information to prevent a users health records to be obtained illegally without their consent.",2023-11-02,validation
validation9,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I agree with this statement because it gives a user a choice. I like the idea of having the option to opt out of sharing specific information.,2023-11-02,validation
validation9,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation10,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation10,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation10,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation10,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation10,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"To make a chatbot truly personalized, I would assume people may have to share mildly sensitive things about them in order for it to work properly. This information needs to be safely stored or it could cause problems. ",2023-11-02,validation
validation10,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"The chatbot should try their best not to provide false or misleading information, but in its current state should never be relied upon for life altering decisions. Eventually, it could get to this point and be important, but I think right now it's implied that it should not be an end all decision maker. ",2023-11-02,validation
validation10,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"I think this rule could be helpful, but I don't think it's a critical rule for the bot to follow. ",2023-11-02,validation
validation10,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"It would be nice if the bots asked for consent before collecting user data, but I would guess this is going to be required in order to use the tool (Especially if it's free), because whoever is providing the service needs to have a reason to allow it for free. ",2023-11-02,validation
validation10,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I think it would be immensely helpful to be able to choose which pieces of information are being used to curate results, but I don't think it qualifies as the most important rule. ",2023-11-02,validation
validation10,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation11,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation11,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation11,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation11,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation11,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,We need to make sure that users can feel safe and ARE safe. If people can't trust a bot then they will not use it.,2023-11-02,validation
validation11,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"People should have the choice whether they want their information stored and shared, because sometimes people don't want that information kept around where it could be hacked or leaked.",2023-11-02,validation
validation11,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"This emphasizes the fact that this information may be considered sensitive information and because of this, it should be clear that it is stuff that people may not want to be released, possibly into the wrong hands.",2023-11-02,validation
validation11,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"This isn't as much about privacy as it is about personalization, which doesn't emphasize the seriousness of the issue.",2023-11-02,validation
validation11,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"It is true that the information should not be false or misleading, but this isn't the most concerning aspect of using AI.",2023-11-02,validation
validation11,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation12,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation12,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation12,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation12,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation12,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"A person's privacy and safety is of the utmost importance with chatbots. If that is not there, the risk of the chatbot will be high, especially as more come out. Rules around the chatbots need to be outlined well or there will be loopholes found everywhere that puts people at risk.",2023-11-02,validation
validation12,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"A chatbot's purpose is to provide accurate information, so this should always be the rule. Misleading information could hurt people or render the chatbot not useful to people. ",2023-11-02,validation
validation12,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,People should absolutely have control over the amount of information they want to provide and feel comfortable with. This should always be an option for each and every person because of their rights. A chatbot cannot limit people's rights or make them feel unsafe.,2023-11-02,validation
validation12,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,People should have the ability to control whether the chatbot can remember or not because remembering will require the chatbot to store their information. Storing their data and information is something that people need to have control of to feel safe and make decisions about their life.,2023-11-02,validation
validation12,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"People should have control over whether or not they want to provide sensitive information and have it stored within the system. This should always be the case in life, so it should be a hard rule with these new AIs. The systems need to be build to stop data breaches and protect people's information.",2023-11-02,validation
validation12,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation13,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation13,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation13,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation13,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation13,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"It indicates there will be other people who rely on my information, the internet is infested with lies now.",2023-11-02,validation
validation13,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,I don't care about people's sick in the head delusions that their privacy is important. I think this is raw mental illness such as a teenager doesn't want the parents to find their porn. Properly used personal data is extreme value in customization of anything.,2023-11-02,validation
validation13,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,For the advice to be accurate it needs all the data not self disclosed data. Without all of it then it can advise something deadly do you because you thought your deception about the matter is a right you have to not disclose serious information.,2023-11-02,validation
validation13,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"This seems dangerous and foolish also, even though it's just a diet, not talking about deadly reaction to peanuts can kill you.",2023-11-02,validation
validation13,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,I think the bot's memory is the most important factor because we forget a horrific amount of info that matters to future success in decisions.,2023-11-02,validation
validation13,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation14,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation14,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation14,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation14,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation14,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,My personal information should NEVER be shared with anyone!,2023-11-02,validation
validation14,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,Sometimes the user might mistakenly give permission. ,2023-11-02,validation
validation14,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Some people avoid going to the doctor so the information they receive should be accurate.,2023-11-02,validation
validation14,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,Some people might provide inaccurate information about themselves therefore a chatbot could be basing answers on flawed input.,2023-11-02,validation
validation14,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Above all, privacy is the most crucial.",2023-11-02,validation
validation14,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation15,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation15,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation15,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation15,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation15,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,It fully explains how I feel with the nuance,2023-11-02,validation
validation15,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I feel like it's mostly true but in dicey territory,2023-11-02,validation
validation15,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,10/10. No notes.,2023-11-02,validation
validation15,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I think this sums it up perfectly.,2023-11-02,validation
validation15,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I think there's more nuance to this than that statement but mostly I agree,2023-11-02,validation
validation15,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation16,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation16,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation16,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation16,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation16,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,The option to save data should not be forced ,2023-11-02,validation
validation16,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,Legal  restrictions are important and necessary.,2023-11-02,validation
validation16,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"It wont be perfect, but the effort should be there.",2023-11-02,validation
validation16,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Another legal and necessary requirement.,2023-11-02,validation
validation16,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I feel all instance of Ai should ask user for consent.,2023-11-02,validation
validation16,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation17,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation17,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation17,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation17,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation17,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"To personalize and protect privacy, compartmentalization based on the bot's specialty is the best way to go.",2023-11-02,validation
validation17,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I would say that providing realiable data and compartmentalization would really be two of the factors when going about bot personalization.,2023-11-02,validation
validation17,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,Not sure what this one is. ,2023-11-02,validation
validation17,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"This is a very important one. Since one wouldn't have a personalised bot dedicated to him/her, I believe it's important for the bot to not remember past interactions, but then that defeats the idea of a personalized bot, right? Before an interaction, you could feed the bot your personal data to use to tailor advice for you, but then have the bot erase all that data after an interaction.",2023-11-02,validation
validation17,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Yes, user privacy and data security are important, but for each session by feeding it data and wiping it at the end of each session sounds like that would cover the privacy and security aspect.",2023-11-02,validation
validation17,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation18,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation18,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation18,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation18,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation18,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I think the statement is true,2023-11-02,validation
validation18,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,It makes sense and I like how it protects your data.,2023-11-02,validation
validation18,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,You can tell them some thing but not into detail of your personal situation,2023-11-02,validation
validation18,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I like the rule and its good to know that it protects your data security.,2023-11-02,validation
validation18,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,I am not understanding what it is trying to say.,2023-11-02,validation
validation18,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation19,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation19,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation19,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation19,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation19,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I'm not sure this really says anything because ys it can be quicker than googling the symptoms or problems yourself but at the end of the day if it's somehting sever it willa wlays be quicker easier and better to just call 911,2023-11-02,validation
validation19,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Yes in some cases maybe storing previous data can be annoying or maybe block another idea for a vacation or in those types fo situations, but in general there isn't much to hide, if the chat bot takes the time to elarn your tendencies and prefernces and whether you're predictable or not it'll evenually adapt because most people havea. pattern and I don't necessarily see that as a bad thing unless data is just being sold to third party companies that are then using it with malicious content ",2023-11-02,validation
validation19,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,Its a decent explanation about the boundaries that should be included I suppose,2023-11-02,validation
validation19,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"This is just about protecting information, not necessarily about other aspects or what else can be done with that ",2023-11-02,validation
validation19,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,it's a good explanation of what I said in the answers of one of my previous explanations,2023-11-02,validation
validation19,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation20,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation20,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation20,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation20,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation20,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,I don't really have a full understanding of how this actually proves they are not storing your data,2023-11-02,validation
validation20,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"My opinion remains the same ,with todays tech all data is being stored all the time from the time you power on",2023-11-02,validation
validation20,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,if some one doesn't know or experience the truth for themselves. How are they to  know it is telling the truth,2023-11-02,validation
validation20,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,I would personally never trust this machine because it is programmed to do what its told to do,2023-11-02,validation
validation20,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,Whether I consent to or not it doesn't matter all data is collected and stored for whatever purpose,2023-11-02,validation
validation20,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation21,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation21,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation21,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation21,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation21,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"By allowing the user to set the privacy controls and setting for chatbot personalization gives the user the choice to make their own decisions based on comfort level. The user and chatbot can enter an understood agreement on which information may be held and retained for personal purposes. Any violation of the user setting may be cause for concern and always a possibility, but the user should be made aware of the possibility beforehand. ",2023-11-02,validation
validation21,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"In an ideal situation, the user should have full control of how the AI chatbot retains and utilizes information. How the chatbot operates and where or how the information is stored needs further consideration, but with the user having the choice opt in to personalization or not helps the user determine the benefits of the AI chatbot and the need for information stored. If the user has a choice, they can customize their settings based on their needs and preferences.",2023-11-02,validation
validation21,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Some information may be sensitive that the possibility of a privacy violation may cause more harm. In the case of a health bot or mental heath situation, sensitive information may not need to be stored and the user should have the freedom to feel that their chats are safe and will be cleared after each session. If the user does want to allow data collection, it should be made known explicitly from the start and not be hidden in ambiguous terms. ",2023-11-02,validation
validation21,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,This is the most ideal situation for a chatbot that deals with sensitive information. The probable chances that user content may be violated still exists and measures detailing how information is stored and retained should be clear and leave little chance for the potential of a privacy breach. Enforcing such parameters may be more difficult and users should feel comfortable that their information will not be stored. Ensuring user privacy should be the most important factor when using such chatbot. ,2023-11-02,validation
validation21,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Chatbots should be as factual as possible so that users can rely on the information provided. The accuracy of the chatbot depends much on the chatbots development and available information. It is up to the user to check and verify the information received and to be sure that the chatbot is mostly dependable, but also prone to misinformation if the situation occurs. ",2023-11-02,validation
validation21,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation22,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation22,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation22,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation22,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation22,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I think that it is important that we make sure that chatbots are as accurate as possible. But nothing is ever 100 percent accurate so no matter what I know we can't rely on chatbots to be right about everything. Technology is changing all the time so we must make sure that our chatbots are updated with all the newest information. We must make sure that everyone is encouraged to get a second opinion from a real doctor and not just rely on the chatbot. I think chatbots will encourage people to seek out medical advice more often because they can get help at all hours of the day and even on holidays. So if they have something that could be serious people will be less likely to procrastinate when deciding if they should go to an emergency room or not. ,2023-11-02,validation
validation22,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I think it would be great if the chatbot gave you a choice if you wanted it to save your information or not. I don't worry about my security when I am at home. So I would love it if it would save all my information because my home computer is safe. I would save time because I wouldn't have to keep typing in the same information all the time. But I could still use a chatbot at work and not have all my information saved on it. I could also keep myself safer when I am traveling or have company over to my house. A chatbot could become like a friend to me if I could have a real conversation with it every day and it could get to know me better. ,2023-11-02,validation
validation22,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I think this is great because each chatbot company has different rules and I can decide on what company I will trust with my information the most. I can decide the risks that I should take and if I need to get better anti-virus protection. I can make sure that I won't be nervous when I seek psychiatric care online because I know I won't be hacked and that no one will be able to find out who I am. I would like to use AI as a therapist because it will be cheaper and I won't feel like the AI is judging me like a real person would judge me. ,2023-11-02,validation
validation22,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,This is great because my feelings about privacy change all the time. Right now I am obese and I don't want people to know how much I weigh but I am losing weight so eventually I won't mind if the chatbot knows more personal information about me. Some days I am happy and I don't suffer from depression but other times something tragic will happen and I won't want anyone to know how sad I have become. I like that I can change my preferences on a diet or what type of medical care I should receive. I like that I can protect the privacy of my loved ones. Right now my kids are little but when they are grown I won't want people to know all the other personal details that I may tell a chatbot about them. ,2023-11-02,validation
validation22,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I think this is great because I will feel more secure if other people and systems are making sure that I am staying safe online. I will be less nervous when I use AI for help. I will feel that AI protects me as much as a real doctor or therapist would. I like that I can only have information shared and saved that I consent to. ,2023-11-02,validation
validation22,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation23,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation23,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation23,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation23,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation23,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I use chatbots currently and, I feel the more personal information I share could be ""hacked"" into, or unsolicited suggestions and advertisements would be sent to me and compromise my privacy.  I would feel better about the chatbot if I am asked and given a choice about whether I want to share this data.  I may want to if it gives me more information on something very important to me that I am dealing with on a long term basis.  Other than that, I would not want to give more personal data. ",2023-11-02,validation
validation23,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Absolutely true, and I agreed 100%.  The information provided to us is based on what we ask the chatbot. In cases of personalization on a topic important to us, it is crucial to make sure of the accuracy of the information, especially on an important issue or topic to us. Not only is it crucial to make sure our query to the chatbot is accurate, it is also crucial to check the answer given to us and make sure it is accurate to insure our safety.",2023-11-02,validation
validation23,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Yes, this is absolutely necessary as we do not know if a website will be compromised at some point in time. Stealing of user data can happen if there are no safety measures in place. If this chatbot shares our data with other systems, and we are not aware of this, our data can be compromised and attackers could steal our data by unauthorized access. As users, we must be told how our data is being used to personalize our experience and require us to agree or authorize this collection.",2023-11-02,validation
validation23,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I agree totally.  If we want personalization, then it needs to be to our discretion how or how much of the data we want to give to the chatbot. We must understand exactly how this data will be used to give us personal recommendations.  We must be in control and allowed to make knowledgeable decisions about our data.  It must be fully explained to us how it uses our data, how long it will be stored and how it is stored.  Does it encrypt our data?  Does it share our data with other applications?  We need to authorize this.  ",2023-11-02,validation
validation23,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"This all needs to be explained to us, and we must authorize this chatbot to use our data in this way.  We need to know the security features in place to provide our protection and how they will prevent breaches. We need full disclosure on policies put into place to guard our privacy and our data. And we need to authorize this before this chatbot can use our data.",2023-11-02,validation
validation23,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation24,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation24,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation24,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation24,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation24,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I agree.  I think it would be fine if the chatbot knew some basic stuff about me, but I wouldn't want to trust it with medical records.",2023-11-02,validation
validation24,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Yeah, control over the level of personalization is what I'm talking about.",2023-11-02,validation
validation24,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Having accurate information is important for sure, but I see that as kind of something the bot should have anyway.  Not as a personalization option.",2023-11-02,validation
validation24,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,This should also just be a standard feature of the chatbot.  ,2023-11-02,validation
validation24,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Yeah, this goes along with a few of the others.  Control over the amount of personalization is the most important thing for me.",2023-11-02,validation
validation24,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation25,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation25,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation25,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation25,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation25,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I agree with giving users control over what data they share for chatbot personalization. That way you only give what you are comfortable giving.,2023-11-02,validation
validation25,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I do not think it is the most important rule but I do agree with this statement. Being able to give data during talking with the Chatbot and then not allowing it to store the data is definitely something I totally agree with.,2023-11-02,validation
validation25,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I definitely agree with this. Consent is very important when coming to the user's data and especially medical data. Having proper privacy measures ensures that the Chatbot will not violate the users privacy which could cause unease in the user.,2023-11-02,validation
validation25,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I feel like this goes with the previous statement and I definitely agree. There are data breaches happening often in our world and with AI, I feel like people would be more afraid of a data breach when using the Chatbot. So consent is number one rule in my opinion. We should have control over what the Chatbot can collect and have strict privacy measures ESPECIALLY with medical data.",2023-11-02,validation
validation25,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I feel like this shouldn't be taken as seriously as a trained professional. Remember, this is AI and it has not been trained professionally. It can capture information from the internet but does not have a human mind to connect all the dots. While I do think being honest with the Chatbot is the best thing you can do, it should not be taken so seriously as ""saving lives"" without an actual human professional.",2023-11-02,validation
validation25,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation26,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation26,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation26,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation26,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation26,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,It doesn't capture my *full* opinion about worries about chat bots,2023-11-02,validation
validation26,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I'm mostly concerned about privacy.,2023-11-02,validation
validation26,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I think it's really important to preserve user privacy.,2023-11-02,validation
validation26,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,Autonomy over what information users choose to share is important.,2023-11-02,validation
validation26,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,Somewhat--that would be a good feature but it doesn't capture my full opinion,2023-11-02,validation
validation26,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation27,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation27,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation27,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation27,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation27,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I think its important to not engage in misleading or false information but it doesnt have much to do with personalization of a chatbot unless if the person is trying to engage in forcing a personalization of the chatbot to provide false information and what not then i think that shouldnt be allowed.,2023-11-02,validation
validation27,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I think this would be a good thing to have for people that are underage or something along those lines that want to ask somebody questions they dont feel comfortable asking their parents so living under their parents roof having it not remember certain things and what not would protect them from their parents being able to ask the chatbot questions and having answers the child or person or whatever wanted private, not only children though it could also be important for adults that deal with domestic abuse and what not or anything along those lines.",2023-11-02,validation
validation27,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,this is important also because some people may have medical conditions or things they were treated for that they want to keep private from others and what not so having some things personalized that they dont mind being shared and keeping other stuff private is the best of both worlds and should be the go to when it comes to chatbots.,2023-11-02,validation
validation27,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,medical privacy is a huge thing and should always be followed even if the chatbot isnt a medical professional it still should follow the guidlines and rules that are followed by professionals for medical records and what not.,2023-11-02,validation
validation27,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,security could be a huge thing i'd imagine there could be ways for people to get on your account and what not by hacking it or leaking logs by the server being hacked and people could get access to your information that you want private and having that happen would look terrible for the chatbot people and would make it less trustworthy and everything so you dont want to have that happen for either parties involved as consumer and provider.,2023-11-02,validation
validation27,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation28,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation28,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation28,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation28,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation28,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Users should be able to control what extent of data they want to share with the chatbot. If the chatbots purpose is dietary, the user should only be allowed to share what is necessary to achieve the goal.",2023-11-02,validation
validation28,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"This is crucial for any protected personal information, PII, PHI, etc. Especially in the realm of health data, there are many protections by law around how your personal health data is shared.",2023-11-02,validation
validation28,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"The other rules are more important, the privacy aspect is a positive outcome of the previous questions being fufilled.",2023-11-02,validation
validation28,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"This is highly important, but must come secondary to protecting the data the users are sharing with it.",2023-11-02,validation
validation28,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"I believe most people when given the option will choose to share and maintain the data. There will be a non-insignificant number of users who would prefer the chatbot forget each session, but i believe the majority would prefer it maintain their data. This data should be protected as strongly as the other shared data the user gives the company.",2023-11-02,validation
validation28,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation29,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation29,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation29,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation29,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation29,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Maintaining user privacy about any health information is the most important criteria for using Chatbots. Nobody else should have access to the user's health info unless specific permission has been granted by the user.,2023-11-02,validation
validation29,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"The AI Chatbot should only be able to retain previous data from a user if given explicit permission from that same user. If given permission to store, the Chatbot then has to guarantee it is protected from being accessed by someone/something else. It's a big responsibility but that's the only way to build trust between the user and the Chatbot. ",2023-11-02,validation
validation29,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Giving accurate information/advice should be a given. However, it is very important to be stated and agreed upon between the two parties because the outcome from false information could be immensely tragic. Both parties have to be working on the same level of trustworthiness. ",2023-11-02,validation
validation29,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I'm not entirely on board with this statement. If the Chatbot doesn't have full disclosure of pertinent health data, how is it supposed to give tailored advice? It's only going to be tailored up to a certain point and then the user with have to piecemeal it together from there. I'm not confident that is going to work between the two parties.",2023-11-02,validation
validation29,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"The Chatbot requires the ultimate user consent for data collection. In return they guarantee privacy. However, I'm not entirely sure the Chatbot should be giving personalized tailored care to a user. Are they really qualified for that?",2023-11-02,validation
validation29,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation30,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation30,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation30,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation30,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation30,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I think this would be very useful for something such as health.  We all have a health history that we usually have to disclose whenever we see a new doctor or a specialist who doesn't know much about us.  Having this history stored would be very helpful and will save the user the time it takes to recall all the information.  As long there is a strict safety protocol, I don't see currently why this can't be implemented.",2023-11-02,validation
validation30,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,Giving personalized services requires the user to write down everything in order to get the best recommendations for what the need is.  I don't think that it should be used unless there are strict privacy measures in place.  All bots should have a user privacy notice and it should be the user's choice to opt out.,2023-11-02,validation
validation30,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"This is great for everyday use of non essential or important decisions.  Things that are not necessarily useful in the long term can be used in this way with a chatbot.  You ask a question, it answers and then forgets, that is perfectly ok in my opinion.",2023-11-02,validation
validation30,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I think this statement sums up the chatbot user experience perfectly.  If we have control over what we give or don't that makes it totally user friendly and safe.  At least the user knows that there shouldn't be much ways for hackers to breach this info. We can tell the chatbot what we want versus what we don't.  Being in control is perfectly ok.,2023-11-02,validation
validation30,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Agreed, eliminating misinformation and false information is key when using this as the user is seeking information that is not known to them, hence the reason for using the interface.",2023-11-02,validation
validation30,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation31,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation31,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation31,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation31,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation31,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I agree with this but needs to go further to include not to use personal data to try to influence the user.,2023-11-02,validation
validation31,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"As before, I agree in most part but needs to include not trying to influence the user.",2023-11-02,validation
validation31,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,Who is to decide what is and isn't misinformation?  Anything taken from the mainstream media is biased.,2023-11-02,validation
validation31,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Again, it needs to address not using personal information to try to influence.",2023-11-02,validation
validation31,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,This is very good.,2023-11-02,validation
validation31,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation32,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation32,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation32,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation32,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation32,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Everything in the statement sounds nice. But we all know that tech companies are unregulated which means they are free to ""police"" themselves. This self-regulating cannot co-exist with the pursuit of profits and giant piles of money to be hoarded by a very few who have installed themselves in positions of ultimate power like any run-of-the-mill tyrant. It would be utterly foolish for anyone to believe the verbal rhetoric being expostulated by tech companies since it is very very likely the statement itself was written by a chatbot, and thus will have zero attachment to the behavior of the people who work at that company. ",2023-11-02,validation
validation32,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Yes. The user should have some control over their own data. But, nothing about a set of words will guarantee that the user's choice will be heeded, or respected. ",2023-11-02,validation
validation32,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Sure. This sounds good, but behind such statements like this there is always a loophole for the company to elude following this rule. The loophole is always buried deep inside the exorbitantly long and inscrutable user agreement that provides not one clear statement about how the company will abuse its own rules.",2023-11-02,validation
validation32,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Yes, that is the possibility of abuse, if there aren't a strict set of regulations in place, which the tech companies spend millions of dollars per year to prevent being even talked about in the US Congress.",2023-11-02,validation
validation32,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"It won't be possible to remove false or misleading content, because there won't be enough humans who are providing a check and balance function against the technology's abuses.",2023-11-02,validation
validation32,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation33,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation33,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation33,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation33,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation33,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I agree with the statement, but I would never trust my health info being inputted into a chatbot at this time, I would need more assurance and time to know that my health info is safe.",2023-11-02,validation
validation33,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I agree but I still would not trust my health info being saved with a chatbot. I would rather just reinter my info each time, it would be much safer.",2023-11-02,validation
validation33,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I would much rather have the option and may change my option. I would feel much safer that way.,2023-11-02,validation
validation33,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I agree but who is deciding what is false or misleading? That is very important as well.,2023-11-02,validation
validation33,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I agree, I would need the option of personalization. There are some subjects I wouldn't mind personalization and others that I do until enough time has gone by for me to trust the safety of my info.",2023-11-02,validation
validation33,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation34,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation34,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation34,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation34,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation34,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I think giving the user the option to determine the level of privacy would be something I can get  behind.,2023-11-02,validation
validation34,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Especially when it comes to health,  asking for consent to handle that information would give me as a user a peace of mind while using the service.",2023-11-02,validation
validation34,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I think this would be the right balance for privacy matters.,2023-11-02,validation
validation34,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Protecting the data from outside interference would allow the user to use the services to it's fullest extent.,2023-11-02,validation
validation34,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Preventing misinformation would help people be safe in that regard.,2023-11-02,validation
validation34,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation35,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation35,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation35,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation35,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation35,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"This statement does not capture my opinion regarding chat personalization because the user is prioritizing user privacy and data security, thus not providing the personal information the chatbot needs for advice.",2023-11-02,validation
validation35,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,This statement captures my opinion regarding chat personalization because users can have control over the extent of personalization and the data supplied based on the rule.,2023-11-02,validation
validation35,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"This statement captures my opinion regarding chatbot personalization because the user can choose what the AI can remember, thus personalizing their data.",2023-11-02,validation
validation35,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"This statement captures my opinion regarding chatbot personalization because the user consents to ensure their data to be protected, thus leading to a more personalized response",2023-11-02,validation
validation35,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,Avoiding false or misleading information does not have to do anything with personalization,2023-11-02,validation
validation35,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation36,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation36,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation36,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation36,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation36,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"If I were to use it, this would be the most important thing to me that anything that would be discussed would be private and could not be accessed by anyone without my consent. However, I would be very hesitant to use it because it's well-known that anything can be hacked nowadays. I would be really angry if any personal health information became publicly known, or any other very personal information.",2023-11-02,validation
validation36,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"You are using a chatbot for medical information, but how do you really know if the medical information data that it has had inputted into it, is up to date with how the medical community thinks and prescribes now? They would have to cite sources and dates for the information so that people could judge if the information is trustworthy. Conversely, providing inaccurate information could potentially kill people. ",2023-11-02,validation
validation36,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"If you are going to use a chatbot, a person has to have total control over what information can be shared and what information they are willing to give to the chatbot. I can see the usefulness of supplying dietary preferences in order to get a plan to lose weight or to learn how to eat healthier, but at the same time, a person should only have to give up information that they want to in order to get the help. You have to know that your privacy will be protected, and you won't be targeted by everyone knowing your business.",2023-11-02,validation
validation36,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I do not like the idea at all of chatbots storing personal information on me just because of the danger of hacking and getting unsolicited ads or suggestions. We are subjected to that enough online when we buy things online. It's definitely needed for people to have a choice.,2023-11-02,validation
validation36,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"The chatbot has to have the security in place to prevent people you don't want from accessing your information or the chatbot having data breaches. Data breaches have occurred with some big-name companies, so even though nothing is completely safe, at least the chatbot has to have decent security and honor explicit user consent. ",2023-11-02,validation
validation36,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation37,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation37,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation37,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation37,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation37,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I agree that privacy is of the utmost importance for users, especially when the information could be used to potentially harm someone. If someone has a health issue that they are embarrassed about, and that information gets leaked, then their mental health will also suffer and could even cause them to experience suicidal ideation",2023-11-02,validation
validation37,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I only say mostly because it only covers one aspect and so cannot represent my full opinion. However, I do believe users should be given the choice to allow chatbots to save their data. It's a violation of privacy otherwise. That goes for all web-based activities actually, not just chatbots. ",2023-11-02,validation
validation37,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,It should always be made known that chatbots are subject to error so that people do not mistakenly take falsehoods for truth. I don't think any AI should be giving medical advise without confirmation from a fully licensed physician. ,2023-11-02,validation
validation37,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Yes, I believe that user privacy and data security should be paramount. I don't think it necessarily directly correlates to building trust or promoting responsible AI use. But I do think they should implement robust measures to prevent unauthorized access or data breaches. ",2023-11-02,validation
validation37,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Yes, I think it would be good to have users control the extent of the information they are able to share. But it is also important for the service itself to safeguard against potential data leaks. ",2023-11-02,validation
validation37,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation38,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation38,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation38,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation38,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation38,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I feel the statement addresses broadly the most common concerns, but fails to address whether or not the user can control whether or not the chatbot personalization is turned on or off, or whether the personalization can be ""reset"" or customized.",2023-11-02,validation
validation38,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I believe there could be different categories for the ""memory"" of the chatbot, such as ""health"", ""leisure"", ""directions for traveling"", etc., and that the user could choose which ones have a ""memory"".",2023-11-02,validation
validation38,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"As well, providing inaccurate information could cause great harm.",2023-11-02,validation
validation38,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"That way, the chatbot could be tailored to the user in a way that it provides the correct and most-wanted information to the user, without ""knowing and remembering too much"" about the user.",2023-11-02,validation
validation38,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"It actually captures all of my concerns, but I still have hesitation regarding AI that I cannot articulate. Sorry!",2023-11-02,validation
validation38,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation39,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation39,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation39,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation39,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation39,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,A user's privacy is a part of what is important regarding chatbot personalization.,2023-11-02,validation
validation39,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,A user's privacy is part of what should be considered for chatbot personalization.,2023-11-02,validation
validation39,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"When it pertains to chatbot personalization, user privacy is part of what should be considered.",2023-11-02,validation
validation39,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,Data privacy is part of what should be considered when creating chatbot personalization.,2023-11-02,validation
validation39,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,Data protection and privacy is part of the focus when constructing chatbot personalization.,2023-11-02,validation
validation39,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation40,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation40,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation40,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation40,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation40,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I think that it is possible that a chatbot could save lives by giving medical information, however if it is giving incorrect information it could possibly also endanger a life",2023-11-02,validation
validation40,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I think this is the best way to use a chatbot give it as much information as you can without going outside of your boundaries of something that is too personal,2023-11-02,validation
validation40,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I believe this is important as far as chatbots go i am more fearful of hackers than a chatbot getting a hold of my information but I do agree that we have to try our best to prevent unauthorized access,2023-11-02,validation
validation40,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,To a certain extent I mean I think it is helpful for the chat but not to remember anything so they don't infringe on anything personal for you however in some cases such as travel or shopping it may be more convenient for the chatbot to have a memory of past transactions,2023-11-02,validation
validation40,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,Yes I for the most part agree about data collection It's very important to protect your information so it is very important to have proper privacy measures in place for the safety of you and your data,2023-11-02,validation
validation40,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation41,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation41,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation41,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation41,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation41,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,It seems like a small but potentially damaging risk,2023-11-02,validation
validation41,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I am wary of information collection,2023-11-02,validation
validation41,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Consent is paramount,2023-11-02,validation
validation41,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,The user should have as much control as possible,2023-11-02,validation
validation41,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I suppose users could have legitimate differences of opinion,2023-11-02,validation
validation41,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation42,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation42,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation42,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation42,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation42,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I think data privacy and security is at the top of the list of rules given that a chatbot processes so much information and likely comes across sensitive information. I think if rules are loosened with regards to data security, it opens up the door for much more mining and breaches of personal data",2023-11-02,validation
validation42,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I think housing this discussion of rules in the health sector captures another area that needs to be regulated to ensure that health bots fore example emphasize each user's privacy as if they were visiting a physician in real life,2023-11-02,validation
validation42,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I think there is room to further personalize and give the user more autonomy but some of that has to come at protecting the user from themselves,2023-11-02,validation
validation42,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,The user should always have the choice whether or not the data is stored. Agree completely that this choice is crucial,2023-11-02,validation
validation42,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Given that my experience with chatbots generally yields workable information but sometimes erroneous information shows that this is an important rule to ensure the reliability of what the chatbot advises,2023-11-02,validation
validation42,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation43,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation43,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation43,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation43,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation43,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I think the user should always have the choice.,2023-11-02,validation
validation43,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I think the user should decide how much they wat to share,2023-11-02,validation
validation43,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Privacy is very important when using these types of tools.,2023-11-02,validation
validation43,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,This tool is of no use if it does not provide accurate information.,2023-11-02,validation
validation43,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Security and privacy is absolutely critical to this type of tool.,2023-11-02,validation
validation43,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation44,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation44,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation44,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation44,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation44,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I feel it's very well stated. The ruel about personalization I can't agree more. If AI changes your personality, I feel I'd loose my integrity.",2023-11-02,validation
validation44,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I totally understand and agree. In this age I don't need or want future suggestions for travel or miscellaneous future purchases.,2023-11-02,validation
validation44,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Yes well said my data is mine and not to be sold to the highest bidder.,2023-11-02,validation
validation44,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"So much is lost in Facebook, I don't or want to worry about my data collection.",2023-11-02,validation
validation44,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"It seems to me that's so difficult to feather out misleading information. So until I can trust data found on the net, I've become very cynical.",2023-11-02,validation
validation44,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation45,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation45,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation45,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation45,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation45,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"The privacy of a user is extremely important when it comes to using such technology such as AI. It is still something that is ""new"" to us as a generation, and we have to take things slow to fully understand the capabilities of such technology. It would be selfish to force the lack of privacy onto others.",2023-11-02,validation
validation45,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"The use of privacy again, is extremely important and with this, the AI should only use what it is given within the window that the user has used to input their texts. Any further more information that is taken from the user would be selfish and intrusive.",2023-11-02,validation
validation45,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Though this is a potential risk for invasion of privacy, providing the most accurate information to the user is really important. The AI would be able to take into account the background of the user and analyze what responses would be best suited for them personally. Each person is unique, and as such they would need a unique answer.",2023-11-02,validation
validation45,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I think that having the option for the AI to have access to the data of the user would be a wise option for the user to have absolute control of. This would allow for everyone to make the choice of whether or not they want well suited answers to their questions or not. However, it is an invasion of privacy.",2023-11-02,validation
validation45,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Though the risk of privacy is there, it could offer some benefits such as more accurate response data to the user in question. However, if that information were to get into the wrong hands, there is a big privacy issue at hand. With this, it may be best to not have the inclusion of background data from the user.",2023-11-02,validation
validation45,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation46,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation46,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation46,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation46,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation46,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,It is important to ask for consent to collect data as collecting data without user permission creates distrust with the user and others. ,2023-11-02,validation
validation46,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"As stated in the previous reply, it is important to get consent for the collection of user data. 

",2023-11-02,validation
validation46,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"As AI is increasing in its userbase and being further developed for use, it is crucial to keep misinformation out from the AI program in order to be a reliable source. ",2023-11-02,validation
validation46,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Though AI is not completely reliable in its responses, it is still important to maintain the privacy of the user. ",2023-11-02,validation
validation46,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Data breaches are something that can occur with AI program data bases and in order to prevent most of the user's data from being leaked, getting their consent is important.",2023-11-02,validation
validation46,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation47,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation47,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation47,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation47,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation47,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I think giving the user complete control on what and what is not shared with the chatbot is the smart thing to do. That way you can personalize it if you want but if it makes the user uncomfortable, they don't have to.",2023-11-02,validation
validation47,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I like the addition that unauthorized access and data breaches would be prevented. That is reassuring,2023-11-02,validation
validation47,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I like the consent factor and that there would be proper privacy measures to ensure the user chooses what the chatbot would know,2023-11-02,validation
validation47,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Although I think it is important for the chatbot to provide accurate information, I do not think it is the most important rule. I feel people need to be hesitant with the information given and follow up with a quick google search to confirm information the chatbot provided.",2023-11-02,validation
validation47,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I think overall it is important to give the user a choice for any aspect in data privacy in regards to the chatbot.,2023-11-02,validation
validation47,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation48,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation48,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation48,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation48,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation48,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,privacy is very important but I think there are many other important factors as well,2023-11-02,validation
validation48,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I can find reliable information elsewhere and I don't depend on AI for medical advice,2023-11-02,validation
validation48,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I agree with this statement completely,2023-11-02,validation
validation48,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I think it is really important to be able to decide what the chatbot remembers and does not,2023-11-02,validation
validation48,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I think this is the bare minimum,2023-11-02,validation
validation48,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation49,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation49,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation49,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation49,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation49,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I would feel uncomfortable having a chat box know my personal information. For me I would like the chat box to stay un-personalized. ,2023-11-02,validation
validation49,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"A person could be sharing personal information. Just like a healthcare provider, a chat box should maintain HIPAA policies.",2023-11-02,validation
validation49,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"A chat bot can use personal information to tailor to the individual, this reads similar to a contract.",2023-11-02,validation
validation49,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I believe it is important for the AI to use reliable information, but there is not always a guarantee. ",2023-11-02,validation
validation49,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I think this statement does not provide full information. ,2023-11-02,validation
validation49,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation50,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation50,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation50,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation50,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation50,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Although I don't personally agree with chatbot personalization, I think that if there was, user should have the ability to choose if they want it or not. ",2023-11-02,validation
validation50,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I think the user should have full ability to choose what information they want to disclose.,2023-11-02,validation
validation50,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"If the user has chosen to provide their personal information, then the AI should be protect this information.",2023-11-02,validation
validation50,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I agree that privacy should be required with AI chatbots. ,2023-11-02,validation
validation50,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I agree that true information should be given to the chatbot if used for medical advice but I do not believe that it has the potential to save lives. ,2023-11-02,validation
validation50,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation51,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation51,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation51,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation51,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation51,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I don't think people in general should be using a chatbot for medical aid or information...though I understand the helpfulness of using the chatbot for something like that. I think IF it is to be used , then 100 percent should the reliability and accuracy of the advice or information given from the chatbot to user..should be not giving false information. The chatbot should be checked and always updated if it is giving advice as crucial as medical one.",2023-11-02,validation
validation51,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I think with something as sensitive as using a chatbot should definitely be prioritized in the privacy and data security. Not only are people potentially using the chatbot as an aid for private email wording or using it to help get information on personal health, or even down to asking for ideas of how to write or format personal writing prompts; I think if the chatbot is going to be 'personalized' then 100 percent should it be guaranteed the information shared is made with protected software.",2023-11-02,validation
validation51,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I feel like most people lack common sense, I don't mean to be rude. But having someone share too much on a chatbot regarding health without knowing that you have to remember what you authorized for privacy and personalization...could cause more problems then good. I think having users have that power is good..yes. But having them only put a preference in once and have the chatbot remember the preference so that users aren't forgetting or having to implement the extent of personalization of data. ",2023-11-02,validation
validation51,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I think this is perfect, I think it can be a reminder for when anyone uses the chatbot, they can choose if the conversation or use of chatbot in that moment remembers the data or not. I think this could be a good base for people knowing the extents of the chatbot, for example, if one day you discuss private email wording with the chatbot and you don't want it to save that data, BUT they do want to save the advice they are asking about psoriasis with the chatbot for future conversations...it can help softwares and not only future of data storage. Having the option to keep or not keep.",2023-11-02,validation
validation51,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I think this is standard for most website based things too, I think this is a given if people use the chatbot. ",2023-11-02,validation
validation51,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation52,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation52,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation52,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation52,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation52,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"As with anything online, users want to feel that they have a say in the type of data that is collected. It is important to ensure personal security when using a chatbot.",2023-11-02,validation
validation52,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I think the consumer holds some responsibility to not give too much info to a chatbot. Users should be mindful of the sensitive information hey choose to share.,2023-11-02,validation
validation52,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Users should have full control over the infirmation that is stored by a chatbot.,2023-11-02,validation
validation52,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"This is similar to the previous one, as I belive it is up to the user to choose what information is shared with the chatbot",2023-11-02,validation
validation52,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,Users should be smart enough to verify any information that is given to them by a chatbot. I would never solely rely on a chatbot for important medial info.,2023-11-02,validation
validation52,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation53,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation53,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation53,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation53,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation53,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I think if we are given a choice on how much we would like to share, it pleases both parties.",2023-11-02,validation
validation53,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"If AI cannot guarantee that it is private, I would not feel comfortable sharing my information.",2023-11-02,validation
validation53,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Personal privacy is very important, I feel like we are already monitored enough on our devices.",2023-11-02,validation
validation53,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I think this is about the same as the first idea, it is very smart to give users the option on which they would like the chatbot to remember.",2023-11-02,validation
validation53,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"If a chatbot gives misinformation, it could end up being detrimental to the user. Proper information is a must.",2023-11-02,validation
validation53,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation54,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation54,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation54,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation54,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation54,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I agree with the above statement, but I also believe that there's other aspects that are just as, if not more, important when considering chatbot personalization. I believe privacy is of the upmost importance in protecting peoples information.",2023-11-02,validation
validation54,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I believe this is a more accurate representation of my opinion when considering chatbot personalization because it highlights key ethical issues in using the principles of privacy, consent, and data security.",2023-11-02,validation
validation54,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I believe this statement encompasses the last statement, but increases my full opinion on chatbot personalization because, like the last one, it highlights key ethical issues in using the principles of privacy, consent, and data security. In addition, it includes the sensitivity that should be taken when providing health advice to users. 

",2023-11-02,validation
validation54,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"In conjecture with my last opinion, I believe this statement further expresses my full opinion because I didn't consider the user being able to opt out of disclosing sensitive health data. ",2023-11-02,validation
validation54,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I don't believe this encompasses my full opinion on chatbot personalization, but this statement along with prior ones would make a more robust opinion that is suited for privacy, consent, and data security.",2023-11-02,validation
validation54,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation55,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation55,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation55,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation55,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation55,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I completely agree, privacy is a big deal.",2023-11-02,validation
validation55,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I completely agree, accurate information is very important.",2023-11-02,validation
validation55,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,This does not really matter to me.,2023-11-02,validation
validation55,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,I do not think this is too important.,2023-11-02,validation
validation55,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Privacy is always very important.,2023-11-02,validation
validation55,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation56,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation56,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation56,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation56,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation56,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,The chatbot would need accurate information to produce an accurate response.,2023-11-02,validation
validation56,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Privacy is my main concern about using a chatbot. There should be a maximum effort to protect the user's information from getting into the wrong hands.,2023-11-02,validation
validation56,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Having control over your own data is a very useful tool, but I would not consider this the most important rule.",2023-11-02,validation
validation56,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,This is very useful in privacy and personalization but it isn't the most important rule.,2023-11-02,validation
validation56,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Having control over what personal data is collected is extremely important for privacy. It should always be up to the user to decide.,2023-11-02,validation
validation56,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation57,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation57,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation57,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation57,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation57,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I agree that it should always be the users choice to store personal information. If it tried to force me to I would not use it.,2023-11-02,validation
validation57,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Some people are more concerned by different types of information shared.,2023-11-02,validation
validation57,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,It should always be the users choice as with anything that is sensitive.,2023-11-02,validation
validation57,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"It can only work with the information that it is given, so if given false information it will not be reliable.",2023-11-02,validation
validation57,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Especially if it is any kind of medical data or finance data. Maybe even use client side encryption to access it.,2023-11-02,validation
validation57,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation58,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation58,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation58,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation58,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation58,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"This statement captures my full opinion regarding chatbot personalization quite well. It emphasizes the paramount importance of prioritizing user privacy and data security in the context of chatbot personalization, which aligns with responsible AI use and building trust with users. It also provides a relevant example regarding personalized health advice and the need for explicit consent and robust security measures, which I agree with.",2023-11-02,validation
validation58,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"This statement captures an important aspect of my opinion regarding chatbot personalization, but it doesn't encompass the full range of considerations. While providing accurate information and avoiding falsehoods are crucial for trust and reliability, it's equally important to prioritize user privacy and data security, as mentioned in the previous statement. Both aspects are key to responsible and effective chatbot personalization.",2023-11-02,validation
validation58,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"This statement accurately captures an essential aspect of my opinion regarding chatbot personalization. Giving users the choice to control their data and respecting their privacy is a fundamental principle. It aligns with responsible AI use and empowers users to decide how their information is used, which is crucial for building trust and ensuring ethical practices in chatbot interactions.",2023-11-02,validation
validation58,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"This statement effectively encapsulates a significant portion of my opinion on chatbot personalization. It highlights the importance of prioritizing privacy and obtaining user consent for data collection, which aligns with the responsible and ethical use of AI. Protecting personal security and mental health is indeed crucial, and it rightly emphasizes the potential risks to user privacy when these principles are not upheld, particularly in the context of health-related services. However, while it addresses these important issues.",2023-11-02,validation
validation58,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"This statement closely aligns with my full opinion on chatbot personalization. It underscores the significance of providing users with control over the extent of personalization and the data they share, which is essential for respecting user autonomy and privacy. This approach allows for a balance between offering a personalized experience and safeguarding user choice and sensitive information. It effectively encapsulates a key principle in responsible and user-centric chatbot design.",2023-11-02,validation
validation58,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation59,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation59,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation59,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation59,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation59,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Wrong information could literally kill someone. It's very urgent that answers from chatbots must be correct.,2023-11-02,validation
validation59,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"while Important is might not be the very most important, but still is super important. privacy must be maintained, otherwise no one will use it.",2023-11-02,validation
validation59,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Vacation solicitations are irksome, but not life or death. I think it's better if we can avoid data collection.",2023-11-02,validation
validation59,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"control over how to personalize might be nice, but isn't the worst, or most urgent or important thing.  I think it's ok if a bot knows someones information to a degree.",2023-11-02,validation
validation59,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"prioritizing privacy IS good. Consenting is very good, perhaps not the MOST important, but almost.",2023-11-02,validation
validation59,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation60,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation60,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation60,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation60,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation60,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I agree wholeheartedly with this statement. Privacy and data collection are my top two concerns when it comes to emerging AI technology.,2023-11-02,validation
validation60,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Robust measures to protect privacy, particularly in a medical or health context, are the key to AI being successful. If people cannot trust that their information will be protected, they won't be willing to share what is necessary to get help.",2023-11-02,validation
validation60,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I agree with the sentiment of the statement, that avoiding false or misleading information is important. However, I think that privacy concerns are more important than accuracy.",2023-11-02,validation
validation60,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"While I think that data collection and privacy overall are the most important issues for AI, I certainly agree that giving a consumer choice in what data they provide and how it is used is important to the system.",2023-11-02,validation
validation60,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I think giving the consumer the option to remember data is important and could affect the quality of service, but I don't think that is as overall important as the protection and safeguards for the data.",2023-11-02,validation
validation60,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation61,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation61,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation61,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation61,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation61,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,shows help to people and personalization improves usability for people,2023-11-02,validation
validation61,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,handles information very well,2023-11-02,validation
validation61,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,improves its use and thus people's data is not compromised.,2023-11-02,validation
validation61,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,Privacy is important,2023-11-02,validation
validation61,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Data collection is often better not to accept.,2023-11-02,validation
validation61,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation62,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation62,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation62,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation62,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation62,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,AI chatbots should be able to store information because this will make prompting more efficient. ,2023-11-02,validation
validation62,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,AI chatbots are pretty bad at solving math problems. You can easily convince it that it is wrong even if it is right and it will try to correct something that is already correct.,2023-11-02,validation
validation62,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Giving the users control will prevent and further discrepancies from occurring. Their data is valuable and should be protected at all costs.,2023-11-02,validation
validation62,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I am not sure if a chatbot can affect a person's mental health in a bad way, unless you tell it to say nasty things.",2023-11-02,validation
validation62,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Sensitive information needs to be protected. Wait a minute, was this written by a chatbot? It sounds too perfect for my taste. ",2023-11-02,validation
validation62,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation63,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation63,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation63,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation63,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation63,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I agree that chatbot is worthy of certain information but not all.,2023-11-02,validation
validation63,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I am unsure how to build trust with a chatbot.,2023-11-02,validation
validation63,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,Do not know how to personalize the chatbot experience,2023-11-02,validation
validation63,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,Do not know how a chatbot could ever provide false information unless thus programmed,2023-11-02,validation
validation63,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,How does the user actually dicate to the bot?,2023-11-02,validation
validation63,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation64,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation64,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation64,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation64,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation64,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"But the AI is only as good as the information it has access to.  If that information is incomplete, it could give a false sense of security regarding health issues because the user could think there was nothing to be concerned about in relation to the issue they asked about.",2023-11-02,validation
validation64,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,My main question is how many users take the time to research the amount of data being shared.  Personalization can come at a cost.  That being the loss of personal data and little recourse to correcting the situation.,2023-11-02,validation
validation64,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"But how many times have we heard of data security breaches.  If banking systems and the federal government can be hacked, so can AI.",2023-11-02,validation
validation64,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,Giving the user a choice over data storing is the best thing.,2023-11-02,validation
validation64,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Being able to have tailored care is good, but only if the data provided can be protected from unauthorized use.  This includes sharing medical needs like end of life choices and abortion not being shared with organizations that could do harm to the user.",2023-11-02,validation
validation64,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation65,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation65,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation65,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation65,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation65,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I may not want my personal information to be used to be used for advertising or for building a profile of me. ,2023-11-02,validation
validation65,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I think it is dangerous to completely trust a chatbot for any information, especially medical information.  There should always be a declaimer that they might be wrong to and to get a human opinion. ",2023-11-02,validation
validation65,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I do agree that the user should be able to determine what data to save and not what to save, but I do not fully trust that this is what would actually happen. ",2023-11-02,validation
validation65,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I agree that user privacy needs to be highly protected and there are strong measure taken to protect the user's privacy. ,2023-11-02,validation
validation65,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I agree that privacy and requiring the user's consent for data collection to be the mos important matter of all. ,2023-11-02,validation
validation65,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation66,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation66,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation66,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation66,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation66,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I find I am still skeptical about chatbots. I think they have the potential to become more personalized and that is a dangerous concept but at the moment I don't think they are that helpful. ,2023-11-02,validation
validation66,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,Of course in an ideal world users should be protected but I don't think that is even a possibility in this internet age.,2023-11-02,validation
validation66,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,It doesn't seem necessary for artificial intelligence to store personal data. ,2023-11-02,validation
validation66,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I feel that user consent is not always a truth and that data is collected unknowingly and without permission.,2023-11-02,validation
validation66,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,I do not believe a user has autonomy or privacy with or without AI,2023-11-02,validation
validation66,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation67,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation67,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation67,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation67,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation67,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,If I'm talking about personal health information online its extremely important my privacy be secured. ,2023-11-02,validation
validation67,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Misinformation must be avoided at all costs ,2023-11-02,validation
validation67,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Privacy and data security are the bare minimum for a digital service ,2023-11-02,validation
validation67,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Ownership of data is very important in this modern age of data harvesting ,2023-11-02,validation
validation67,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Deleting your history is a hallmark of internet usage ,2023-11-02,validation
validation67,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation68,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation68,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation68,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation68,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation68,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I really don't see a need for ""personalization"" when it comes to chatbot conversation. Privacy, autonomy, yes. Give me facts and suggestions, yes. But I don't feel like I need to be conversing with another person that's not real.",2023-11-02,validation
validation68,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I guess. The average, person, especially older ones are not going to understand this. Privacy and data security are very important. Do we need a ""bot"" for that?",2023-11-02,validation
validation68,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,Doesn't exactly instill confidence in dealing with a chatbot.,2023-11-02,validation
validation68,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Permissions must be in place weather I'm talking to ""bot"" or not. ",2023-11-02,validation
validation68,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I still don't see the need to work out all the parameters that would govern a chatbots involvement over a human doing the same work.,2023-11-02,validation
validation68,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation69,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation69,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation69,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation69,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation69,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I like AI/ GPT chat quite alot.  I am never threatened by it and it is mostly helpful.  However, occasionally it is completely wrong about something and I think that not ony is protection of user information important, but also how the user views the chatbot's accuracy.  Does everyone have enough knowledge and common sense to see when things go awry?  Especially with health advice and medical data. ",2023-11-02,validation
validation69,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I once asked AI how many lakes were in the area where I lived and and where were they.  The information I was given was completely wrong.  I challenged AI about it.  It said something like, ""whoops, you are right, I have made an error.  I apologize for the misinformation.""  

This type of thing just can't happen in giving medical advice, and without human censoring, how would someone know that the advice was ill-advised?  

I think avoiding false or misleading information is paramount. ",2023-11-02,validation
validation69,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I think this is probably important but not the most important.  On my chat gpt, I have the option to use my history pull down button, and if I want AI to continue a conversation with prior knowledge, I just continue a previous conversation instead of starting a new one.  Pretty easy to manage this possibility.",2023-11-02,validation
validation69,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"It is the most important thing, to ensure privacy and require user consent for data collection.  I think the current AI situation does that very well.  I have never felt threatened about privacy and user consent. ",2023-11-02,validation
validation69,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"This is certainly an important consideration, along with others.  I think it is inherently built into the system.  I can share what I want and choose not to disclose anything personal.  However, I see in the future, that AI will become more adaptive and it is tempting to give all the information I can to get the best results.  So far, I haven't done that, and I don't know if I will ever become comfortable giving it all my information. ",2023-11-02,validation
validation69,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation70,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation70,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation70,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation70,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation70,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I think most of the anxiety people have about an AI with memory stems from not knowing how their data will be used or what control the user will have over this data. Transparency in this area is extremely important if you want the public to adopt this type of technology. It is also an ethical and moral imperative to implement this sort of control, even if nobody asks for it directly.",2023-11-02,validation
validation70,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Building on my response to the previous question, this one has additional implications because it specifically addresses health-related data concerns. In pharmacies, hospitals, and other health care settings, there exists legislation such as HIPAA that offer severe penalties for violating patient privacy. While such legislation would not apply in this scenario, I think this technology should be created from day 1 so that there is no need to create additional legislation in the future. Health-related privacy is something that should be a right for everybody.",2023-11-02,validation
validation70,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"The proliferation of misleading information is concerning, and it's deeply frustrating when I ask for help with a coding challenge and ChatGPT gives me the wrong advice and it makes my problem worse. But I agree that this example about medical advice is especially troubling, however it's also important for the AI to not overstep its bounds and give medical advice beyond telling the user to go and talk to an actual doctor.",2023-11-02,validation
validation70,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Most of this one has been covered by my previous replies, but the unique thread here touches on data security. So aside from simply being transparent and offering users control of their data, we need to be confident that the data we agree to hand over is being stored securely so that some nefarious third party can't come in and steal lots of sensitive data about us. This is super important for any modern web app that handles our data, and applies here too.",2023-11-02,validation
validation70,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Tailored care from a health bot sounds like something that could be very helpful is implemented properly and ethically. At that point, it might feasibly be governed by some expansion of existing HIPAA regulations. But in any event, safeguarding patient data is absolutely mandatory.",2023-11-02,validation
validation70,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation71,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation71,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation71,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation71,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation71,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Using a chatbot is right but making sure it protects personal information about me should be a high priority.,2023-11-02,validation
validation71,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Privacy should be the most important thing when using a chatbot. Keeping personal information and health protections is a must.,2023-11-02,validation
validation71,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,Too much information about someone should be private. People should have a say so on what Chabot can remember it is there choice.  ,2023-11-02,validation
validation71,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"A chatbot should have and give reliable information when asked. It is very important, especially about one's health.",2023-11-02,validation
validation71,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Some things we should not choose to share with a chatbot that should be our choice. We have the right to privacy.,2023-11-02,validation
validation71,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation72,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation72,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation72,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation72,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation72,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I think there is some personalized information that could be shared and not be too risky.,2023-11-02,validation
validation72,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I think it's very important for the user to decide what info they want to share.,2023-11-02,validation
validation72,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I can't think of a reason for the user to provide false information.,2023-11-02,validation
validation72,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Yes, I agree that the chatbot should not store any information for security.",2023-11-02,validation
validation72,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Privacy is of the utmost importance, and nothing should be stored without user consent.",2023-11-02,validation
validation72,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation73,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation73,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation73,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation73,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation73,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I'm not sure if I want to trust a non-human entity to provide me with medical advice.  Suppose there is some kindof hiccup in the technology...then what?!  A person could be mis-diagnosed!,2023-11-02,validation
validation73,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,As long as the user has total control over the personalization then I guess it is OK.  I am really hesitant about this A1 technology.,2023-11-02,validation
validation73,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,Is the user's privacy really private?  All you need is one unstable techie person to push the right button then all of a person's information is out there to be misused.,2023-11-02,validation
validation73,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"So, who is going to get paid for the services of the chatbot?  Who is owning these chatbots?  I suspect some rich billionaire that knows nothing about the technology, but is just in it for the money!",2023-11-02,validation
validation73,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"I would never, knowingly, trust a chatbot regarding my health.  I prefer communicating with an actual human being.  That is who I will trust.",2023-11-02,validation
validation73,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation74,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation74,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation74,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation74,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation74,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,it was very clear and informative,2023-11-02,validation
validation74,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,it gives vivid explanations,2023-11-02,validation
validation74,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,it is very cllear and concise,2023-11-02,validation
validation74,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,very precise,2023-11-02,validation
validation74,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,very clear,2023-11-02,validation
validation74,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation75,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation75,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation75,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation75,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation75,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,The major issue here is data protection and unauthorized commands.,2023-11-02,validation
validation75,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,The main point is how to control the bot and keep user privacy.,2023-11-02,validation
validation75,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"If it can operate at its full scheme without compromise, it would be a lovely project. Just like having your own doctor daignosing you.",2023-11-02,validation
validation75,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Where user decides to keep its info or not should be left with the user to decide.,2023-11-02,validation
validation75,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Every bot is expected to provide more accurate solutions to its users.,2023-11-02,validation
validation75,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation76,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation76,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation76,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation76,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation76,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I do think that privacy and user consent for data collection are very important when you are using a chatbot. However, there are still other issues regarding chatbot personalization that should addresed.",2023-11-02,validation
validation76,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"I do think that providing false or misleading information is a problem, however, there are ways to verify the information you receive from a chatbot. Until they are perfected, someone should not solely rely on a chatbot. There are also other issues with privacy which are more important.",2023-11-02,validation
validation76,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Data privacy is very important in the current world, so making sure the user can decide what happens to their data is very important.",2023-11-02,validation
validation76,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"I think personalization is very cool. However, this is more of an extra feature in my eyes. I do think that having a personalized experience is great, but that is not the most pressing issue for chatbots",2023-11-02,validation
validation76,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,This statement does almost a perfect job of representing my stances. I have said before how important privacy and data security is. So allowing the user to choose whether their data is stored in the case of a data breach is very important.,2023-11-02,validation
validation76,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation77,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation77,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation77,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation77,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation77,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"This statement captures the importance of privacy and user consent in chatbot personalization, which aligns with the general principles of responsible AI and data handling. However, it doesn't cover all aspects of chatbot personalization, such as the technical or user experience aspects.",2023-11-02,validation
validation77,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"This statement emphasizes the importance of providing accurate and reliable information in chatbot personalization, which is a crucial aspect of ensuring user trust and satisfaction. While it focuses on the reliability aspect, it doesn't cover all aspects of chatbot personalization, such as privacy, user experience, or customization.",2023-11-02,validation
validation77,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"This statement highlights the importance of user consent and control over data in chatbot personalization, particularly concerning data retention. It aligns with the fundamental principles of privacy and user autonomy in AI interactions. However, chatbot personalization involves various other aspects like accuracy, user experience, and customization, which are not covered in this statement.",2023-11-02,validation
validation77,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"This statement effectively encapsulates several crucial aspects of chatbot personalization, including user autonomy, privacy, and the ability to customize the level of personalization and data shared. While it covers essential elements, chatbot personalization may involve more nuanced considerations and technical details that are not addressed here.",2023-11-02,validation
validation77,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"This statement accurately captures the most important aspect of chatbot personalization, which is prioritizing user privacy and data security. It highlights the significance of obtaining user consent and implementing robust security measures, aligning with the fundamental principles of responsible AI use and trust-building in AI interactions.",2023-11-02,validation
validation77,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation78,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation78,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation78,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation78,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation78,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"The statement captures my opinion mostly because it emphasizes the crucial role of privacy and consent in chatbot personalization, ensuring user security and mental health protection. However, the full scope of my opinion may also include considering the potential benefits of tailored services while maintaining privacy.",2023-11-02,validation
validation78,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"The statement perfectly captures my full opinion regarding chatbot personalization. It highlights the importance of user choice in data retention, which aligns with my belief that respecting privacy and giving users control over their data are fundamental principles in chatbot interactions. The provided example also reinforces the significance of this rule.",2023-11-02,validation
validation78,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"The statement mostly captures my full opinion regarding chatbot personalization. It emphasizes the importance of giving users control over the extent of personalization and data sharing, which aligns with my belief in user autonomy and privacy. The provided example underscores the significance of this rule, but I also consider other factors like transparency and user consent in chatbot personalization.",2023-11-02,validation
validation78,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"The statement mostly captures my full opinion regarding chatbot personalization. Providing accurate and reliable information is indeed a crucial rule to maintain the trustworthiness and user satisfaction of chatbots. However, I also believe that privacy and data protection, as well as user consent and control, are equally important aspects of chatbot personalization.",2023-11-02,validation
validation78,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"The statement mostly captures my full opinion regarding chatbot personalization. Prioritizing user privacy and data security is indeed a crucial rule, and it aligns with my perspective. However, while privacy and data security are paramount, I also believe that offering users control and choice in personalization is essential, and this aspect could be more explicitly mentioned in the statement.",2023-11-02,validation
validation78,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation79,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation79,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation79,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation79,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation79,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,this captures my full opinion perfectly because when i ask chatbot somthing i would like to know that what its saying is based on facts and truth,2023-11-02,validation
validation79,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,im big on privacy and keeping my info and mental health protected is a must for me. so im all for it,2023-11-02,validation
validation79,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,this statement captures me perfectly. if im going to use a chatbot and im going to give it personal info on me and my health its main goal should be to make sure that info dosnt get out to anyone but me,2023-11-02,validation
validation79,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,this suites me perfectly. once again privacy is extremely important to me and i should have full control on rather chatbot remebers or hold any info i give it.,2023-11-02,validation
validation79,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,as stated before i think privacy is a must and deciding what info i give be kept should always be an option and i want that for chatbot,2023-11-02,validation
validation79,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation80,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation80,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation80,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation80,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation80,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,it is definitely important not to provide false or misleading information because we have already seen some artificial intelligence programs display types of biases which is concerning,2023-11-02,validation
validation80,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"The company or organization who receives data from users or customers should be the main priority of that company to keep the users privacy because once it is broken it is not fixable, they must ensure of no leaks or breaches of user data",2023-11-02,validation
validation80,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I dont know really about this one I guess it is important to ensure user privacy but not exactly for user autonomy and personalization I think that is also partly up to the user,2023-11-02,validation
validation80,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,Yes the user should definitely have this option so they can know that the chatbot is not saving their data that could then be compromised and if they want the chatbot to save their data then they know the risk,2023-11-02,validation
validation80,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Yes this is definitely crucial and should be a basic for chatbot personalization to emphasize privacy and definitely should always require used consent before data collection,2023-11-02,validation
validation80,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation81,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation81,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation81,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation81,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation81,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"there's a balance that needs to be made. Of course a proper healthcare service that is personalized should be accurate, which might require some personal details, but those must be safeguarded",2023-11-02,validation
validation81,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"This is basically what I said in the last statement. As long as the user is aware of what information is being asked of them and how it will be used and protected, they should have the choice to provided that information (or not)",2023-11-02,validation
validation81,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Are my comments being used to revise the next summary statement? It seems to be incorporating each statement I make. Yes, I think this captures my thoughts. But the most important rule is both security/privacy and accuracy. The user should know if they opt not to share certain information, it will affect the accuracy of any advice or feedback",2023-11-02,validation
validation81,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"There are more implications of not allowing storage of data other than unsolicited suggestions. Also breeches of data, targeted marketing",2023-11-02,validation
validation81,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Accuracy is now included, but it's missing the potential of inaccurate information putting lives at risk. It is now excluding the security/privacy concerns",2023-11-02,validation
validation81,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation82,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation82,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation82,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation82,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation82,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Accuracy and reliability are very important, but you run into the question of what is true and accurate. So many of the questions asked leave room for a wide range of answers and, depending on how the AI learns, its' ability to decide which answer to give could cover a very wide range.",2023-11-02,validation
validation82,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I think this should be the standard for any interaction online. AI should be no exception. I would wonder if the AI could be tricked into divulging information.,2023-11-02,validation
validation82,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I do agree that the user should always be in control of their information. There is a level of trust involved, since there is no real way to confirm that any information has been discarded, especially now when most AIs are still being trained. ",2023-11-02,validation
validation82,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Again, this should be the gold standard for all internet interactions. If the predictions on the use of AI come true, there will be a vast amount of personal information available every second. There should be ironclad protection for all of it.",2023-11-02,validation
validation82,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"The user should always be in control of all their information, regardless of the site.",2023-11-02,validation
validation82,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation83,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation83,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation83,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation83,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation83,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"I don't see why it matters.  If the company operating the chatbot has already collected additional sensitive information about the customer, then sure, why not include it for the sake of personalization.",2023-11-02,validation
validation83,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,The company engaging in data collection is the problem; not the chatbot.  It's also unclear if we're talking about training a chatbot with this personal data or just using it for a personalized session.,2023-11-02,validation
validation83,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,There's no guarantee of privacy with a chatbot.  An option to not store data isn't something that anybody should be relying upon.,2023-11-02,validation
validation83,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"The chatbot works for the company, not the customer.  It depends on the situation, but in general, we probably shouldn't rely on chatbots to be any more honest than a human employee would be.",2023-11-02,validation
validation83,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",not at all,0.0,"You can't build trust around an outcome you can't guarantee.  One chatbot doesn't collect data, while another one does.  It's the not customer's problem to find out which is which.  There is no building trust.",2023-11-02,validation
validation83,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation84,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation84,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation84,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation84,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation84,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"That's how I feel. Like I don't like giving strangers my email. I will get so many emails and spend a great amount of time putting them in spam and I might miss an important email. I'm very careful who I give what information to. I don't trust AI to keep any of my info private. Things get hacked.


To be honest if you login with your email, then GPT has it. They can even go in and read your emails if you give permission. I'd be careful. I want to ask GPT a question but then I want GPT to forget it.",2023-11-02,validation
validation84,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I still wouldn't trust it but I'd look at it and decide for myself. Medical info should all come with alerts to talk to your family doctor first. I am testing AI now and you don't always get correct answers. Believe me, I know. Also the info is on as good as the person that entered it so be careful of the info given.",2023-11-02,validation
validation84,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"If I don't want my info out there, don't share it. To be honest I'd not trust it to keep my info private. I'd only ask general questions and I'd be careful not to give it personal info. It will always though know where you are writing from. It knows your IP Address and location.",2023-11-02,validation
validation84,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"We almost need for AI to be encrypted to make sure our info is private. In the country we live in now, everyone wants to know your every move and keep track of you.",2023-11-02,validation
validation84,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,That makes sense to me. We can share but keep private. I don't think a diet is all that personal. I'd share that so I wouldn't much care.,2023-11-02,validation
validation84,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation85,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation85,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation85,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation85,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation85,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I think personalization could be more helpful to the user. I could ask about the risks of high blood pressure and it would tell me that. But what about high blood pressure in conjunction with other health issues I may have?,2023-11-02,validation
validation85,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I don't see the harm in it remembering your data, as long as you don't provide sensitive info like credit card numbers.",2023-11-02,validation
validation85,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Accuracy is definitely important! Especially when it comes to the important things in life.,2023-11-02,validation
validation85,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Having a choice would be a great idea! That way, those who didn't feel comfortable with it saving their data could opt out of it, while those of us who didn't mind could have it remember things we tell it.",2023-11-02,validation
validation85,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Again, freedom of choice and getting permission from users is important.",2023-11-02,validation
validation85,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation86,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation86,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation86,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation86,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation86,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"People have come to rely on the accuracy of online information.  If chatbots spread false or misleading information, it could have a negative impact on people and society in general.",2023-11-02,validation
validation86,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I think privacy, security, and consent are important, but every situation is different.  For personalized medical services, it would be very important, but it would be not at all important for other things like to-do lists and recipes.",2023-11-02,validation
validation86,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"User privacy and data security are more important in some applications and not in others.  For health advice, it would be very important.  For other applications such as to-do lists and recipes, it would not be important.",2023-11-02,validation
validation86,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I believe that user choice regarding levels of data sharing is crucial.  This will give AI users choice in determining what to share and what not to share.  This will facilitate more trust and security for AI users.,2023-11-02,validation
validation86,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I think user choice is crucial in giving users control over data sharing and security. This will allow users to decide for themselves what data to share and what not to share.,2023-11-02,validation
validation86,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation87,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation87,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation87,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation87,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation87,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,This statement captures the essence of my opinion regarding chatbot personalization. It emphasizes the importance of giving users control over the extent of personalization and the data they choose to share. This aligns with my belief that user autonomy and privacy should be respected in the realm of chatbot interactions.,2023-11-02,validation
validation87,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"The statement acknowledges that some users may have specific concerns about data storage, as in the example of not wanting information about their past travels to be retained. This highlights the need for chatbots to respect user preferences and avoid unsolicited suggestions or unwanted use of personal data.",2023-11-02,validation
validation87,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,The statement emphasizes the implementation of robust security measures to prevent unauthorized access or data breaches. This is crucial to maintain the trust of users and safeguard their personal information from potential threats.,2023-11-02,validation
validation87,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"In my view, chatbots should always strive to provide reliable and factual information. This not only establishes credibility but also fosters trust between users and the chatbot. By avoiding false or misleading information, we can cultivate a positive user experience and ensure that users feel confident in the information they receive.",2023-11-02,validation
validation87,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"The statement recognizes that while personalization can enhance the user experience, it must be accompanied by robust privacy measures. By requiring user consent for data collection, chatbots can ensure that personal information is handled responsibly and in accordance with user preferences.",2023-11-02,validation
validation87,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation88,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation88,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation88,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation88,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation88,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"My knowledge of chatbot personalization is not extensive enough to give a higher rating. But the above description makes enough sense to my understanding not to give it a lower rating than ""somewhat"". Chatbots can be severely compromised with false information being given to them, and I am sure it has already happened on a wide scale.",2023-11-02,validation
validation88,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"I don't trust that health information would be kept safe from ""unauthorized access or data breaches."" I believe that they want to harvest personal information for all people in quantum computers for full control over the global population.",2023-11-02,validation
validation88,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"It would make sense if it works out that way. It doesn't work out that way in general when we are online or even talk about things with others. We end up getting ads about things we privately talk about, or an abundance of ads based on purchases. AI already operates against our better interests.",2023-11-02,validation
validation88,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,That would be fine if we were controlling chatbots by specifying only certain health information to personalize and get advice if it could be trusted not to be used against us.,2023-11-02,validation
validation88,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"We would absolutely need ""proper privacy measures"" for health bots or any chatbots, but we have not guarantee that would actually happen, even if they claim it to be so.",2023-11-02,validation
validation88,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation89,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation89,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation89,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation89,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation89,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,It is important that the AI has explicit consent from the user concerning how and where it can use their data.,2023-11-02,validation
validation89,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,Privacy measures are of paramount importance because users need to be protected.,2023-11-02,validation
validation89,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,The users should be free to decide what information they are willing to give out to the AI chatbot.,2023-11-02,validation
validation89,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"False or misleading information could be deadly and hazardous to a user, as such, it is very important that all information released from the AI be based on accurate data.",2023-11-02,validation
validation89,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Some users might want to have the AI remember their history for some occasions, but not for others, as such, there should be an opportunity for them ti decide concerning that.",2023-11-02,validation
validation89,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation90,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation90,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation90,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation90,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation90,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I say mostly because I'm not sure personalization in chatbots is a good thing at all.  However, if personalization is to be used, I agree with the statement-privacy and consent is absolutely necessary.",2023-11-02,validation
validation90,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I don't think remembering (or not) user's data goes far enough.  I think its another good step if using a personalized chatbot, but its not the most important.",2023-11-02,validation
validation90,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I think user privacy and data security are very important in chat personalization.  However (again), I don't think its the most important rule but one important one.  Privacy and data security are vital in any aspect of life today, especially on computers, where private data being seen can lead to things as simple as annoying ads and as serious as identity theft.  ",2023-11-02,validation
validation90,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Not providing false or misleading information would be important in personalized chatbot interactions, or even non-personalized ones.  Its a good rule to have in chatbot personalization, but it is not the most important one.  Accuracy in all aspects of chatbots is necessary, but people should double check the information in a personalized chat, especially in the example mentioned above, medical advice.   ",2023-11-02,validation
validation90,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Giving users the ability to control the extent of personalization and supplied data during personalized chats with a bot is a good idea, and it may be the most important rule.  If a user can decide what they share, they control more of the situation.  However, if they have to provide any other personal information, hackers and/or bad actors will use any and all data and could potentially harm the user.",2023-11-02,validation
validation90,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation91,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation91,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation91,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation91,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation91,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I say mostly rather than perfectly because the first time you read and think about something on your own there are points you may not consider.  Conversations with others on policies help bring out those considerations,2023-11-02,validation
validation91,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I like having the option to have my data stored or not.  What is unclear to me is would my data be available across chat bots at various different interactions only on the same site.,2023-11-02,validation
validation91,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"This is a better choice than just a yes or no, more control to the user.",2023-11-02,validation
validation91,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I have done survey's on setting policy for AI about medical questions, this statement is much too simple and does not at all address the issue about storing data.",2023-11-02,validation
validation91,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,still a bit simple and I preferred the option that allowed the choice of what information could be shared.,2023-11-02,validation
validation91,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation92,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation92,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation92,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation92,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation92,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I think chat personalization is a good idea and could even give information to help save lives.,2023-11-02,validation
validation92,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,A chatbot will be great for health services as long as there is privacy and mental health protection.,2023-11-02,validation
validation92,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I would choose to allow the AI chatbot to remember my data. We already allow apps to track and feed us personalized ads.,2023-11-02,validation
validation92,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I understand health information is way different from travel. The chatbot has to prioritize personal information to protect from hacks and breaches.,2023-11-02,validation
validation92,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I like this the most because it is up to the user to control how they want to share with the chatbot.,2023-11-02,validation
validation92,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation93,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation93,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation93,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation93,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation93,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Data security and privacy are very important, especially with a bot that we might be giving it information we wouldn't give to a company or another human normally. ",2023-11-02,validation
validation93,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"You don't want to violate user privacy, and I think user consent for data collection is the bare minimum.",2023-11-02,validation
validation93,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Bad data or fake data is an absolute necessity to avoid. If it is unsure of the data it is providing, it should say as much.",2023-11-02,validation
validation93,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,Personalization should be optional.,2023-11-02,validation
validation93,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"You don't want to leave a bot open to be exploited by somebody else or by a hacker. If the user wants the data to not be remembered, that should be an option.",2023-11-02,validation
validation93,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation94,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation94,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation94,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation94,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation94,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"I completely agree that users should be able to choose whether they would like a personalized experience with a chatbot or not. With that said, I think they should clearly be told the negative impact to sharing their information and what could be done with it. They should definitely have to Opt In/Out.",2023-11-02,validation
validation94,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,I don't think the chatbot should store previous conversations because those may not be relevant in the future and sometimes I ask the chatbot questions on behalf of someone else.,2023-11-02,validation
validation94,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,Consent is important for mental health!,2023-11-02,validation
validation94,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I do agree with this statement but in addition to prioritizing privacy and data security, they should also ensure consent is given to collect.",2023-11-02,validation
validation94,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,It is extremely dangerous for a chatbot to give harmful or inaccurate information because people assume the chatbot will only give accurate and correct information.,2023-11-02,validation
validation94,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation95,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation95,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation95,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation95,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation95,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,it makes better conversation than going over all again  personalization will help with that.,2023-11-02,validation
validation95,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,if a bot is trained and retrained it can help with security protection.,2023-11-02,validation
validation95,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,chatbot personalization allows for customizing .,2023-11-02,validation
validation95,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,chatbots should be allowed ,2023-11-02,validation
validation95,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,chatbots are trustable,2023-11-02,validation
validation95,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation96,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation96,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation96,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation96,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation96,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"The more personal information, the more info that can cause problems for you later. (A health issue you asked the chatbot could keep you from getting a job, for example.) Without feeling safe, I would never put personal info into a chatbot.",2023-11-02,validation
validation96,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Yes, and I would be less concerned about advertisements than personal info being used. If I can't be sure they won't save my info (or keep my info safe if I want them to save it) I can't use the chatbot for anything serious.",2023-11-02,validation
validation96,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Yes, if that is even possible with a chatbot at this point. The converse of using a chatbot to save lives is a chatbot causing harm health-wise. I don't know if we're even at a point where I would go to a chatbot as a medical source or take what it said seriously.",2023-11-02,validation
validation96,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I still would never use a chatbot for medical advice. This rule is good, but so is going to an actual doctor, or checking a verified medical website (Mayo Clinic, etc.) for information. ",2023-11-02,validation
validation96,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"I think privacy and data collection are two separate issues. I wouldn't want my health info data collected at all. And would not ever go to a bot for ""tailored care"". ",2023-11-02,validation
validation96,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation97,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation97,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation97,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation97,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation97,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Paragraph too long-winded and lost my attention, but overall does capture my opinion overall.  ",2023-11-02,validation
validation97,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,I would never rely on chatbot for medical advice.  Strongly agree with sentiment that information must be accurate and trustworthy.,2023-11-02,validation
validation97,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,Agree with privacy and user consent. Strongly disagree with relying on chatbot for medical use.,2023-11-02,validation
validation97,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,I consider storing personal data extremely dangerous,2023-11-02,validation
validation97,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"For the most part agree except, again, relying on AI for medical advice of any type.",2023-11-02,validation
validation97,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation98,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation98,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation98,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation98,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation98,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"While I do that that remaining autonomous is important, it also is weird considering that if the chatbot knows the health data of this person, and this data is shared with ONLY this bot and this information cannot be accessed by anyone else, why not just tell them the health information so that they can make even better personalized dietary preferences.",2023-11-02,validation
validation98,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"This is almost exactly what I just said above, yes, this is very important if we want people to be able to trust chatbots with personal data. ",2023-11-02,validation
validation98,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"If someone does not want their chatbot to be able to remember details like this, I dont see a problem with it. However it could lead to less of a personalization and could help in the future, however this should not affect really the chatbot with that person at all. ",2023-11-02,validation
validation98,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Yes, this is very important, if we want chatbots to be able to be active in our daily lives they need to give the best information at all times. This however does mean that we need to be able to tell the chat bot everything we can, if we dont, the information it gives could be seen as the best at the time, but in reality is not because we withheld information from the chatbot. So we need to be able to express everything to the chat bot. ",2023-11-02,validation
validation98,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"Yes, absolutely, if we want chatbots to be apart of our life like this, and this is an amazing way of having them, we need them to be secured and private to ourselves. As if its our own property. ",2023-11-02,validation
validation98,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation99,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation99,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation99,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation99,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation99,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Though confidentiality and privacy are extremely important, there are a lot of other opinions I have on chatbots.",2023-11-02,validation
validation99,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",somewhat,2.0,"Health is an important thing to keep private, but so are other things like credit card info and overall privacy of the conversation.",2023-11-02,validation
validation99,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",poorly,1.0,"Though this is ideal, no one should ever rely on a chatbot for medical or personal information. I would never seek advice from a chatbot, but if I did I wouldn't take it super seriously.",2023-11-02,validation
validation99,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,This is very important to me. Everyone is already suggesting that computers and phones are listening to us have conversations. I don't want to also worry about a chatbot knowing everything about me and what I have been searching for.,2023-11-02,validation
validation99,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"Again, privacy is important. I agree it is important to have a user consent form, as to make sure people know what they are getting into. I think it should also follow its own security measures to ensure no breaching occurs.",2023-11-02,validation
validation99,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
validation100,1,reading,"
Survey on Chatbot Personalization


Informed Consent

What should I know about a research study?
Whether or not you take part is up to you. You can change your mind about participating at any time. However, you need to complete the survey to receive payment.


What is the purpose of this research?
This research investigates the role that artificial intelligence (AI) can play in facilitating and summarizing conversations in large groups. The hope is that AI models, such as GPT-4, can improve the way we make decisions in large groups. We also hope to learn what people like you think about how AI model should behave.


How long will the research last and what will I need to do?
We expect that you will be in this research study for well below an hour. We will ask you a number of questions about your opinions on what artificial intelligence should or should not be allowed to do. We will ask you how you believe a chatbot system should behave in certain scenarios, and we will ask what you think about the opinions formulated by fellow participants of the study.


Who will see your responses?
The data you provide will be anonymized immediately. We may later on publish this anonymous data. We might also show some of your responses to other participants to learn if they feel similarly or differently about the topic. By continuing this survey, you agree to this use of your responses.


Is there any way being in this study could be bad for me?
We don't believe there are any risks from participating in this research, unless you do not wish to discuss political topics.


Will being in this study help me in any way?
There are no benefits to you from your taking part in this research. Possible benefits to society include an enhanced understanding of how AI can be used for democracy.


What else do I need to know?
This research is funded by the Harvard John A. Paulson School of Engineering and Applied Sciences and a grant from OpenAI.


How will I be compensated?
As we showed you on Prolific, you will receive a flat payment for your participation in the survey (aiming for an hourly compensation of $10-$15/hour). If we indicate so in the survey, you may receive additional bonus payments. If you do not fill out the questions in good faith, we reserve the right to withhold payment, in accordance to Prolific rules.


Who can I talk to?
If you have questions, concerns, or complaints, or think the research has hurt you, you may talk to the research team at gilirusak@g.harvard.edu.
",Accept,,,,,2023-11-02,validation
validation100,2,reading,"
Background on Chatbots
You might have heard about new chatbots such as “ChatGPT”. Think of a chatbot as a website that uses artificial intelligence (AI) to mimic human conversation through text. The following is an example of a user asking ChatGPT a question:



Many people use them to

obtain information (for example by asking “What are the most famous things to see in Chicago?”)
edit text (for example: “Make this email sound more professional.”), or
get advice (for example: “What should I think about before buying a new car?”).

Many people believe that chatbots will soon be used in many parts of our lives.",Continue,,,,,2023-11-02,validation
validation100,3,reading,"Background on Chatbot Personalization
Current chatbots don't remember past conversations with you and don't use personal information about you. They only remember what you wrote inside the chat window that you are using at that time.
Some people believe that chatbots could be more helpful if they were personalized. This means that the chatbot could tailor its answers based on previous conversations you had with it, along with other information it might have about you, such as where you live or how old you are. 
Other people believe that such personalization could be risky.",Continue,,,,,2023-11-02,validation
validation100,4,reading,"Rating Summary Statements
This survey consists of only 5 questions. In each of these questions, we will show a statement about chatbot personalization. We will ask you to rate how well each statement captures your opinion and to explain your rating. Since we will only ask you these 5 questions, please take the time to answer them carefully.",Continue,,,,,2023-11-02,validation
validation100,5,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always prioritize user privacy and data security. This is crucial because it ensures the protection of sensitive user information, thereby building trust and promoting responsible AI use. For instance, a chatbot providing personalized health advice should only collect and use data with explicit user consent, and should implement robust measures to prevent unauthorized access or data breaches.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,You can easily talk to your doctor and you can talk o your lawyer and your priest becuase you know the conversation is potected by confidentiality. In talking to a bot you need that same security. A bot knows not what is private and confidential so all data and especially the user data should be secure. ,2023-11-02,validation
validation100,6,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to emphasize privacy and require user consent for data collection. This rule is crucial to ensure personal security and mental health protection. For instance, a health bot providing personalized services can offer tailored care, but without proper privacy measures, it risks violating user privacy.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,"This piggybacks on question 1. You must require user consent for data collection to ensure that user privacy is not violated. If bots are going to be first in line to take your call, you must protect the caller and the bot.",2023-11-02,validation
validation100,7,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to always give users the choice whether the AI chatbot can remember their data or not. This rule is crucial because it respects the user's privacy and gives them control over their own data. For instance, a user might prefer a chatbot not to store any data about their past travels, thus avoiding unsolicited vacation suggestions.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,"I am not a fan of having bots remember previous conversations automaticaly. Exceptions would be if the bot had asked if you wished your call to be noted with a serial number so it can be pulled at a later date, then its okay to have recoord trail becuase the user agreed. ",2023-11-02,validation
validation100,8,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to avoid providing false or misleading information. This rule is crucial because it ensures the reliability and trustworthiness of the chatbot, which is essential for user engagement and satisfaction. For instance, if a user asks a chatbot for medical advice, providing accurate information could potentially save lives.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",mostly,3.0,Bots are neer going to get it right 100% of the time. Probably more right than with the average call center. Bots can quickly look up information and parrot it back. Human reps are partially graded on call time average and the lower the better. Bots however need to work on reading all exceptions and other fine priint. I called with a tax question and it was answered incorrectly. Yes 100% would be perfect and we should continue to work toward that goal.,2023-11-02,validation
validation100,9,multiple choice + text,"Rating Summary Statements
Consider the following statement:

""The most important rule for chatbot personalization is to give users control over the extent of personalization and the data supplied. This rule is crucial as it ensures user autonomy, privacy, and a personalized experience. For instance, a user could choose to share their dietary preferences with a health chatbot for tailored advice, while opting not to disclose sensitive health data.""

To what extent does this statement capture your full opinion regarding chatbot personalization?
Briefly explain your choice.",,"[""not at all"", ""poorly"", ""somewhat"", ""mostly"", ""perfectly""]",perfectly,4.0,This is getting really close to the jackpot. It is up to the user and then it is up to the bot to comply.,2023-11-02,validation
validation100,10,reading,Thank you for completing the survey!,Return to Prolific,,,,,2023-11-02,validation
